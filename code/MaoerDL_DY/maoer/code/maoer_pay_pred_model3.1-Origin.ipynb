{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "042e0f49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T07:26:09.962363Z",
     "start_time": "2024-09-04T07:26:09.796542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--------开始时间： 2024-09-17 16:26:24.994971 -------------\n"
     ]
    }
   ],
   "source": [
    "# maoer_data深度学习模型 双层注意力机制\n",
    "# 加上付费label作为输入的gpu版  添加ACC、F1 score、Precision、Recall\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import datetime\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, recall_score, precision_score, roc_curve, \\\n",
    "    confusion_matrix\n",
    "from _collections import OrderedDict  # 导入 OrderedDict 来保持字典中键值对的顺序\n",
    "\n",
    "print('||--------开始时间：', datetime.datetime.now(), '-------------')\n",
    "# data input\n",
    "data_time_windows_list = ['0101_0131']  #'0115_0215',\n",
    "\n",
    "# 参数设置\n",
    "npratio=50 #负样本数\n",
    "\n",
    "# train_ratio = 0.6\n",
    "val_ratio = 0.5\n",
    "test_ratio = 0.5\n",
    "num_heads = 10\n",
    "feature_dim = 200\n",
    "max_history_len = 15\n",
    "num_experts = 3\n",
    "num_tasks = 2\n",
    "# 设置嵌入维度\n",
    "continue_embedding_dim = 200\n",
    "discrete_embedding_dim = 200\n",
    "lr = 0.1\n",
    "batch_size = 128\n",
    "threshold = 0.5\n",
    "\n",
    "\n",
    "# 获取时间窗内连续与离散特征名的列表\n",
    "def get_continue_discrete_feature_namelist(time_windows, datapath):\n",
    "    data = pd.read_csv(datapath)\n",
    "    time_windows_data = data[(data['DataSet'] == time_windows)]\n",
    "    user_history_pay_QOE_continue_column = eval([time_windows_data['QOE_continue'].values.tolist()][0][0])\n",
    "    user_history_pay_CHONGHE_continue_column = eval([time_windows_data['CHONGHE_continue'].values.tolist()][0][0])\n",
    "    user_history_pay_FUFEI_continue_column = eval([time_windows_data['FUFEI_continue'].values.tolist()][0][0])\n",
    "    user_history_pay_QOE_discrete_column = eval([time_windows_data['QOE_discrete'].values.tolist()][0][0])\n",
    "    user_history_pay_CHONGHE_discrete_column = eval([time_windows_data['CHONGHE_discrete'].values.tolist()][0][0])\n",
    "    user_history_pay_FUFEI_discrete_column = eval([time_windows_data['FUFEI_discrete'].values.tolist()][0][0])\n",
    "\n",
    "    return user_history_pay_QOE_continue_column, user_history_pay_CHONGHE_continue_column, user_history_pay_FUFEI_continue_column, \\\n",
    "        user_history_pay_QOE_discrete_column, user_history_pay_CHONGHE_discrete_column, user_history_pay_FUFEI_discrete_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db025e35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T08:36:41.921734Z",
     "start_time": "2024-09-04T08:36:41.803951Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1.数据处理+划分训练、验证、测试集\n",
    "\n",
    "# 划分数据集 给定输出后固定结果 输出形式定为存储user_id 形成train_dataset,val_dataset,test_dataset\n",
    "def data_input(data_time_windows, train_path, test_path, spilt_outpath, val_ratio, test_ratio, total_continue_feature):\n",
    "    train_dataset_path = train_path  # 待修改********\n",
    "    test_dataset_path = test_path\n",
    "    dataset_spilt_path = spilt_outpath  # 待修改********\n",
    "    if os.path.exists(dataset_spilt_path):  # 划分训练、验证、测试集\n",
    "        print(\"划分文件已存在，不再进行数据划分\")\n",
    "    else:\n",
    "        split_data_unique(train_dataset_path, test_dataset_path, dataset_spilt_path, val_ratio, test_ratio)\n",
    "    train_deal_data_df = data_pre_deal(train_dataset_path, total_continue_feature)  # 数据预处理\n",
    "    test_deal_data_df = data_pre_deal(test_dataset_path, total_continue_feature)  # 数据预处理\n",
    "    # 获取离散特征的类别数量，并存储为字典\n",
    "    _, train_deal_data_df = get_unique_feature_num_and_discrete_valueChange(\n",
    "        train_deal_data_df,\n",
    "        total_discrete_feature)\n",
    "\n",
    "    _, test_deal_data_df = get_unique_feature_num_and_discrete_valueChange(\n",
    "        test_deal_data_df,\n",
    "        total_discrete_feature)\n",
    "\n",
    "    feature_category_num_dict, _ = get_unique_feature_num_and_discrete_valueChange(\n",
    "        pd.concat([train_deal_data_df, test_deal_data_df]),\n",
    "        total_discrete_feature\n",
    "    )\n",
    "    # 读取划分文件的结果\n",
    "    spilt_data_df = pd.read_csv(dataset_spilt_path)\n",
    "    # 输出每一列数据为列表\n",
    "    train_list = spilt_data_df['Train'].tolist()\n",
    "    val_list = spilt_data_df['Val'].tolist()\n",
    "    test_list = spilt_data_df['Test'].tolist()\n",
    "    train_list = [x for x in train_list if not math.isnan(x)]\n",
    "    val_list = [x for x in val_list if not math.isnan(x)]\n",
    "    test_list = [x for x in test_list if not math.isnan(x)]\n",
    "    # print('训练集、验证集、测试集大小=', len(train_list),len(val_list),len(test_list))\n",
    "    # 根据划分好的生成以user_id为key的hash（特征集合）将最后一行看做目标数据\n",
    "    train_data_hash = {}\n",
    "    data_hash = {}  # 存成一个hash形式\n",
    "    find_data_by_list(train_list, train_deal_data_df, train_data_hash)\n",
    "    find_data_by_list(val_list, test_deal_data_df, data_hash)\n",
    "    find_data_by_list(test_list, test_deal_data_df, data_hash)\n",
    "    print('数据划分完成')\n",
    "    # print(feature_category_num_dict)\n",
    "    return train_list, val_list, test_list, train_data_hash, data_hash, feature_category_num_dict\n",
    "\n",
    "\n",
    "# 数据预处理 将连续特征变离散特征 分桶 不处理user_id、sound_id、drama_id、time\n",
    "def data_pre_deal(input_path, continue_feature_list):\n",
    "    df = pd.read_csv(input_path)\n",
    "    print('数据预处理结束')\n",
    "    return df\n",
    "\n",
    "\n",
    "# 根据划分好的数据集中user_id 找到对应csv文件中对应user_id的所有行数据取出，即包含了历史数据（付费+非付费）+目标数据（最后一次行为）\n",
    "# def find_data_by_list(user_list, intput_data_df, data_hash):\n",
    "#     df = intput_data_df\n",
    "#     # result_list = []\n",
    "#     # 遍历列表中的值，在CSV文件中找到所有匹配的行数据并加入结果列表\n",
    "#     for user_id in user_list:\n",
    "#         result_df = df[df[df.columns[0]] == user_id]\n",
    "#         # result_list.append(result_df)\n",
    "#         if user_id in data_hash:\n",
    "#             data_hash[user_id].update({col: result_df for col in df.columns})  # 使用列名作为键\n",
    "#         else:\n",
    "#             data_hash[user_id] = {col: result_df for col in df.columns}\n",
    "#     #result = pd.concat(result_list)  # 合并所有匹配的行数据\n",
    "#     return data_hash\n",
    "\n",
    "def find_data_by_list(user_list, intput_data_df, data_hash):\n",
    "    # 遍历列表中的值，在DataFrame中找到所有匹配的行数据并加入data_hash  \n",
    "    for user_id in user_list:\n",
    "        result_df = intput_data_df[intput_data_df[intput_data_df.columns[0]] == user_id]\n",
    "        data_hash[user_id] = result_df  # 直接存储DataFrame对象  \n",
    "    return data_hash\n",
    "\n",
    "\n",
    "# 获取列唯一值数量表，并对离散特征的值转化为从0开始的索引\n",
    "def get_unique_feature_num_and_discrete_valueChange(datadf, discrete_feature_column_list):\n",
    "    # 获取离散特征的类别数量，并存储为字典\n",
    "    feature_category_num_dict = {}\n",
    "    for column in datadf.columns:\n",
    "        unique_values_len = datadf[column].nunique()  # 获取列的唯一值数量\n",
    "        feature_category_num_dict[column] = unique_values_len\n",
    "        if column in discrete_feature_column_list:\n",
    "            unique_values = datadf[column].unique()\n",
    "            value_mapping_dict = {value: index for index, value in enumerate(unique_values) if\n",
    "                                  value != -1 and value != '' and value is not None}\n",
    "            datadf[column] = datadf[column].map(value_mapping_dict)\n",
    "    return feature_category_num_dict, datadf\n",
    "\n",
    "\n",
    "# 总的特征输入，生成划分后数据集及其输入\n",
    "def data_input(data_time_windows, train_path, test_path, spilt_outpath, val_ratio, test_ratio, total_continue_feature):\n",
    "    train_dataset_path = train_path  # 待修改********\n",
    "    test_dataset_path = test_path\n",
    "    dataset_spilt_path = spilt_outpath  # 待修改********\n",
    "    if os.path.exists(dataset_spilt_path):  # 划分训练、验证、测试集\n",
    "        print(\"划分文件已存在，不再进行数据划分\")\n",
    "    else:\n",
    "        split_data_unique(train_dataset_path, test_dataset_path, dataset_spilt_path, val_ratio, test_ratio)\n",
    "    train_deal_data_df = data_pre_deal(train_dataset_path, total_continue_feature)  # 数据预处理\n",
    "    test_deal_data_df = data_pre_deal(test_dataset_path, total_continue_feature)  # 数据预处理\n",
    "    # 获取离散特征的类别数量，并存储为字典\n",
    "    _, train_deal_data_df = get_unique_feature_num_and_discrete_valueChange(\n",
    "        train_deal_data_df,\n",
    "        total_discrete_feature)\n",
    "\n",
    "    _, test_deal_data_df = get_unique_feature_num_and_discrete_valueChange(\n",
    "        test_deal_data_df,\n",
    "        total_discrete_feature)\n",
    "\n",
    "    feature_category_num_dict, _ = get_unique_feature_num_and_discrete_valueChange(\n",
    "        pd.concat([train_deal_data_df, test_deal_data_df]),\n",
    "        total_discrete_feature\n",
    "    )\n",
    "    # 读取划分文件的结果\n",
    "    spilt_data_df = pd.read_csv(dataset_spilt_path)\n",
    "    # 输出每一列数据为列表\n",
    "    train_list = spilt_data_df['Train'].tolist()\n",
    "    val_list = spilt_data_df['Val'].tolist()\n",
    "    test_list = spilt_data_df['Test'].tolist()\n",
    "    train_list = [x for x in train_list if not math.isnan(x)]\n",
    "    val_list = [x for x in val_list if not math.isnan(x)]\n",
    "    test_list = [x for x in test_list if not math.isnan(x)]\n",
    "    # print('训练集、验证集、测试集大小=', len(train_list),len(val_list),len(test_list))\n",
    "    # 根据划分好的生成以user_id为key的hash（特征集合）将最后一行看做目标数据\n",
    "    train_data_hash = {}\n",
    "    data_hash = {}  # 存成一个hash形式\n",
    "    find_data_by_list(train_list, train_deal_data_df, train_data_hash)\n",
    "    find_data_by_list(val_list, test_deal_data_df, data_hash)\n",
    "    find_data_by_list(test_list, test_deal_data_df, data_hash)\n",
    "    print('数据划分完成')\n",
    "    # print(feature_category_num_dict)\n",
    "    return train_list, val_list, test_list, train_data_hash, data_hash, feature_category_num_dict\n",
    "\n",
    "# test\n",
    "# 数据集 train、val、test划分及总数据hash表(以user_id为key的存储对应对应行的hash表)及不同类特征数存储的字典\n",
    "# train_list, val_list, test_list, data_hash, feature_category_num_dict = data_input(\"0101_0131\", path,dataset_spilt_path, train_ratio, val_ratio, test_ratio, total_continue_feature)\n",
    "# print(data_hash[3617476])\n",
    "# print(feature_category_num_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59420a1d-a80d-4242-80c7-bc15ea0497dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T08:36:42.632667Z",
     "start_time": "2024-09-04T08:36:42.576725Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. 形成张量矩阵 目标特征为：（batch,1,feature_num; 用户历史行为特征为（batch,max_history_len(固定长度的历史记录数),feature_num）\n",
    "\n",
    "# mask 对用户历史行为长度的固定\n",
    "# 转换 history 列为长度为max_history_len的数组\n",
    "def process_history(history, max_history_len):\n",
    "    if len(history) >= max_history_len:\n",
    "        processed_history = history[-max_history_len:]\n",
    "    else:\n",
    "        processed_history = [-1] * (max_history_len - len(history)) + history\n",
    "    return processed_history\n",
    "\n",
    "\n",
    "# 将填充-1的位置标记为True\n",
    "def create_mask(history):\n",
    "    mask = [True if item == -1 else False for item in history]\n",
    "    return mask\n",
    "\n",
    "\n",
    "# 将历史行为记录处理为固定长度并进行mask\n",
    "def history_feature_mask(user_history_feature_index, data_matrix_user_history, max_history_len):\n",
    "    # user_history_feature_index: 用户历史特征的索引列表\n",
    "    mask_history_feature_matrix = []\n",
    "    origin_history_feature_matrix = []\n",
    "    for feature_index in range(len(user_history_feature_index)):\n",
    "        feature_data = [data_row[feature_index] for data_row in data_matrix_user_history]  # 获取一列特征值\n",
    "        processed_feature_data = process_history(feature_data,\n",
    "                                                 max_history_len)  # 处理为固定长度 max_history_len 假如max_history_len=15,原长度为5，那么处理后为[-1,-1, ..., -1, x1,x2,x3,x4,x5]\n",
    "        origin_history_feature_matrix.append(processed_feature_data)\n",
    "        mask_feature_data = create_mask(processed_feature_data)  # 将空的mask,填充-1的位置标记为True,其他为False\n",
    "        mask_history_feature_matrix.append(mask_feature_data)\n",
    "\n",
    "    # print('mask',len(origin_history_feature_matrix),len(origin_history_feature_matrix[0]))\n",
    "    return origin_history_feature_matrix, mask_history_feature_matrix\n",
    "\n",
    "\n",
    "# 将输入形成的data_hash和连续、离散特征列名,按照划分的训练或测试的user_id的列表，提取用户特征形成张量矩阵存储到data_tensor_hash中，以user_id为key，多个张量矩阵为value\n",
    "def get_feature_to_matrix(train_or_val_or_test_list, data_hash, feature_column_dict):\n",
    "    # 存储新的张量hash\n",
    "    data_tensor_hash = {}\n",
    "    # 存储历史记录的掩码矩阵\n",
    "    data_tensor_history_mask_hash = {}\n",
    "    target_label = []  # 预测目标值的标签\n",
    "\n",
    "    for user_id in train_or_val_or_test_list:\n",
    "        user_data = data_hash[user_id]\n",
    "        # 创建空的二维矩阵\n",
    "        # data_matrix_user_info_continue = []\n",
    "        # data_matrix_user_info_discrete = []\n",
    "        data_matrix_pay_QOE_continue = []\n",
    "        data_matrix_pay_QOE_discrete = []\n",
    "        data_matrix_pay_CHONGHE_continue = []\n",
    "        data_matrix_pay_CHONGHE_discrete = []\n",
    "        data_matrix_pay_FUFEI_continue = []\n",
    "        data_matrix_pay_FUFEI_discrete = []\n",
    "        data_matrix_target_QOE_continue = []\n",
    "        data_matrix_target_CHONGHE_continue = []\n",
    "        data_matrix_target_FUFEI_continue = []\n",
    "        data_matrix_target_QOE_discrete = []\n",
    "        data_matrix_target_CHONGHE_discrete = []\n",
    "        data_matrix_target_FUFEI_discrete = []\n",
    "        # 提取特征列对应的索引\n",
    "        # user_feature_continue_index = [user_data.columns.get_loc(col) for col in feature_column_dict['user_info_continue'] if col in user_data.columns]\n",
    "        # user_feature_discrete_index = [user_data.columns.get_loc(col) for col in feature_column_dict['user_info_discrete'] if\n",
    "        #                                col in user_data.columns]\n",
    "        user_history_QOE_continue_index = [user_data.columns.get_loc(col) for col in\n",
    "                                           feature_column_dict['history_QOE_continue'] if\n",
    "                                           col in user_data.columns]\n",
    "        user_history_QOE_discrete_index = [user_data.columns.get_loc(col) for col in\n",
    "                                           feature_column_dict['history_QOE_discrete'] if\n",
    "                                           col in user_data.columns]\n",
    "        user_history_CHONGHE_continue_index = [user_data.columns.get_loc(col) for col in\n",
    "                                               feature_column_dict['history_CHONGHE_continue'] if\n",
    "                                               col in user_data.columns]\n",
    "        user_history_CHONGHE_discrete_index = [user_data.columns.get_loc(col) for col in\n",
    "                                               feature_column_dict['history_CHONGHE_discrete'] if\n",
    "                                               col in user_data.columns]\n",
    "        user_history_FUFEI_continue_index = [user_data.columns.get_loc(col) for col in\n",
    "                                             feature_column_dict['history_FUFEI_continue'] if\n",
    "                                             col in user_data.columns]\n",
    "        user_history_FUFEI_discrete_index = [user_data.columns.get_loc(col) for col in\n",
    "                                             feature_column_dict['history_FUFEI_discrete'] if\n",
    "                                             col in user_data.columns]\n",
    "        user_history_CHONGHE_discrete_add_D_index = [user_data.columns.get_loc(col) for col in\n",
    "                                                     feature_column_dict['history_CHONGHE_discrete_add_D'] if\n",
    "                                                     col in user_data.columns]\n",
    "\n",
    "        # 填充数据矩阵\n",
    "        for i in range(len(user_data)):\n",
    "            if i != (len(user_data) - 1):  # 除最后一行即所有历史记录，不包括目标记录\n",
    "                # [[x11, x12, x13, ..., x1n],\n",
    "                #  [x21, x22, x23, ..., x2n],\n",
    "                #    .    .    .    .    .\n",
    "                #    .    .    .    .    .\n",
    "                #    .    .    .    .    .\n",
    "                #  [xm1, xm2, xm3, ..., xmn]]\n",
    "                # m x n: m代表该user_id对应的数据的行数-1，n代表qoe/fufei/chonghe的特征数\n",
    "                data_matrix_pay_QOE_continue.append(\n",
    "                    [user_data.iloc[i, col] for col in user_history_QOE_continue_index])  # 用户历史QOE连续特征\n",
    "                data_matrix_pay_QOE_discrete.append(\n",
    "                    [user_data.iloc[i, col] for col in user_history_QOE_discrete_index])  # 用户历史QOE离散特征\n",
    "                data_matrix_pay_CHONGHE_continue.append(\n",
    "                    [user_data.iloc[i, col] for col in user_history_CHONGHE_continue_index])  # 用户历史CHONGHE连续特征\n",
    "                data_matrix_pay_CHONGHE_discrete.append(\n",
    "                    [user_data.iloc[i, col] for col in user_history_CHONGHE_discrete_add_D_index])  # 用户历史CHONGHE离散特征\n",
    "                data_matrix_pay_FUFEI_continue.append(\n",
    "                    [user_data.iloc[i, col] for col in user_history_FUFEI_continue_index])  # 用户历史FUFEI连续特征\n",
    "                data_matrix_pay_FUFEI_discrete.append(\n",
    "                    [user_data.iloc[i, col] for col in user_history_FUFEI_discrete_index])  # 用户历史FUFEI离散特征\n",
    "            else:  # 目标记录\n",
    "                # data_matrix_user_info_continue.append([user_data.iloc[i, col] for col in user_feature_continue_index])  # 用户连续特征\n",
    "                # data_matrix_user_info_discrete.append([user_data.iloc[i, col] for col in user_feature_discrete_index])  # 用户离散特征\n",
    "                # 维度：1xn, 其中n代表特征数\n",
    "                target_label.append(user_data.iloc[i, -1])  # 预测目标的y值：1x1\n",
    "                data_matrix_target_QOE_continue.append(\n",
    "                    [user_data.iloc[i, col] for col in user_history_QOE_continue_index])  # 目标QOE连续特征\n",
    "                data_matrix_target_QOE_discrete.append(\n",
    "                    [user_data.iloc[i, col] for col in user_history_QOE_discrete_index])  # 目标QOE离散特征\n",
    "                data_matrix_target_CHONGHE_continue.append(\n",
    "                    [user_data.iloc[i, col] for col in user_history_CHONGHE_continue_index])  # 目标CHONGHE连续特征\n",
    "                data_matrix_target_CHONGHE_discrete.append(\n",
    "                    [user_data.iloc[i, col] for col in user_history_CHONGHE_discrete_index])  # 目标CHONGHE离散特征\n",
    "                data_matrix_target_FUFEI_continue.append(\n",
    "                    [user_data.iloc[i, col] for col in user_history_FUFEI_continue_index])  # 目标FUFEI连续特征\n",
    "                data_matrix_target_FUFEI_discrete.append(\n",
    "                    [user_data.iloc[i, col] for col in user_history_FUFEI_discrete_index])  # 目标FUFEI离散特征\n",
    "        # print('data_matrix_pay_QOE_continue:', len(data_matrix_pay_QOE_continue),len(data_matrix_pay_QOE_continue[0]))\n",
    "        # print(len(data_matrix_target_QOE_continue),len(data_matrix_target_QOE_continue[0]))\n",
    "        # 将历史行为记录处理为固定长度并进行mask\n",
    "        data_matrix_pay_QOE_continue, data_matrix_pay_QOE_continue_mask = history_feature_mask(\n",
    "            user_history_QOE_continue_index, data_matrix_pay_QOE_continue, max_history_len)\n",
    "        data_matrix_pay_QOE_discrete, data_matrix_pay_QOE_discrete_mask = history_feature_mask(\n",
    "            user_history_QOE_discrete_index, data_matrix_pay_QOE_discrete, max_history_len)\n",
    "        data_matrix_pay_CHONGHE_continue, data_matrix_pay_CHONGHE_continue_mask = history_feature_mask(\n",
    "            user_history_CHONGHE_continue_index, data_matrix_pay_CHONGHE_continue, max_history_len)\n",
    "        data_matrix_pay_CHONGHE_discrete, data_matrix_pay_CHONGHE_discrete_mask = history_feature_mask(\n",
    "            user_history_CHONGHE_discrete_add_D_index, data_matrix_pay_CHONGHE_discrete, max_history_len)\n",
    "        data_matrix_pay_FUFEI_continue, data_matrix_pay_FUFEI_continue_mask = history_feature_mask(\n",
    "            user_history_FUFEI_continue_index, data_matrix_pay_FUFEI_continue, max_history_len)\n",
    "        data_matrix_pay_FUFEI_discrete, data_matrix_pay_FUFEI_discrete_mask = history_feature_mask(\n",
    "            user_history_FUFEI_discrete_index, data_matrix_pay_FUFEI_discrete, max_history_len)\n",
    "        # print('data_matrix_pay_QOE_discrete',len(data_matrix_pay_QOE_discrete),len(data_matrix_pay_QOE_discrete[0]))\n",
    "        # print('(ata_matrix_pay_QOE_discrete',data_matrix_pay_QOE_discrete[0])\n",
    "\n",
    "        # 将numpy数组转换为PyTorch张量       # history   得到的data_matrix_user_history及data_tensor_pay_QOE_continue维度是(feature_num,history_len)需要转成tensor后转置\n",
    "        data_tensor_pay_QOE_continue = torch.transpose(\n",
    "            torch.tensor(np.array(data_matrix_pay_QOE_continue), dtype=torch.float32), -2, -1)\n",
    "        # data_tensor_pay_QOE_discrete = torch.tensor(np.array(data_matrix_pay_QOE_discrete), dtype=torch.float32)\n",
    "        # print('data_tensor_pay_QOE_discrete1',data_tensor_pay_QOE_discrete[0,:])\n",
    "        data_tensor_pay_QOE_discrete = torch.transpose(\n",
    "            torch.tensor(np.array(data_matrix_pay_QOE_discrete), dtype=torch.float32), -2, -1)\n",
    "        # print('data_tensor_pay_QOE_discrete2',data_tensor_pay_QOE_discrete[0,:])\n",
    "        # print('data_tensor_pay_QOE_discrete3',data_tensor_pay_QOE_discrete[:,0])\n",
    "        data_tensor_pay_CHONGHE_continue = torch.transpose(\n",
    "            torch.tensor(np.array(data_matrix_pay_CHONGHE_continue), dtype=torch.float32), -2, -1)\n",
    "        data_tensor_pay_CHONGHE_discrete = torch.transpose(\n",
    "            torch.tensor(np.array(data_matrix_pay_CHONGHE_discrete), dtype=torch.float32), -2, -1)\n",
    "        data_tensor_pay_FUFEI_continue = torch.transpose(\n",
    "            torch.tensor(np.array(data_matrix_pay_FUFEI_continue), dtype=torch.float32), -2, -1)\n",
    "        data_tensor_pay_FUFEI_discrete = torch.transpose(\n",
    "            torch.tensor(np.array(data_matrix_pay_FUFEI_discrete), dtype=torch.float32), -2, -1)\n",
    "        #  mask矩阵   得到的data_matrix_user_history及data_tensor_pay_QOE_continue维度是(feature_num,history_len)需要转成tensor后转置\n",
    "        data_tensor_pay_QOE_continue_mask = torch.transpose(\n",
    "            torch.tensor(np.array(data_matrix_pay_QOE_continue_mask), dtype=torch.float32), -2, -1)\n",
    "        data_tensor_pay_QOE_discrete_mask = torch.transpose(\n",
    "            torch.tensor(np.array(data_matrix_pay_QOE_discrete_mask), dtype=torch.float32), -2, -1)\n",
    "        data_tensor_pay_CHONGHE_continue_mask = torch.transpose(\n",
    "            torch.tensor(np.array(data_matrix_pay_CHONGHE_continue_mask), dtype=torch.float32), -2, -1)\n",
    "        data_tensor_pay_CHONGHE_discrete_mask = torch.transpose(\n",
    "            torch.tensor(np.array(data_matrix_pay_CHONGHE_discrete_mask), dtype=torch.float32), -2, -1)\n",
    "        data_tensor_pay_FUFEI_continue_mask = torch.transpose(\n",
    "            torch.tensor(np.array(data_matrix_pay_FUFEI_continue_mask), dtype=torch.float32), -2, -1)\n",
    "        data_tensor_pay_FUFEI_discrete_mask = torch.transpose(\n",
    "            torch.tensor(np.array(data_matrix_pay_FUFEI_discrete_mask), dtype=torch.float32), -2, -1)\n",
    "        # user + target   输出维度为（1，feature_num）,一处第一个为1的维度变为（feature_num）\n",
    "        # data_tensor_user_info_continue = torch.tensor(np.array(data_matrix_user_info_continue), dtype=torch.float32)\n",
    "        # data_tensor_user_info_discrete = torch.tensor(np.array(data_matrix_user_info_discrete), dtype=torch.float32)\n",
    "        data_tensor_target_QOE_continue = torch.squeeze(\n",
    "            torch.tensor(np.array(data_matrix_target_QOE_continue), dtype=torch.float32), dim=0)\n",
    "        data_tensor_target_QOE_discrete = torch.squeeze(\n",
    "            torch.tensor(np.array(data_matrix_target_QOE_discrete), dtype=torch.float32), dim=0)\n",
    "        data_tensor_target_CHONGHE_continue = torch.squeeze(\n",
    "            torch.tensor(np.array(data_matrix_target_CHONGHE_continue), dtype=torch.float32), dim=0)\n",
    "        data_tensor_target_CHONGHE_discrete = torch.squeeze(\n",
    "            torch.tensor(np.array(data_matrix_target_CHONGHE_discrete), dtype=torch.float32), dim=0)\n",
    "        data_tensor_target_FUFEI_continue = torch.squeeze(\n",
    "            torch.tensor(np.array(data_matrix_target_FUFEI_continue), dtype=torch.float32), dim=0)\n",
    "        data_tensor_target_FUFEI_discrete = torch.squeeze(\n",
    "            torch.tensor(np.array(data_matrix_target_FUFEI_discrete), dtype=torch.float32), dim=0)\n",
    "\n",
    "        # 生成hash值，按user_id为key存储成hash\n",
    "        tensor_hash_value = {\n",
    "            'pay_QOE_continue': data_tensor_pay_QOE_continue,\n",
    "            'pay_QOE_discrete': data_tensor_pay_QOE_discrete,\n",
    "            'pay_CHONGHE_continue': data_tensor_pay_CHONGHE_continue,\n",
    "            'pay_CHONGHE_discrete': data_tensor_pay_CHONGHE_discrete,\n",
    "            'pay_FUFEI_continue': data_tensor_pay_FUFEI_continue,\n",
    "            'pay_FUFEI_discrete': data_tensor_pay_FUFEI_discrete,\n",
    "            'target_QOE_continue': data_tensor_target_QOE_continue,\n",
    "            'target_QOE_discrete': data_tensor_target_QOE_discrete,\n",
    "            'target_CHONGHE_continue': data_tensor_target_CHONGHE_continue,\n",
    "            'target_CHONGHE_discrete': data_tensor_target_CHONGHE_discrete,\n",
    "            'target_FUFEI_continue': data_tensor_target_FUFEI_continue,\n",
    "            'target_FUFEI_discrete': data_tensor_target_FUFEI_discrete\n",
    "        }\n",
    "        tensor_hash_value_history_mask = {\n",
    "            'pay_QOE_continue': data_tensor_pay_QOE_continue_mask,\n",
    "            'pay_QOE_discrete': data_tensor_pay_QOE_discrete_mask,\n",
    "            'pay_CHONGHE_continue': data_tensor_pay_CHONGHE_continue_mask,\n",
    "            'pay_CHONGHE_discrete': data_tensor_pay_CHONGHE_discrete_mask,\n",
    "            'pay_FUFEI_continue': data_tensor_pay_FUFEI_continue_mask,\n",
    "            'pay_FUFEI_discrete': data_tensor_pay_FUFEI_discrete_mask,\n",
    "        }\n",
    "        if user_id in data_tensor_hash:\n",
    "            data_tensor_hash[user_id].update(tensor_hash_value)\n",
    "            data_tensor_history_mask_hash[user_id].update(tensor_hash_value_history_mask)\n",
    "        else:\n",
    "            data_tensor_hash[user_id] = tensor_hash_value\n",
    "            data_tensor_history_mask_hash[user_id] = tensor_hash_value_history_mask\n",
    "\n",
    "    # 如果需要合并成一个张量，可以使用torch.cat方法\n",
    "    # combined_tensor = torch.cat((data_matrix_1_tensor, data_matrix_2_tensor), dim=1)\n",
    "    # data_tensor_hash中用户历史的输出维度(max_history_len,feature_num)，目标的输出维度是（feature_num）\n",
    "    return data_tensor_hash, target_label, data_tensor_history_mask_hash\n",
    "\n",
    "\n",
    "# 张量矩阵添加一个batch维度，并在用户特征与目标特征的张量中再添加一维使其与用户历史行为张量对齐， 形成两种：\n",
    "# 原数据为：1.用户特征与目标特征都为：（1,feature_num）; 2.用户历史行为特征为（max_history_len(固定长度的历史记录数),feature_num）\n",
    "# 新数据为：1.用户特征与目标特征都为：（batch,1,1,feature_num); 2.用户历史行为特征为（batch,max_history_len(固定长度的历史记录数),feature_num）\n",
    "# 形成batch维度的特征\n",
    "def generate_batch_feature(train_or_val_or_test_list, data_tensor_hash,\n",
    "                           feature_category):  # 例:feature_category = 'user_info_continue' 就是上面生成的tensor_hash_value字典的键\n",
    "    tensor_list = []\n",
    "    for user_id in train_or_val_or_test_list:  # 遍历data_tensor_hash的所有key (user_id)\n",
    "        if feature_category in data_tensor_hash[user_id]:\n",
    "            tensor = data_tensor_hash[user_id][feature_category]  # 获取feature_category对应的张量\n",
    "            tensor_list.append(tensor)  # 添加到tensor_list中\n",
    "    #  print(tensor_list)\n",
    "    batch_feature_tensor = torch.stack(tensor_list, dim=0)  # 在第一个维度上合并所有张量(其实相当于生成一个新维度)\n",
    "    return batch_feature_tensor\n",
    "\n",
    "\n",
    "# 生成batch再添加维度对齐张量（三个维度）\n",
    "def generate_user_feature_alignment_tensor(train_or_val_or_test_list, data_tensor_hash, is_mask=False):\n",
    "    # 用户历史行为矩阵（max_history_len(固定长度的历史记录数),feature_num）->（batch,max_history_len(固定长度的历史记录数),feature_num）\n",
    "    pay_QOE_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list, data_tensor_hash,\n",
    "                                                                   'pay_QOE_continue')\n",
    "    pay_QOE_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list, data_tensor_hash,\n",
    "                                                                   'pay_QOE_discrete')\n",
    "    pay_CHONGHE_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list, data_tensor_hash,\n",
    "                                                                       'pay_CHONGHE_continue')\n",
    "    pay_CHONGHE_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list, data_tensor_hash,\n",
    "                                                                       'pay_CHONGHE_discrete')\n",
    "    pay_FUFEI_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list, data_tensor_hash,\n",
    "                                                                     'pay_FUFEI_continue')\n",
    "    pay_FUFEI_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list, data_tensor_hash,\n",
    "                                                                     'pay_FUFEI_discrete')\n",
    "    # print('pay_QOE_discrete_batch_feature_tensor1',pay_QOE_discrete_batch_feature_tensor[0,:,0])\n",
    "    # 看是否是掩码矩阵，不是则xxx，是则没有user+target\n",
    "    if is_mask == False:\n",
    "        # 用户矩阵 (feature_num) ->(batch,feature_num)\n",
    "        # user_info_continue_batch_feature_tensor = generate_batch_feature(data_tensor_hash, 'user_info_continue')\n",
    "        # user_info_discrete_batch_feature_tensor = generate_batch_feature(data_tensor_hash, 'user_info_discrete')\n",
    "        # 目标矩阵 (feature_num) ->(batch,feature_num)\n",
    "        target_QOE_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list, data_tensor_hash,\n",
    "                                                                          'target_QOE_continue')\n",
    "        target_QOE_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list, data_tensor_hash,\n",
    "                                                                          'target_QOE_discrete')\n",
    "        target_CHONGHE_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,\n",
    "                                                                              data_tensor_hash,\n",
    "                                                                              'target_CHONGHE_continue')\n",
    "        target_CHONGHE_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,\n",
    "                                                                              data_tensor_hash,\n",
    "                                                                              'target_CHONGHE_discrete')\n",
    "        target_FUFEI_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list, data_tensor_hash,\n",
    "                                                                            'target_FUFEI_continue')\n",
    "        target_FUFEI_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list, data_tensor_hash,\n",
    "                                                                            'target_FUFEI_discrete')\n",
    "\n",
    "        # 假设原始张量矩阵为 tensor，形状为 (batch_size, feature_num)将其加一个维度变为 (batch_size, 1, feature_num)\n",
    "        # user_info_continue_batch_feature_tensor = torch.unsqueeze(user_info_continue_batch_feature_tensor, dim=1)\n",
    "        # user_info_discrete_batch_feature_tensor = torch.unsqueeze(user_info_discrete_batch_feature_tensor, dim=1)\n",
    "        target_QOE_continue_batch_feature_tensor = torch.unsqueeze(target_QOE_continue_batch_feature_tensor, dim=1)\n",
    "        target_QOE_discrete_batch_feature_tensor = torch.unsqueeze(target_QOE_discrete_batch_feature_tensor, dim=1)\n",
    "        target_CHONGHE_continue_batch_feature_tensor = torch.unsqueeze(target_CHONGHE_continue_batch_feature_tensor,\n",
    "                                                                       dim=1)\n",
    "        target_CHONGHE_discrete_batch_feature_tensor = torch.unsqueeze(target_CHONGHE_discrete_batch_feature_tensor,\n",
    "                                                                       dim=1)\n",
    "        target_FUFEI_continue_batch_feature_tensor = torch.unsqueeze(target_FUFEI_continue_batch_feature_tensor, dim=1)\n",
    "        target_FUFEI_discrete_batch_feature_tensor = torch.unsqueeze(target_FUFEI_discrete_batch_feature_tensor, dim=1)\n",
    "\n",
    "        batch_feature_tensor_dict = {\n",
    "            'pay_QOE_discrete': pay_QOE_discrete_batch_feature_tensor,\n",
    "            'pay_CHONGHE_discrete': pay_CHONGHE_discrete_batch_feature_tensor,\n",
    "            'pay_FUFEI_discrete': pay_FUFEI_discrete_batch_feature_tensor,\n",
    "            'pay_QOE_continue': pay_QOE_continue_batch_feature_tensor,\n",
    "            'pay_CHONGHE_continue': pay_CHONGHE_continue_batch_feature_tensor,\n",
    "            'pay_FUFEI_continue': pay_FUFEI_continue_batch_feature_tensor,\n",
    "            'target_QOE_discrete': target_QOE_discrete_batch_feature_tensor,\n",
    "            'target_CHONGHE_discrete': target_CHONGHE_discrete_batch_feature_tensor,\n",
    "            'target_FUFEI_discrete': target_FUFEI_discrete_batch_feature_tensor,\n",
    "            'target_QOE_continue': target_QOE_continue_batch_feature_tensor,\n",
    "            'target_CHONGHE_continue': target_CHONGHE_continue_batch_feature_tensor,\n",
    "            'target_FUFEI_continue': target_FUFEI_continue_batch_feature_tensor,\n",
    "\n",
    "        }\n",
    "    else:\n",
    "        batch_feature_tensor_dict = {\n",
    "            'pay_QOE_discrete': pay_QOE_discrete_batch_feature_tensor,\n",
    "            'pay_CHONGHE_discrete': pay_CHONGHE_discrete_batch_feature_tensor,\n",
    "            'pay_FUFEI_discrete': pay_FUFEI_discrete_batch_feature_tensor,\n",
    "            'pay_QOE_continue': pay_QOE_continue_batch_feature_tensor,\n",
    "            'pay_CHONGHE_continue': pay_CHONGHE_continue_batch_feature_tensor,\n",
    "            'pay_FUFEI_continue': pay_FUFEI_continue_batch_feature_tensor,\n",
    "        }\n",
    "    return batch_feature_tensor_dict  # 这里张量输出的全是三维 (batch_size, 1 or max_history_len, feature_num)\n",
    "\n",
    "\n",
    "# 由于模型输入得是张量，因此在之前将字典转化为了张量，现在将它转换回去\n",
    "class TensorDatasettoDict(Dataset):\n",
    "    def __init__(self, dataset, keys):\n",
    "        self.dataset = dataset\n",
    "        self.keys = keys\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        sample = {key: data[i] for i, key in enumerate(self.keys)}\n",
    "        return sample\n",
    "\n",
    "# test\n",
    "# 获取训练、验证、测试集对应的数据形成的向量hash存储及label\n",
    "# print(data_hash[3617476])\n",
    "# train_data_tensor_hash, train_label, train_data_tensor_hash_history_mask = get_feature_to_matrix(train_list, data_hash, feature_column_dict)\n",
    "# first_key = list(train_data_tensor_hash.keys())[0]\n",
    "# print(train_data_tensor_hash[first_key]['pay_QOE_discrete'][:,0])\n",
    "# print(train_label)\n",
    "# # print(train_data_tensor_hash[3617476])\n",
    "# dimensions1 = train_data_tensor_hash[3617476]['pay_QOE_continue'].size()\n",
    "# dimensions2 = train_data_tensor_hash[3617476]['pay_QOE_discrete'].size()\n",
    "# dimensions3 = train_data_tensor_hash[3617476]['pay_CHONGHE_continue'].size()\n",
    "# dimensions4 = train_data_tensor_hash[3617476]['target_QOE_continue'].size()\n",
    "# dimensions5 = train_data_tensor_hash[3617476]['target_QOE_discrete'].size()\n",
    "# dimensions6 = train_data_tensor_hash[3617476]['target_CHONGHE_continue'].size()\n",
    "# print(\"PyTorch张量的维度：\", dimensions1,dimensions2,dimensions3,dimensions4,dimensions5,dimensions6)\n",
    "# train_batch_feature_tensor_dict = generate_user_feature_alignment_tensor(train_list,train_data_tensor_hash)\n",
    "# train_batch_feature_tensor_history_mask_dict = generate_user_feature_alignment_tensor(train_data_tensor_hash_history_mask,is_mask=True)\n",
    "# print(train_batch_feature_tensor_dict['pay_QOE_discrete'][0,:,0])\n",
    "# dimensions1 = train_data_tensor_hash[3617476]['pay_QOE_continue'].size()\n",
    "# dimensions2 = train_data_tensor_hash[3617476]['pay_QOE_discrete'].size()\n",
    "# dimensions3 = train_data_tensor_hash[3617476]['pay_CHONGHE_continue'].size()\n",
    "# dimensions4 = train_data_tensor_hash[3617476]['target_QOE_continue'].size()\n",
    "# dimensions5 = train_data_tensor_hash[3617476]['target_QOE_discrete'].size()\n",
    "# dimensions6 = train_data_tensor_hash[3617476]['target_CHONGHE_continue'].size()\n",
    "# print(\"PyTorch添加batch后张量的维度：\", dimensions1,dimensions2,dimensions3,dimensions4,dimensions5,dimensions6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6535f848-5c74-494a-84e9-884c8f6d42b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T08:36:43.490103Z",
     "start_time": "2024-09-04T08:36:43.369467Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3.基础模型 embedding、attention\n",
    "# 构建离散特征的embedding\n",
    "def discrete_embedding(feature_category_num_dict, feature_column_name_list, embedding_dim):  # 输入特征取值大小的集合,特征数,维度\n",
    "    # 创建一个列表来存储每个嵌入层\n",
    "    embeddings = []\n",
    "    for i in range(0, len(feature_column_name_list)):\n",
    "        # print(feature_column_name_list[i], feature_category_num_dict[feature_column_name_list[i]])\n",
    "        embedding_layer1 = nn.Embedding(feature_category_num_dict[feature_column_name_list[i]] + 2, embedding_dim)\n",
    "        embeddings.append(embedding_layer1)\n",
    "    #     print('embedding维度',feature_category_num_dict[feature_column_name_list[i]]+1)\n",
    "    # print('本轮embedding层：',len(feature_column_name_list))\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# 全连接层 MLP\n",
    "def dense_layer(in_features, out_features):\n",
    "    # in_features=hidden_size,out_features=1\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features, bias=True),\n",
    "        nn.ReLU())\n",
    "\n",
    "\n",
    "# 全连接层 MLP\n",
    "def dense_layer_noReLu(in_features, out_features):\n",
    "    # in_features=hidden_size,out_features=1\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features, bias=True))\n",
    "\n",
    "\n",
    "# 连续特征离散化\n",
    "def continuous_embedding(num_continuous_features, out_features):\n",
    "    continuous_embedding_layers = []\n",
    "    for i in range(0, len(num_continuous_features)):\n",
    "        num_continuous_feature = num_continuous_features[i]\n",
    "        embedding_layer = dense_layer(1, out_features)\n",
    "        continuous_embedding_layers.append(embedding_layer)\n",
    "    return continuous_embedding_layers\n",
    "\n",
    "\n",
    "# 根据全特征数量表及类别，得到类别下的对应特征数量  feature_column_name_list = feature_column_dict['user_info_continue']\n",
    "def category_feature_num(feature_category_num_dict, feature_column_name_list):\n",
    "    category_feature_num_list = []\n",
    "    for i in range(len(feature_column_name_list)):\n",
    "        category_feature_num_list.append(feature_category_num_dict[feature_column_name_list[i]])\n",
    "    # print('category_feature_num',len(category_feature_num_list))\n",
    "    return category_feature_num_list\n",
    "\n",
    "\n",
    "# SE层中找到合适的reduction使channel // reduction得到整数\n",
    "def find_reduction(channel, min_reduction=2, max_reduction=19):\n",
    "    # 对于质数，直接取自己作为reduction  \n",
    "    if is_prime(channel):\n",
    "        return channel\n",
    "\n",
    "        # 计算介于min_reduction和max_reduction之间的候选reduction值  \n",
    "    candidates = [i for i in range(min_reduction, max_reduction + 1) if channel % i == 0]\n",
    "\n",
    "    # 如果候选列表为空，则至少取2作为reduction  \n",
    "    if not candidates:\n",
    "        return min_reduction\n",
    "\n",
    "        # 尝试找到最大的候选值，使得channel // reduction的结果尽可能大  \n",
    "    reduction = max(candidates)\n",
    "\n",
    "    return reduction\n",
    "\n",
    "\n",
    "def is_prime(n):\n",
    "    \"\"\"判断一个数是否为质数\"\"\"\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(math.sqrt(n)) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# 输入(batch,feature_num,embedding_dim,1) ->(batch,feature_num,embedding_dim,1)->输出特征权重及权重乘后的(batch,embedding_dim) \n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.reduction = reduction\n",
    "        self.reduction = find_reduction(channel)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        # print('b, c, h, w',b, c, h, w)\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        # print('y',y)\n",
    "        weight = self.fc(y).view(b, c, 1, 1)\n",
    "        new_x = x * weight.expand_as(x)  # 利用了 PyTorch 的广播机制，使得张量 weight 被复制成与输入 x 相同的形状，然后进行逐元素相乘 \n",
    "        # 加权平均 (batch, embedding_dim)\n",
    "        weighted_avg_out_x = new_x.mean(dim=1, keepdim=True)  # 在 feature_num维度上取平均，保持维度\n",
    "        # 调整维度\n",
    "        weighted_avg_out_x = weighted_avg_out_x.view(b, 1, h, w)\n",
    "        # 去除最后一维\n",
    "        new_x = new_x.squeeze(dim=3)\n",
    "        weighted_avg_out_x = weighted_avg_out_x.squeeze(dim=3)\n",
    "\n",
    "        return weight, weighted_avg_out_x, new_x\n",
    "\n",
    "\n",
    "# 旧 弃用\n",
    "# class SELayer(nn.Module):\n",
    "#     def __init__(self, feature_dim, feature_num, reduction=16):\n",
    "#         super(SELayer, self).__init__()\n",
    "#         self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(in_features=feature_dim, out_features=feature_dim // reduction, bias=False),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(in_features=feature_dim // reduction, out_features=feature_num, bias=False),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         # Apply average pooling along the feature_dim dimension  x(batch, embedding_dim, feature_num)\n",
    "#         b, c, h = x.size()\n",
    "#         print('b, c, h', b, c, h)\n",
    "#         y = self.pool(x.unsqueeze(-1)).view(b, c, -1)  # (batch, embedding_dim, 1)\n",
    "#         print('y', y)\n",
    "#         print('b, h', b, h)\n",
    "#         # Generate attention weights for each feature\n",
    "#         attention_weights = self.fc(y).view(b, h, -1)  # 权重batch, 1, feature_num\n",
    "#         print(attention_weights.shape)\n",
    "#         # Apply attention weights to the original input\n",
    "#         weighted_x = x * attention_weights.unsqueeze(1)\n",
    "#         # 输出的是一个形状为(batch, embedding_dim, feature_num)的张量。\n",
    "#         # 这个张量是对原始输入x进行加权后的结果，其中每个特征都被相应的注意力权重所乘。\n",
    "\n",
    "#         # Sum over the feature_num dimension to get (batch, embedding_dim)\n",
    "#         weighted_sum = torch.sum(weighted_x, dim=2)\n",
    "\n",
    "#         return attention_weights, weighted_sum, weighted_x\n",
    "# def forward(self, x):\n",
    "#     # Apply average pooling along the feature_dim dimension  x(batch, feature_dim, feature_num)\n",
    "#     b, c, h, w = x.size()\n",
    "#     print('b, c, h, w',b, c, h, w)\n",
    "#     y = self.pool(x).view(b, c, -1)  # (batch, feature_dim, 1, 1)\n",
    "#     print('y',y)\n",
    "#     print('b, h * w',b, h * w)\n",
    "#     # Generate attention weights for each feature\n",
    "#     attention_weights = self.fc(y).view(b, h * w, -1)  # 权重batch, 1, 1, feature_num)\n",
    "#     print(attention_weights.shape)\n",
    "#     # Apply attention weights to the original input\n",
    "#     weighted_x = x.view(b, c, -1) * attention_weights\n",
    "#     # 输出的是一个形状为(batch, feature_dim, 1, feature_num)的张量。\n",
    "#     # 这个张量是对原始输入x进行加权后的结果，其中每个特征都被相应的注意力权重所乘。\n",
    "#     weighted_x = weighted_x.view(b, c, h, w)\n",
    "\n",
    "#     # Sum over the feature_num dimension to get (batch, feature_dim, 1)\n",
    "#     # weighted_sum = torch.sum(weighted_x, dim=2, keepdim=True)的具体意思是沿着feature_num维度\n",
    "#     # （即第三个维度，索引为2）对weighted_x进行求和。由于keepdim=True，求和后的结果保持了一个额外的维度，\n",
    "#     # 形状为(batch, feature_dim, 1)。这一步实现了对每个样本的所有特征进行加权求和，得到一个新的特征表示。\n",
    "#     weighted_sum = torch.sum(weighted_x, dim=2, keepdim=True)\n",
    "#     # 转置最后两维\n",
    "#     weighted_sum = torch.transpose(weighted_sum, -2, -1)\n",
    "\n",
    "#     return attention_weights, weighted_sum, weighted_x\n",
    "\n",
    "# 多头自注意力\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, num_heads, feature_dim, max_history_len):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.num_heads = num_heads  #10\n",
    "        self.feature_dim = feature_dim  #200\n",
    "        self.head_dim = feature_dim // num_heads\n",
    "        self.max_history_len = max_history_len\n",
    "\n",
    "        self.WQ = nn.Linear(feature_dim, feature_dim)\n",
    "        self.WK = nn.Linear(feature_dim, feature_dim)\n",
    "        self.WV = nn.Linear(feature_dim, feature_dim)\n",
    "\n",
    "    def forward(self, history_matrix, mask=None):\n",
    "        batch_size, history_len, _ = history_matrix.size()\n",
    "\n",
    "        Q = self.WQ(history_matrix)\n",
    "        K = self.WK(history_matrix)\n",
    "        V = self.WV(history_matrix)\n",
    "\n",
    "        Q = Q.view(batch_size, history_len, self.num_heads, self.head_dim).permute(0, 2, 1,\n",
    "                                                                                   3)  #(batch,num_heads,history_len,head_dim)\n",
    "        K = K.view(batch_size, history_len, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, history_len, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "        attention_scores = torch.matmul(Q, K.permute(0, 1, 3, 2)) / (self.head_dim ** 0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.permute(0, 2, 1)  # 二、三维度互换  变为(batch, feature_num, history)\n",
    "            temp_dim = mask.shape[1]\n",
    "            #（样本数*特征数,历史数）\n",
    "            mask = mask.reshape(-1, max_history_len)\n",
    "            attention_scores = attention_scores.masked_fill(mask.unsqueeze(1).unsqueeze(2).bool(), float('-1e30'))  #()\n",
    "\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)  #shape(batch,head,history_len,history_len)\n",
    "        #(batch,history_len,200)\n",
    "        weighted_sum = torch.matmul(attention_weights, V).permute(0, 2, 1, 3).contiguous().view(batch_size, history_len,\n",
    "                                                                                                self.feature_dim)\n",
    "        # 计算加权平均\n",
    "        weighted_avg_out = weighted_sum.mean(dim=1, keepdim=True)  # 在 history_len 维度上取平均，保持维度\n",
    "        # 调整维度\n",
    "        weighted_avg_out = weighted_avg_out.view(batch_size, 1, self.feature_dim)\n",
    "        # print('weighted_sum',weighted_avg_out.shape)\n",
    "\n",
    "        return attention_weights, weighted_avg_out, weighted_sum\n",
    "\n",
    "\n",
    "# class MultiHeadSelfAttention(nn.Module):\n",
    "#     def __init__(self, num_heads, feature_dim):\n",
    "#         super(MultiHeadSelfAttention, self).__init__()\n",
    "#         self.num_heads = num_heads\n",
    "#         self.feature_dim = feature_dim\n",
    "#         self.head_dim = feature_dim // num_heads\n",
    "\n",
    "#         # 线性变换的权重\n",
    "#         self.wq = nn.Parameter(torch.Tensor(feature_dim, self.num_heads * self.head_dim))\n",
    "#         self.wk = nn.Parameter(torch.Tensor(feature_dim, self.num_heads * self.head_dim))\n",
    "#         self.wv = nn.Parameter(torch.Tensor(feature_dim, self.num_heads * self.head_dim))\n",
    "\n",
    "#         # 初始化权重\n",
    "#         nn.init.normal_(self.wq, std=0.02)\n",
    "#         nn.init.normal_(self.wk, std=0.02)\n",
    "#         nn.init.normal_(self.wv, std=0.02)\n",
    "\n",
    "#     def forward(self, history_embedding_vec, mask=None):\n",
    "#         batch_size, history_len, feature_num, feature_dim = history_embedding_vec.size()\n",
    "#         # 将feature_num和batch_size合并\n",
    "#         x = history_embedding_vec.view(batch_size * feature_num, history_len, feature_dim)\n",
    "#         # 线性变换\n",
    "#         q = torch.matmul(x, self.wq).view(batch_size * feature_num, history_len, self.num_heads,self.head_dim).transpose(1, 2)\n",
    "#         k = torch.matmul(x, self.wk).view(batch_size * feature_num, history_len, self.num_heads,self.head_dim).transpose(1, 2)\n",
    "#         v = torch.matmul(x, self.wv).view(batch_size * feature_num, history_len, self.num_heads,self.head_dim).transpose(1, 2)\n",
    "#         # 缩放点积注意力\n",
    "#         scores = torch.matmul(q, k.transpose(-1, -2)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
    "#         if mask is not None:\n",
    "#             mask = mask.view(batch_size * feature_num, history_len)\n",
    "#             scores = scores.masked_fill(mask.unsqueeze(1).unsqueeze(2).bool(), float('-inf'))\n",
    "#         attention_weights = nn.Softmax(dim=-1)(scores)\n",
    "#         out = torch.matmul(attention_weights, v).transpose(1, 2).contiguous().view(batch_size, feature_num, history_len,self.num_heads * self.head_dim)\n",
    "#         # 合并多头\n",
    "#         out = torch.matmul(out, self.wq.view(self.num_heads * self.head_dim, feature_dim)).view(batch_size, feature_num,history_len,feature_dim)\n",
    "#         # 恢复到原始形状\n",
    "#         # out = out.view(batch_size, feature_num, history_len, feature_dim)\n",
    "\n",
    "#           # 计算加权平均后的结果\n",
    "#         # 计算加权平均\n",
    "#         weighted_avg_out = out.mean(dim=2, keepdim=True)  # 在 history_len 维度上取平均，保持维度\n",
    "#         # 调整维度\n",
    "#         weighted_avg_out = weighted_avg_out.view(batch_size, 1, feature_num, feature_dim)\n",
    "\n",
    "#         return attention_weights, weighted_avg_out\n",
    "\n",
    "# 注意力机制 关于用\n",
    "class MultiHeadHistory_TargetAttention(nn.Module):\n",
    "    def __init__(self, num_heads, embed_dim, dropout=0.1):\n",
    "        super(MultiHeadHistory_TargetAttention, self).__init__()\n",
    "\n",
    "        assert embed_dim % num_heads == 0, f\"Embedding dimension ({embed_dim}) should be divisible by the number of heads ({num_heads}).\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        # 定义权重矩阵\n",
    "        self.q_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self.scaling = self.head_dim ** -0.5\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        # 进行线性投影并分离成多个头\n",
    "        q = self.q_linear(query).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.k_linear(key).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.v_linear(value).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        # 计算注意力得分\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scaling\n",
    "        if attn_mask is not None:\n",
    "            scores.masked_fill_(attn_mask.unsqueeze(1), float('-1e30'))\n",
    "        # 应用softmax函数\n",
    "        attn_weights = self.softmax(scores)\n",
    "        # 应用dropout\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        # 进行值的加权求和\n",
    "        context = torch.matmul(attn_weights, v).transpose(1, 2).contiguous().view(batch_size, -1, self.embed_dim)\n",
    "        # 输出层的线性变换\n",
    "        output = self.out_proj(context)\n",
    "        return attn_weights, output\n",
    "\n",
    "# class MultiHeadHistory_TargetAttention(nn.Module):\n",
    "#     def __init__(self, num_heads, feature_dim):\n",
    "#         super(MultiHeadHistory_TargetAttention, self).__init__()\n",
    "#         self.feature_dim = feature_dim\n",
    "#         self.num_heads = num_heads\n",
    "#         self.head_dim = feature_dim // num_heads\n",
    "\n",
    "#         assert (\n",
    "#                 self.head_dim * num_heads == feature_dim\n",
    "#         ), \"Embedding dimension must be divisible by num_heads.\"\n",
    "\n",
    "#         self.values = nn.Linear(self.num_heads * self.head_dim, self.num_heads * self.head_dim, bias=False)\n",
    "#         # self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "#         self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "#         self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "#         # 其他部分保持不变\n",
    "\n",
    "#     def forward(self, student_embeddings, unit_embeddings, mask=None):\n",
    "#         batch_size = student_embeddings.size(0)\n",
    "\n",
    "#         # Split the embedding into self.num_heads different pieces\n",
    "#         student_values = student_embeddings.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "#         student_keys = student_embeddings.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "#         student_queries = student_embeddings.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "\n",
    "#         unit_values = unit_embeddings.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "#         unit_keys = unit_embeddings.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "#         # print('student_queries',student_queries.shape)\n",
    "#         # print('unit_keys',unit_keys.shape)\n",
    "\n",
    "#         # Compute the attention weights\n",
    "#         energy = torch.matmul(student_queries, unit_keys.transpose(-2, -1)) / torch.sqrt(\n",
    "#             torch.tensor(self.head_dim, dtype=torch.float32))\n",
    "#         if mask is not None:\n",
    "#             attention_weights = energy.masked_fill(mask.unsqueeze(1).unsqueeze(2), float('-inf'))\n",
    "#         attention_weights = torch.softmax(energy, dim=-1)\n",
    "\n",
    "#         # Apply attention weights to the values\n",
    "#         out = torch.matmul(attention_weights, unit_values)\n",
    "#         # print(out.shape)\n",
    "\n",
    "#         # Concatenate the outputs of the different heads\n",
    "#         out = out.view(batch_size, -1, self.num_heads * self.head_dim)\n",
    "#         # print(out.shape)\n",
    "\n",
    "#         # Finally, apply a linear layer to get the final output\n",
    "#         out = self.values(out)\n",
    "\n",
    "#         return attention_weights, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b1a312-5627-4a04-9e2f-dd5dc3889a88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T08:36:44.430495Z",
     "start_time": "2024-09-04T08:36:44.395131Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.Embedding层\n",
    "\n",
    "# user_history_feature 对于一个user的多个历史行为，将其拼接成一维向量 要先经过一层通道注意力机制得到最后结果\n",
    "# (样本数,history,20,200) ->多头 ->(样本数,20,200)->转置->(样本数,200,20) ->SE->特征权重->(样本数,200,20) ->转置-> 加权->(样本数,1，200)\n",
    "# user_pay_history_feature 加上batch的\n",
    "# 用户历史\n",
    "class UserPayHistoryEmbedding(nn.Module):\n",
    "    def __init__(self, continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict):\n",
    "        super(UserPayHistoryEmbedding, self).__init__()\n",
    "        # 连续特征\n",
    "        # 离散特征\n",
    "        self.feature_category_num_dict = feature_category_num_dict\n",
    "        # 离散embedding\n",
    "        self.user_pay_history_QOE_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,\n",
    "                                                                           feature_column_dict['history_QOE_discrete'],\n",
    "                                                                           discrete_embedding_dim)\n",
    "        self.user_pay_history_CHONGHE_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,\n",
    "                                                                               feature_column_dict[\n",
    "                                                                                   'history_CHONGHE_discrete_add_D'],\n",
    "                                                                               discrete_embedding_dim)\n",
    "        self.user_pay_history_FUFEI_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,\n",
    "                                                                             feature_column_dict[\n",
    "                                                                                 'history_FUFEI_discrete'],\n",
    "                                                                             discrete_embedding_dim)\n",
    "        # MLP  连续embedding\n",
    "        # category_feature_num_list = category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_continue'])\n",
    "        self.user_pay_history_QOE_continue_embedding = continuous_embedding(\n",
    "            category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_continue']),\n",
    "            continue_embedding_dim)\n",
    "        self.user_pay_history_CHONGHE_continue_embedding = continuous_embedding(\n",
    "            category_feature_num(feature_category_num_dict, feature_column_dict['history_CHONGHE_continue']),\n",
    "            continue_embedding_dim)\n",
    "        self.user_pay_history_FUFEI_continue_embedding = continuous_embedding(\n",
    "            category_feature_num(feature_category_num_dict, feature_column_dict['history_FUFEI_continue']),\n",
    "            continue_embedding_dim)\n",
    "\n",
    "    def forward(self, batch_feature_tensor_pay_QOE_discrete, batch_feature_tensor_pay_CHONGHE_discrete,\n",
    "                batch_feature_tensor_pay_FUFEI_discrete, batch_feature_tensor_pay_QOE_continue,\n",
    "                batch_feature_tensor_pay_CHONGHE_continue, batch_feature_tensor_pay_FUFEI_continue):\n",
    "        # user_history Embedding\n",
    "        # user_history_continue_features_embedding 得到(batch, 1, continue_feature_num, continue_embedding_dim)\n",
    "        # user_history_discrete_features_embedding 得到(batch, 1, discrete_feature_num, discrete_embedding_dim)\n",
    "        # history中有三种：QOE/CHONGHE/FUFEI,将其分别转化为embedding然后合并\n",
    "        # embedding的数据要求输入是整数类型 因此转为int，输入数据得是从0开始的索引后的数据，因此mask后得到-1以及在输入时得到了从0开始的索引后值，\n",
    "        # 现在所有discrete数据输入时+1，即 batch_feature_tensor_pay_QOE_discrete[:, :, i]+1 \n",
    "        # for i in range(batch_feature_tensor_pay_QOE_discrete.shape[2]):\n",
    "        #     print(i,batch_feature_tensor_pay_QOE_discrete.shape[2],batch_feature_tensor_pay_QOE_discrete[:, :, i]+1,self.user_pay_history_QOE_discrete_embeddings[i].num_embeddings )\n",
    "        batch_feature_tensor_pay_QOE_discrete = batch_feature_tensor_pay_QOE_discrete.int()\n",
    "        batch_feature_tensor_pay_CHONGHE_discrete = batch_feature_tensor_pay_CHONGHE_discrete.int()\n",
    "        batch_feature_tensor_pay_FUFEI_discrete = batch_feature_tensor_pay_FUFEI_discrete.int()\n",
    "\n",
    "        user_history_pay_QOE_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_pay_QOE_discrete[:, :, i] + 1) for i, embedding_layer in\n",
    "             enumerate(self.user_pay_history_QOE_discrete_embeddings)], dim=-2)\n",
    "        user_history_pay_QOE_continue_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_pay_QOE_continue[:, :, i].unsqueeze(-1).float()) for\n",
    "             i, embedding_layer in\n",
    "             enumerate(self.user_pay_history_QOE_continue_embedding)], dim=-2)\n",
    "        user_history_pay_QOE_vec = torch.cat(\n",
    "            [user_history_pay_QOE_discrete_column_discrete_features_embedding,\n",
    "             user_history_pay_QOE_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "\n",
    "        user_history_pay_CHONGHE_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_pay_CHONGHE_discrete[:, :, i] + 1) for i, embedding_layer in\n",
    "             enumerate(self.user_pay_history_CHONGHE_discrete_embeddings)], dim=-2)\n",
    "        user_history_pay_CHONGHE_continue_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_pay_CHONGHE_continue[:, :, i].unsqueeze(2).float()) for\n",
    "             i, embedding_layer in\n",
    "             enumerate(self.user_pay_history_CHONGHE_continue_embedding)], dim=-2)\n",
    "        user_history_pay_CHONGHE_vec = torch.cat(\n",
    "            [user_history_pay_CHONGHE_discrete_column_discrete_features_embedding,\n",
    "             user_history_pay_CHONGHE_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "\n",
    "        user_history_pay_FUFEI_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_pay_FUFEI_discrete[:, :, i] + 1) for i, embedding_layer in\n",
    "             enumerate(self.user_pay_history_FUFEI_discrete_embeddings)], dim=-2)\n",
    "        user_history_pay_FUFEI_continue_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_pay_FUFEI_continue[:, :, i].unsqueeze(2).float()) for\n",
    "             i, embedding_layer in\n",
    "             enumerate(self.user_pay_history_FUFEI_continue_embedding)], dim=-2)\n",
    "        user_history_pay_FUFEI_vec = torch.cat(\n",
    "            [user_history_pay_FUFEI_discrete_column_discrete_features_embedding,\n",
    "             user_history_pay_FUFEI_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "        # print(user_history_pay_FUFEI_discrete_column_discrete_features_embedding.shape,user_history_pay_FUFEI_continue_column_discrete_features_embedding.shape)\n",
    "\n",
    "        return user_history_pay_QOE_vec, user_history_pay_CHONGHE_vec, user_history_pay_FUFEI_vec\n",
    "\n",
    "\n",
    "# target_feature\n",
    "class TargetEmbedding(nn.Module):\n",
    "    def __init__(self, continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict):\n",
    "        super(TargetEmbedding, self).__init__()\n",
    "        # 连续特征  与付费、非付费共享一套特征\n",
    "        # 离散特征  与付费、非付费共享一套特征\n",
    "        self.feature_category_num_dict = feature_category_num_dict\n",
    "        # 离散embedding\n",
    "        self.target_QOE_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,\n",
    "                                                                 feature_column_dict['history_QOE_discrete'],\n",
    "                                                                 discrete_embedding_dim)\n",
    "        self.target_CHONGHE_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,\n",
    "                                                                     feature_column_dict['history_CHONGHE_discrete'],\n",
    "                                                                     discrete_embedding_dim)\n",
    "        self.target_FUFEI_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,\n",
    "                                                                   feature_column_dict['history_FUFEI_discrete'],\n",
    "                                                                   discrete_embedding_dim)\n",
    "        # MLP  连续embedding\n",
    "        self.target_QOE_continue_embedding = continuous_embedding(\n",
    "            category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_continue']),\n",
    "            continue_embedding_dim)\n",
    "        self.target_CHONGHE_continue_embedding = continuous_embedding(\n",
    "            category_feature_num(feature_category_num_dict, feature_column_dict['history_CHONGHE_continue']),\n",
    "            continue_embedding_dim)\n",
    "        self.target_FUFEI_continue_embedding = continuous_embedding(\n",
    "            category_feature_num(feature_category_num_dict, feature_column_dict['history_FUFEI_continue']),\n",
    "            continue_embedding_dim)\n",
    "\n",
    "    def forward(self, batch_feature_tensor_target_QOE_discrete, batch_feature_tensor_target_CHONGHE_discrete,\n",
    "                batch_feature_tensor_target_FUFEI_discrete, batch_feature_tensor_target_QOE_continue,\n",
    "                batch_feature_tensor_target_CHONGHE_continue, batch_feature_tensor_target_FUFEI_continue):\n",
    "        # target Embedding\n",
    "        # target_continue_features_embedding 得到(batch, 1, continue_feature_num, continue_embedding_dim)\n",
    "        # target_discrete_features_embedding 得到(batch, 1, discrete_feature_num, discrete_embedding_dim)\n",
    "        # 有三种：QOE/CHONGHE/FUFEI,将其分别转化为embedding然后合并\n",
    "        batch_feature_tensor_target_QOE_discrete = batch_feature_tensor_target_QOE_discrete.int()\n",
    "        batch_feature_tensor_target_CHONGHE_discrete = batch_feature_tensor_target_CHONGHE_discrete.int()\n",
    "        batch_feature_tensor_target_FUFEI_discrete = batch_feature_tensor_target_FUFEI_discrete.int()\n",
    "        target_QOE_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_target_QOE_discrete[:, :, i] + 1) for i, embedding_layer in\n",
    "             enumerate(self.target_QOE_discrete_embeddings)], dim=-2)\n",
    "        target_QOE_continue_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_target_QOE_continue[:, :, i].unsqueeze(2).float()) for\n",
    "             i, embedding_layer in\n",
    "             enumerate(self.target_QOE_continue_embedding)], dim=-2)\n",
    "        target_QOE_vec = torch.cat(\n",
    "            [target_QOE_discrete_column_discrete_features_embedding,\n",
    "             target_QOE_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "\n",
    "        target_CHONGHE_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_target_CHONGHE_discrete[:, :, i] + 1) for i, embedding_layer in\n",
    "             enumerate(self.target_CHONGHE_discrete_embeddings)], dim=-2)\n",
    "        target_CHONGHE_continue_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_target_CHONGHE_continue[:, :, i].unsqueeze(2).float()) for\n",
    "             i, embedding_layer in\n",
    "             enumerate(self.target_CHONGHE_continue_embedding)], dim=-2)\n",
    "        target_CHONGHE_vec = torch.cat(\n",
    "            [target_CHONGHE_discrete_column_discrete_features_embedding,\n",
    "             target_CHONGHE_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "\n",
    "        target_FUFEI_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_target_FUFEI_discrete[:, :, i] + 1) for i, embedding_layer in\n",
    "             enumerate(self.target_FUFEI_discrete_embeddings)], dim=-2)\n",
    "        target_FUFEI_continue_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_target_FUFEI_continue[:, :, i].unsqueeze(2).float()) for\n",
    "             i, embedding_layer in\n",
    "             enumerate(self.target_FUFEI_continue_embedding)], dim=-2)\n",
    "        target_FUFEI_vec = torch.cat(\n",
    "            [target_FUFEI_discrete_column_discrete_features_embedding,\n",
    "             target_FUFEI_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "\n",
    "        return target_QOE_vec, target_CHONGHE_vec, target_FUFEI_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53d8814f-4dd7-4f2f-a6c0-e9af13389f7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T08:36:45.122619Z",
     "start_time": "2024-09-04T08:36:45.041765Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5.Attention层\n",
    "\n",
    "\n",
    "# 用户历史embedding 多头+SE  (batch, history, feature_num, feature_dim)->(batch, 1，feature_dim)\n",
    "class HistoryDimScalingLayer(nn.Module):\n",
    "    def __init__(self, num_heads, feature_dim, feature_category_num_dict, max_history_len):\n",
    "        super(HistoryDimScalingLayer, self).__init__()\n",
    "        # 多头注意力\n",
    "        self.multi_head_attention = MultiHeadSelfAttention(num_heads, feature_dim, max_history_len)\n",
    "        # SE注意力\n",
    "        self.se_attention_QOE = SELayer(\n",
    "            len(category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_continue'])) + len(\n",
    "                category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_discrete'])))\n",
    "        self.se_attention_CHONGHE = SELayer(\n",
    "            len(category_feature_num(feature_category_num_dict, feature_column_dict['history_CHONGHE_continue'])) + len(\n",
    "                category_feature_num(feature_category_num_dict, feature_column_dict['history_CHONGHE_discrete_add_D'])))\n",
    "        self.se_attention_FUFEI = SELayer(\n",
    "            len(category_feature_num(feature_category_num_dict, feature_column_dict['history_FUFEI_continue'])) + len(\n",
    "                category_feature_num(feature_category_num_dict, feature_column_dict['history_FUFEI_discrete'])))\n",
    "\n",
    "    def forward(self, user_history_QOE_vec, user_history_CHONGHE_vec, user_history_FUFEI_vec, pay_QOE_mask=None,\n",
    "                pay_CHONGHE_mask=None, pay_FUFEI_mask=None):\n",
    "        # (batch, history, feature_num, feature_dim) ->多头 ->(batch, feature_num, feature_dim)->转置->(batch, feature_dim, feature_num) ->SE->特征权重->(batch, feature_dim, feature_num) ->转置-> 加权->(batch, 1，feature_dim)\n",
    "        # 多头注意力  例(batch, history, 20, 200) ->多头 ->(batch, 20, 200)\n",
    "        # print('user_history_QOE_vec',user_history_QOE_vec.shape,pay_QOE_mask.shape)\n",
    "        # ********多头注意力前转化************\n",
    "        # 二、三维度互换  变为(batch, feature_num, history, 200)\n",
    "        user_history_QOE_vec = user_history_QOE_vec.permute(0, 2, 1, 3)\n",
    "        user_history_CHONGHE_vec = user_history_CHONGHE_vec.permute(0, 2, 1, 3)\n",
    "        user_history_FUFEI_vec = user_history_FUFEI_vec.permute(0, 2, 1, 3)\n",
    "        # 记录特征数\n",
    "        user_history_QOE_temp_dim = user_history_QOE_vec.shape[1]\n",
    "        user_history_CHONGHE_temp_dim = user_history_CHONGHE_vec.shape[1]\n",
    "        user_history_FUFEI_temp_dim = user_history_FUFEI_vec.shape[1]\n",
    "        #（样本数*特征数,历史数，200）\n",
    "        user_history_QOE_vec = user_history_QOE_vec.reshape(-1, max_history_len, feature_dim)\n",
    "        user_history_CHONGHE_vec = user_history_CHONGHE_vec.reshape(-1, max_history_len, feature_dim)\n",
    "        user_history_FUFEI_vec = user_history_FUFEI_vec.reshape(-1, max_history_len, feature_dim)\n",
    "        #(样本数*特征数，200）\n",
    "        mutli_QOE_weight, multi_user_history_QOE_vec, _ = self.multi_head_attention(user_history_QOE_vec,\n",
    "                                                                                    mask=pay_QOE_mask)\n",
    "        mutli_CHONGHE_weight, multi_user_history_CHONGHE_vec, _ = self.multi_head_attention(user_history_CHONGHE_vec,\n",
    "                                                                                            mask=pay_CHONGHE_mask)\n",
    "        mutli_FUFEI_weight, multi_user_history_FUFEI_vec, _ = self.multi_head_attention(user_history_FUFEI_vec,\n",
    "                                                                                        mask=pay_FUFEI_mask)\n",
    "        #(样本数,特征数，200）\n",
    "        multi_user_history_QOE_vec = multi_user_history_QOE_vec.view(-1, user_history_QOE_temp_dim, feature_dim)\n",
    "        multi_user_history_CHONGHE_vec = multi_user_history_CHONGHE_vec.view(-1, user_history_CHONGHE_temp_dim,\n",
    "                                                                             feature_dim)\n",
    "        multi_user_history_FUFEI_vec = multi_user_history_FUFEI_vec.view(-1, user_history_FUFEI_temp_dim, feature_dim)\n",
    "        # print('multi_user_history_QOE_vec',multi_user_history_QOE_vec.shape) #,multi_user_history_QOE_vec[0,0,:])\n",
    "\n",
    "        # 去掉第二维  (batch, 1, 20, 200)->(batch, 20, 200)\n",
    "        # multi_user_history_QOE_vec = multi_user_history_QOE_vec.squeeze(dim=1)\n",
    "        # multi_user_history_CHONGHE_vec = multi_user_history_CHONGHE_vec.squeeze(dim=1)\n",
    "        # multi_user_history_FUFEI_vec= multi_user_history_FUFEI_vec.squeeze(dim=1)\n",
    "        # 调整维度 (batch, 20, 200)->(batch,20,200,1)  (batch,feature_num.embedding_dim,1)\n",
    "        multi_user_history_QOE_vec = multi_user_history_QOE_vec.unsqueeze(-1)\n",
    "        multi_user_history_CHONGHE_vec = multi_user_history_CHONGHE_vec.unsqueeze(-1)\n",
    "        multi_user_history_FUFEI_vec = multi_user_history_FUFEI_vec.unsqueeze(-1)\n",
    "        # 转置 交换最后两个维度 (feature_num 和 embedding_dim)\n",
    "        # multi_user_history_QOE_vec = torch.transpose(multi_user_history_QOE_vec, 1, 2)\n",
    "        # multi_user_history_CHONGHE_vec = torch.transpose(multi_user_history_CHONGHE_vec, 1, 2)\n",
    "        # multi_user_history_FUFEI_vec = torch.transpose(multi_user_history_FUFEI_vec, 1, 2)\n",
    "\n",
    "        # SE注意力  (batch,feature_num,feature_dim,1) ->SE->特征权重->(batch,feature_num,feature_dim,1)->去除最后一列-> 加权->(batch, 1，feature_dim)\n",
    "        se_QOE_weight, se_user_history_QOE_vec, _ = self.se_attention_QOE(multi_user_history_QOE_vec)\n",
    "        se_CHONGHE_weight, se_user_history_CHONGHE_vec, _ = self.se_attention_CHONGHE(multi_user_history_CHONGHE_vec)\n",
    "        se_FUFEI_weight, se_user_history_FUFEI_vec, _ = self.se_attention_FUFEI(multi_user_history_FUFEI_vec)\n",
    "\n",
    "        HistoryDimScaling_Weight_Result = {\n",
    "            'mutli_QOE_weight': mutli_QOE_weight,\n",
    "            'mutli_CHONGHE_weight': mutli_CHONGHE_weight,\n",
    "            'mutli_FUFEI_weight': mutli_FUFEI_weight,\n",
    "            'se_QOE_weight': se_QOE_weight,\n",
    "            'se_CHONGHE_weight': se_CHONGHE_weight,\n",
    "            'se_FUFEI_weight': se_FUFEI_weight\n",
    "        }\n",
    "        return HistoryDimScaling_Weight_Result, se_user_history_QOE_vec, se_user_history_CHONGHE_vec, se_user_history_FUFEI_vec\n",
    "\n",
    "\n",
    "# 目标产品embedding SE  (batch, 1, feature_num, feature_dim)->(batch, 1，feature_dim)\n",
    "class TargetDimScalingLayer(nn.Module):\n",
    "    def __init__(self, feature_dim, feature_category_num_dict):\n",
    "        super(TargetDimScalingLayer, self).__init__()\n",
    "        # SE注意力\n",
    "        self.se_attention_QOE = SELayer(\n",
    "            len(category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_continue'])) + len(\n",
    "                category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_discrete'])))\n",
    "        self.se_attention_CHONGHE = SELayer(\n",
    "            len(category_feature_num(feature_category_num_dict, feature_column_dict['history_CHONGHE_continue'])) + len(\n",
    "                category_feature_num(feature_category_num_dict, feature_column_dict['history_CHONGHE_discrete'])))\n",
    "        self.se_attention_FUFEI = SELayer(\n",
    "            len(category_feature_num(feature_category_num_dict, feature_column_dict['history_FUFEI_continue'])) + len(\n",
    "                category_feature_num(feature_category_num_dict, feature_column_dict['history_FUFEI_discrete'])))\n",
    "\n",
    "    def forward(self, target_QOE_vec, target_CHONGHE_vec, target_FUFEI_vec, mask=None):\n",
    "        # (batch, 1, feature_num, feature_dim) (batch, feature_num, feature_dim)->转置->(batch, feature_dim, feature_num) ->SE->特征权重->(batch, feature_dim, feature_num) ->转置-> 加权->(batch, 1，feature_dim)\n",
    "        # target_QOE_vec = target_QOE_vec.squeeze(1)  # 使用 squeeze 函数移除大小为 1 的维度\n",
    "        # target_CHONGHE_vec = target_CHONGHE_vec.squeeze(1)  # 使用 squeeze 函数移除大小为 1 的维度\n",
    "        # target_FUFEI_vec = target_FUFEI_vec.squeeze(1)  # 使用 squeeze 函数移除大小为 1 的维度\n",
    "        # 转置 交换最后两个维度 (20 和 200)\n",
    "        # target_QOE_vec = torch.transpose(target_QOE_vec, -2, -1)\n",
    "        # target_CHONGHE_vec = torch.transpose(target_CHONGHE_vec, -2, -1)\n",
    "        # target_FUFEI_vec = torch.transpose(target_FUFEI_vec, -2, -1)\n",
    "        # 去掉第二维  (batch, 1, 20, 200)->(batch, 20, 200)\n",
    "        target_QOE_vec = target_QOE_vec.squeeze(dim=1)\n",
    "        target_CHONGHE_vec = target_CHONGHE_vec.squeeze(dim=1)\n",
    "        target_FUFEI_vec = target_FUFEI_vec.squeeze(dim=1)\n",
    "        # 调整维度 (batch, 20, 200)->(batch,20,200,1)  (batch,feature_num.embedding_dim,1)\n",
    "        target_QOE_vec = target_QOE_vec.unsqueeze(-1)\n",
    "        target_CHONGHE_vec = target_CHONGHE_vec.unsqueeze(-1)\n",
    "        target_FUFEI_vec = target_FUFEI_vec.unsqueeze(-1)\n",
    "\n",
    "        # SE注意力  (batch, feature_dim, feature_num) ->SE->特征权重->(batch, feature_dim, feature_num)->转置-> 加权->(batch, 1，feature_dim)\n",
    "        # 结果为权重，合并后向量，合并前向量\n",
    "        se_QOE_weight, se_target_QOE_vec, _ = self.se_attention_QOE(target_QOE_vec)\n",
    "        se_CHONGHE_weight, se_target_CHONGHE_vec, _ = self.se_attention_CHONGHE(target_CHONGHE_vec)\n",
    "        se_FUFEI_weight, se_target_FUFEI_vec, _ = self.se_attention_FUFEI(target_FUFEI_vec)\n",
    "\n",
    "        TargetDimScaling_Weight_Result = {\n",
    "            'se_QOE_weight': se_QOE_weight,\n",
    "            'se_CHONGHE_weight': se_CHONGHE_weight,\n",
    "            'se_FUFEI_weight': se_FUFEI_weight\n",
    "        }\n",
    "        return TargetDimScaling_Weight_Result, se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec\n",
    "\n",
    "\n",
    "# 用户历史与目标记录的attention层\n",
    "class History_Target_AttentionLayer(nn.Module):\n",
    "    def __init__(self, num_heads, feature_dim):\n",
    "        super(History_Target_AttentionLayer, self).__init__()\n",
    "        self.target_history_pay_feature_pianhao_QOE_layer = MultiHeadHistory_TargetAttention(num_heads, feature_dim)\n",
    "        self.target_history_pay_feature_pianhao_CHONGHE_layer = MultiHeadHistory_TargetAttention(num_heads, feature_dim)\n",
    "        self.target_history_pay_feature_pianhao_FUFEI_layer = MultiHeadHistory_TargetAttention(num_heads, feature_dim)\n",
    "\n",
    "    def forward(self, se_user_history_pay_QOE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_FUFEI_vec,\n",
    "                se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec, pay_QOE_mask=None, pay_CHONGHE_mask=None,\n",
    "                pay_FUFEI_mask=None):\n",
    "        # 将QOE、CHONGHE、FUFEI分别做attention\n",
    "        # 对目标特征求对历史特征的偏好   (batch, 1，feature_dim)输出\n",
    "        target_history_pay_attention_QOE_weight, target_history_pay_attention_QOE_vec = self.target_history_pay_feature_pianhao_QOE_layer(\n",
    "            se_target_QOE_vec, se_user_history_pay_QOE_vec, se_user_history_pay_QOE_vec)\n",
    "        target_history_pay_attention_CHONGHE_weight, target_history_pay_attention_CHONGHE_vec = self.target_history_pay_feature_pianhao_CHONGHE_layer(\n",
    "            se_target_CHONGHE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_CHONGHE_vec)\n",
    "        target_history_pay_attention_FUFEI_weight, target_history_pay_attention_FUFEI_vec = self.target_history_pay_feature_pianhao_FUFEI_layer(\n",
    "            se_target_FUFEI_vec, se_user_history_pay_FUFEI_vec, se_user_history_pay_FUFEI_vec)\n",
    "        # CONCAT  (batch, 3，feature_dim)输出\n",
    "        target_history_pay_attention_vec = torch.cat((target_history_pay_attention_QOE_vec,\n",
    "                                                      target_history_pay_attention_CHONGHE_vec,\n",
    "                                                      target_history_pay_attention_FUFEI_vec), dim=1)\n",
    "        return target_history_pay_attention_vec, target_history_pay_attention_QOE_weight, target_history_pay_attention_CHONGHE_weight, target_history_pay_attention_FUFEI_weight\n",
    "\n",
    "# class History_Target_AttentionLayer(nn.Module):\n",
    "#     def __init__(self, num_heads, feature_dim):\n",
    "#         super(History_Target_AttentionLayer, self).__init__()\n",
    "#         self.target_history_pay_feature_pianhao_layer = MultiHeadHistory_TargetAttention(num_heads, feature_dim)\n",
    "#         self.target_history_not_pay_feature_pianhao_layer = MultiHeadHistory_TargetAttention(num_heads, feature_dim)\n",
    "\n",
    "#     def forward(self, se_user_history_pay_QOE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_FUFEI_vec, se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec, pay_QOE_mask=None, pay_CHONGHE_mask=None, pay_FUFEI_mask=None):\n",
    "#         # 将QOE、CHONGHE、FUFEI叠加，形成三个特征的向量  (batch, 1，feature_dim)->(batch, 3，feature_dim)\n",
    "#         user_history_pay_vec = torch.cat((se_user_history_pay_QOE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_FUFEI_vec), dim=1)\n",
    "#         target_vec = torch.cat((se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec), dim=1)\n",
    "\n",
    "#         # 对目标特征求对历史特征的偏好   (batch, 3，feature_dim)输出\n",
    "#         target_history_pay_attention_weight, target_history_pay_attention_vec = self.target_history_pay_feature_pianhao_layer(target_vec, user_history_pay_vec)\n",
    "\n",
    "#         return target_history_pay_attention_weight, target_history_pay_attention_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d9fff9-b6f3-457a-a203-48e5819897d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T05:36:17.688177Z",
     "start_time": "2024-09-04T05:36:17.277736Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6.整合模型\n",
    "\n",
    "\n",
    "# (batch,600)经过网络变成200 +(batch,featuer_user*200)经过网络变成200 -> (batch,200)\n",
    "# (batch,200) ->MLP ->(batch，1) ->sigmoid -> (batch,1)\n",
    "\n",
    "# 整合层\n",
    "class MatchingModel(nn.Module):\n",
    "    def __init__(self, feature_category_num_dict, feature_column_dict, continue_embedding_dim,\n",
    "                 discrete_embedding_dim, num_heads, feature_dim, max_history_len):\n",
    "        super(MatchingModel, self).__init__()\n",
    "        # Embedding层\n",
    "        # self.user_info_embedding_layer = UserInfoEmbedding(continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict)\n",
    "        self.user_history_pay_embedding_layer = UserPayHistoryEmbedding(continue_embedding_dim, discrete_embedding_dim,\n",
    "                                                                        feature_category_num_dict, feature_column_dict)\n",
    "        #print('embedding user_history结果')\n",
    "        self.target_embedding_layer = TargetEmbedding(continue_embedding_dim, discrete_embedding_dim,\n",
    "                                                      feature_category_num_dict, feature_column_dict)\n",
    "\n",
    "        # User History & Target Attention层\n",
    "        self.history_pay_attention_layer = HistoryDimScalingLayer(num_heads, feature_dim, feature_category_num_dict,\n",
    "                                                                  max_history_len)\n",
    "        self.target_attention_layer = TargetDimScalingLayer(feature_dim, feature_category_num_dict)\n",
    "\n",
    "        # Target History Attention层\n",
    "        self.target_history_attention_layer = History_Target_AttentionLayer(num_heads, feature_dim)\n",
    "\n",
    "        # 维度转换层\n",
    "        final_dim = 20\n",
    "        self.target_dim_change = dense_layer_noReLu(3 * feature_dim,\n",
    "                                                    final_dim)  # (batch,3,200)->(batch,600)->(batch,200)\n",
    "        # user_info_feature_num = feature_category_num_dict['user_info_continue'].shape[2] + feature_category_num_dict['user_info_discrete'].shape[2]\n",
    "        # self.user_info_dim_change = dense_layer(user_info_feature_num, 200)  # (batch,user_info_feature,200)->(batch,user_info_feature*200)->(batch,200)\n",
    "        # MLP\n",
    "        self.pay_vec_MLP_layer = dense_layer_noReLu(final_dim, 1)\n",
    "\n",
    "    def forward(self, batch_feature_tensor_pay_QOE_discrete, batch_feature_tensor_pay_CHONGHE_discrete,\n",
    "                batch_feature_tensor_pay_FUFEI_discrete,\n",
    "                batch_feature_tensor_pay_QOE_continue, batch_feature_tensor_pay_CHONGHE_continue,\n",
    "                batch_feature_tensor_pay_FUFEI_continue,\n",
    "                batch_feature_tensor_target_QOE_discrete, batch_feature_tensor_target_CHONGHE_discrete,\n",
    "                batch_feature_tensor_target_FUFEI_discrete,\n",
    "                batch_feature_tensor_target_QOE_continue, batch_feature_tensor_target_CHONGHE_continue,\n",
    "                batch_feature_tensor_target_FUFEI_continue,\n",
    "                batch_feature_tensor_pay_QOE_discrete_mask, batch_feature_tensor_pay_CHONGHE_discrete_mask,\n",
    "                batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "                batch_feature_tensor_pay_QOE_continue_mask, batch_feature_tensor_pay_CHONGHE_continue_mask,\n",
    "                batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "                label_tensor):\n",
    "        # Embedding层\n",
    "        user_history_pay_QOE_vec, user_history_pay_CHONGHE_vec, user_history_pay_FUFEI_vec = self.user_history_pay_embedding_layer(\n",
    "            batch_feature_tensor_pay_QOE_discrete, batch_feature_tensor_pay_CHONGHE_discrete,\n",
    "            batch_feature_tensor_pay_FUFEI_discrete, batch_feature_tensor_pay_QOE_continue,\n",
    "            batch_feature_tensor_pay_CHONGHE_continue, batch_feature_tensor_pay_FUFEI_continue)\n",
    "        target_QOE_vec, target_CHONGHE_vec, target_FUFEI_vec = self.target_embedding_layer(\n",
    "            batch_feature_tensor_target_QOE_discrete, batch_feature_tensor_target_CHONGHE_discrete,\n",
    "            batch_feature_tensor_target_FUFEI_discrete, batch_feature_tensor_target_QOE_continue,\n",
    "            batch_feature_tensor_target_CHONGHE_continue, batch_feature_tensor_target_FUFEI_continue)\n",
    "        # print('user_history_pay_FUFEI_vec size=',user_history_pay_FUFEI_vec.size())\n",
    "        # print('target_QOE_vec size=',target_QOE_vec.size())\n",
    "        # User History & Target Attention层\n",
    "        # 合并mask输入  \n",
    "        # print(\"Shape of mask tensor:\", batch_feature_tensor_pay_QOE_discrete_mask.shape,batch_feature_tensor_pay_QOE_continue_mask.shape)\n",
    "        pay_QOE_mask = torch.cat(\n",
    "            (batch_feature_tensor_pay_QOE_discrete_mask, batch_feature_tensor_pay_QOE_continue_mask), dim=2)\n",
    "        pay_CHONGHE_mask = torch.cat(\n",
    "            (batch_feature_tensor_pay_CHONGHE_discrete_mask, batch_feature_tensor_pay_CHONGHE_continue_mask), dim=2)\n",
    "        pay_FUFEI_mask = torch.cat(\n",
    "            (batch_feature_tensor_pay_FUFEI_discrete_mask, batch_feature_tensor_pay_FUFEI_continue_mask), dim=2)\n",
    "        HistoryDimScaling_Weight_Result, se_user_history_pay_QOE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_FUFEI_vec = self.history_pay_attention_layer(\n",
    "            user_history_pay_QOE_vec, user_history_pay_CHONGHE_vec, user_history_pay_FUFEI_vec,\n",
    "            pay_QOE_mask=pay_QOE_mask, pay_CHONGHE_mask=pay_CHONGHE_mask, pay_FUFEI_mask=pay_FUFEI_mask)\n",
    "        TargetDimScaling_Weight_Result, se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec = self.target_attention_layer(\n",
    "            target_QOE_vec, target_CHONGHE_vec, target_FUFEI_vec)\n",
    "        # print('se_user_history_pay_QOE_vec size=', se_user_history_pay_QOE_vec.shape)\n",
    "        # print('se_target_QOE_vec size=', se_target_QOE_vec.shape)\n",
    "        # Target with History Attention层\n",
    "        target_history_pay_attention_vec, target_history_pay_attention_QOE_weight, \\\n",
    "            target_history_pay_attention_CHONGHE_weight, target_history_pay_attention_FUFEI_weight = self.target_history_attention_layer(\n",
    "            se_user_history_pay_QOE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_FUFEI_vec,\n",
    "            se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec)\n",
    "        # print('target_history_pay_attention_vec size=', target_history_pay_attention_vec.shape)\n",
    "\n",
    "        # # 拼接user_info_vec与target_history_pay_attention_vec等\n",
    "        # user_info_vec = user_info_vec.squeeze(1)  # 使用 squeeze 函数移除大小为 1 的维度\n",
    "        # FUFEI:(batch,3,200)->(batch,3*200)经过网络->(batch,200) + uer_info:(batch,featuer_user*200)经过网络->(batch,200) 叠加后-> (batch,400)\n",
    "        # 维度转换 (batch,3,200)->(batch,feature*200)经过网络->(batch,200)\n",
    "        target_history_pay_attention_vec = target_history_pay_attention_vec.view(batch_size,\n",
    "                                                                                 -1)  # 将张量 x 重塑为 (batch, 3*200)  使用 -1 作为自动计算的维度       \n",
    "        target_history_pay_attention_vec = self.target_dim_change(target_history_pay_attention_vec)\n",
    "        # print('target_history_pay_attention_vec',target_history_pay_attention_vec)\n",
    "\n",
    "        # MLP\n",
    "        # (batch,200) ->MLP ->(batch，1) ->sigmoid -> (batch,1)\n",
    "        out_vec = self.pay_vec_MLP_layer(target_history_pay_attention_vec)\n",
    "        # print('out_vec size=',out_vec.shape,'out_vec:',out_vec)\n",
    "        # 使用softmax函数将logits转换为概率分布\n",
    "        # softmax_score = F.softmax(out_vec, dim=1)  # 在类别维度（dim=1）上应用softmax\n",
    "        sigmoid_score = torch.sigmoid(out_vec)  # 在类别维度（dim=1）上应用softmax\n",
    "        # sigmoid_score = out_vec  # 在类别维度（dim=1）上应用softmax\n",
    "        softmax_score = torch.softmax(out_vec, dim=1)\n",
    "        # print('softmax_score size=',softmax_score.shape,'score:',softmax_score)\n",
    "        # print('sigmoid_score size=',sigmoid_score.shape,'score:',sigmoid_score)\n",
    "        print(sigmoid_score)\n",
    "        return softmax_score, sigmoid_score, HistoryDimScaling_Weight_Result, TargetDimScaling_Weight_Result, target_history_pay_attention_QOE_weight, target_history_pay_attention_CHONGHE_weight, target_history_pay_attention_FUFEI_weight\n",
    "\n",
    "\n",
    "# 损失函数\n",
    "class LossFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossFunction, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target_label):\n",
    "        # pred是未经处理过的原值，target_label是0、1标签\n",
    "        # 计算第一个任务的二元交叉熵损失\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, target_label, reduction='none')\n",
    "        return loss\n",
    "\n",
    "\n",
    "# 自动评估阈值，计算ACC 、 Precision 等评估指标\n",
    "def evaluate(y_true, y_pred, digits=4, cutoff='auto'):\n",
    "    '''\n",
    "    Args:\n",
    "        y_true: list, labels, y_pred: list, predictions, digits: The number of decimals to use when rounding the number. Default is 4（保留小数后几位）\n",
    "        cutoff: float or 'auto'\n",
    "    Returns:\n",
    "        evaluation: dict\n",
    "    '''\n",
    "    # 根据预测概率值y_pred计算最佳的切分阈值\n",
    "    if cutoff == 'auto':\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "        youden = tpr - fpr\n",
    "        cutoff = thresholds[np.argmax(youden)]\n",
    "    y_pred_t = [1 if i > cutoff else 0 for i in y_pred]\n",
    "\n",
    "    evaluation = OrderedDict()\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_t).ravel()\n",
    "    evaluation['auc'] = round(roc_auc_score(y_true, y_pred), digits)\n",
    "    evaluation['acc'] = round(accuracy_score(y_true, y_pred_t), digits)\n",
    "    evaluation['recall'] = round(recall_score(y_true, y_pred_t), digits)\n",
    "    evaluation['precision'] = round(precision_score(y_true, y_pred_t), digits)\n",
    "    evaluation['specificity'] = round(tn / (tn + fp), digits)\n",
    "    evaluation['F1'] = round(f1_score(y_true, y_pred_t), digits)\n",
    "    evaluation['cutoff'] = cutoff\n",
    "\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "# 输出 Target History 的对特征的注意力得分\n",
    "def OutputMutliAttentionScore(attention_weights):\n",
    "    # 将注意力矩阵 reshape 成 (batch_size * head_num, feature_num, head_dim) 的形状\n",
    "    batch_size, feature_num, feature_num, head_dim = attention_weights.shape\n",
    "    attention_weights = attention_weights.view(-1, feature_num, head_dim)\n",
    "    # 定义全连接层和激活函数\n",
    "    fc_layer = nn.Linear(head_dim, 1).to(attention_weights.device)\n",
    "    activation = nn.Sigmoid()\n",
    "    # 将注意力矩阵输入全连接层\n",
    "    output = fc_layer(attention_weights)\n",
    "    # 应用激活函数\n",
    "    output = activation(output)\n",
    "    # 将输出 reshape 成最终形状 (batch_size, feature_num, 1, 1)\n",
    "    final_output = output.view(-1, feature_num, 1, 1)\n",
    "    return final_output\n",
    "\n",
    "\n",
    "# 输出权重结果到文件夹 首先要压缩维度到特征上，然后根据特征名列表输出\n",
    "# tensor_dict_idx = ['pay_QOE_continue','pay_QOE_discrete','pay_CHONGHE_continue','pay_CHONGHE_discrete','pay_FUFEI_continue','pay_FUFEI_discrete','target_QOE_continue','target_QOE_discrete','target_CHONGHE_continue','target_CHONGHE_discrete','target_FUFEI_continue','target_FUFEI_discrete']\n",
    "def WeightResult(HistoryDimScaling_Weight_Result, TargetDimScaling_Weight_Result,\n",
    "                 target_history_pay_attention_QOE_weight,\n",
    "                 target_history_pay_attention_CHONGHE_weight, target_history_pay_attention_FUFEI_weight):\n",
    "    # SE attention  (batch,feature_num,1,1)\n",
    "    se_user_pay_QOE_weight = HistoryDimScaling_Weight_Result['se_QOE_weight']\n",
    "    se_user_pay_CHONGHE_weight = HistoryDimScaling_Weight_Result['se_CHONGHE_weight']\n",
    "    se_user_pay_FUFEI_weight = HistoryDimScaling_Weight_Result['se_FUFEI_weight']\n",
    "    se_target_QOE_weight = TargetDimScaling_Weight_Result['se_QOE_weight']\n",
    "    se_target_CHONGHE_weight = TargetDimScaling_Weight_Result['se_CHONGHE_weight']\n",
    "    se_target_FUFEI_weight = TargetDimScaling_Weight_Result['se_FUFEI_weight']\n",
    "    # Target History Attention  得到(batch,feature_num,1,1)\n",
    "    # print('target_history_pay_attention_QOE_weight',target_history_pay_attention_QOE_weight.shape)\n",
    "    target_history_pay_attention_QOE_weight = OutputMutliAttentionScore(target_history_pay_attention_QOE_weight)\n",
    "    target_history_pay_attention_CHONGHE_weight = OutputMutliAttentionScore(target_history_pay_attention_CHONGHE_weight)\n",
    "    target_history_pay_attention_FUFEI_weight = OutputMutliAttentionScore(target_history_pay_attention_FUFEI_weight)\n",
    "    # 在batch维度上取平均，保持维度 得到(1,feature_num,1,1) 再用.squeeze()去掉为1的维度\n",
    "    se_user_pay_QOE_weight = se_user_pay_QOE_weight.mean(dim=0, keepdim=True).squeeze()\n",
    "    se_user_pay_CHONGHE_weight = se_user_pay_CHONGHE_weight.mean(dim=0, keepdim=True).squeeze()\n",
    "    se_user_pay_FUFEI_weight = se_user_pay_FUFEI_weight.mean(dim=0, keepdim=True).squeeze()\n",
    "    se_target_QOE_weight = se_target_QOE_weight.mean(dim=0, keepdim=True).squeeze()\n",
    "    se_target_CHONGHE_weight = se_target_CHONGHE_weight.mean(dim=0, keepdim=True).squeeze()\n",
    "    se_target_FUFEI_weight = se_target_FUFEI_weight.mean(dim=0, keepdim=True).squeeze()\n",
    "    target_history_pay_attention_QOE_weight = target_history_pay_attention_QOE_weight.mean(dim=0,\n",
    "                                                                                           keepdim=True).squeeze()\n",
    "    target_history_pay_attention_CHONGHE_weight = target_history_pay_attention_CHONGHE_weight.mean(dim=0,\n",
    "                                                                                                   keepdim=True).squeeze()\n",
    "    target_history_pay_attention_FUFEI_weight = target_history_pay_attention_FUFEI_weight.mean(dim=0,\n",
    "                                                                                               keepdim=True).squeeze()\n",
    "\n",
    "    result = {'se_user_pay_QOE_weight': se_user_pay_QOE_weight.tolist(),\n",
    "              'se_user_pay_CHONGHE_weight': se_user_pay_CHONGHE_weight.tolist(),\n",
    "              'se_user_pay_FUFEI_weight': se_user_pay_FUFEI_weight.tolist(),\n",
    "              'se_target_QOE_weight': se_target_QOE_weight.tolist(),\n",
    "              'se_target_CHONGHE_weight': se_target_CHONGHE_weight.tolist(),\n",
    "              'se_target_FUFEI_weight': se_target_FUFEI_weight.tolist(),\n",
    "              'target_history_pay_attention_QOE_weight': target_history_pay_attention_QOE_weight.tolist(),\n",
    "              'target_history_pay_attention_CHONGHE_weight': target_history_pay_attention_CHONGHE_weight.tolist(),\n",
    "              'target_history_pay_attention_FUFEI_weight': target_history_pay_attention_FUFEI_weight.tolist()\n",
    "              }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a90faa8-237f-4578-9890-a187f8f11efa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:29:05.029601Z",
     "start_time": "2024-09-04T02:29:04.834401Z"
    }
   },
   "outputs": [],
   "source": [
    "# 创建大模型的实例 'drama_upuser_subscriptions_num,drama_sound_max_traffic_position_in_sound_avg,label1'\n",
    "# model = MatchingModel(feature_category_num_dict, feature_column_dict, continue_embedding_dim,\n",
    "#                  discrete_embedding_dim, num_heads, feature_dim, max_history_len)\n",
    "# print('模型创建完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf028181-1968-4486-b6ef-3a1d338888f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:29:05.221772Z",
     "start_time": "2024-09-04T02:29:05.074859Z"
    }
   },
   "outputs": [],
   "source": [
    "# 7.模型训练 Trainging\n",
    "\n",
    "def model_training(model, train_loader, val_loader, lossfunction, optimizer, EPOCH, device):\n",
    "    # 定义早停策略的参数\n",
    "    best_val_loss = float('inf')  # 初始化最佳验证损失为正无穷\n",
    "    patience = 1  # 容忍多少个epoch没有验证性能提升\n",
    "    early_stopping_counter = 0  # 初始化计数器\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        model.train()  # 设置模型为训练模式\n",
    "        total_classfier_loss = 0.0\n",
    "        total_loss = 0.0\n",
    "        train_time = 0\n",
    "        val_time = 0\n",
    "        for batch in train_loader:\n",
    "            batch = [data.to(device) for data in batch]\n",
    "            batch_feature_tensor_pay_QOE_discrete, batch_feature_tensor_pay_CHONGHE_discrete, batch_feature_tensor_pay_FUFEI_discrete, \\\n",
    "                batch_feature_tensor_pay_QOE_continue, batch_feature_tensor_pay_CHONGHE_continue, batch_feature_tensor_pay_FUFEI_continue, \\\n",
    "                batch_feature_tensor_target_QOE_discrete, batch_feature_tensor_target_CHONGHE_discrete, batch_feature_tensor_target_FUFEI_discrete, \\\n",
    "                batch_feature_tensor_target_QOE_continue, batch_feature_tensor_target_CHONGHE_continue, batch_feature_tensor_target_FUFEI_continue, \\\n",
    "                batch_feature_tensor_pay_QOE_discrete_mask, batch_feature_tensor_pay_CHONGHE_discrete_mask, batch_feature_tensor_pay_FUFEI_discrete_mask, \\\n",
    "                batch_feature_tensor_pay_QOE_continue_mask, batch_feature_tensor_pay_CHONGHE_continue_mask, batch_feature_tensor_pay_FUFEI_continue_mask, \\\n",
    "                train_label_tensor = batch\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer.zero_grad()\n",
    "            softmax_score, sigmoid_score, HistoryDimScaling_Weight_Result, TargetDimScaling_Weight_Result, \\\n",
    "                target_history_pay_attention_QOE_weight, target_history_pay_attention_CHONGHE_weight, \\\n",
    "                target_history_pay_attention_FUFEI_weight = model(batch_feature_tensor_pay_QOE_discrete,\n",
    "                                                                  batch_feature_tensor_pay_CHONGHE_discrete,\n",
    "                                                                  batch_feature_tensor_pay_FUFEI_discrete,\n",
    "                                                                  batch_feature_tensor_pay_QOE_continue,\n",
    "                                                                  batch_feature_tensor_pay_CHONGHE_continue,\n",
    "                                                                  batch_feature_tensor_pay_FUFEI_continue,\n",
    "                                                                  batch_feature_tensor_target_QOE_discrete,\n",
    "                                                                  batch_feature_tensor_target_CHONGHE_discrete,\n",
    "                                                                  batch_feature_tensor_target_FUFEI_discrete,\n",
    "                                                                  batch_feature_tensor_target_QOE_continue,\n",
    "                                                                  batch_feature_tensor_target_CHONGHE_continue,\n",
    "                                                                  batch_feature_tensor_target_FUFEI_continue,\n",
    "                                                                  batch_feature_tensor_pay_QOE_discrete_mask,\n",
    "                                                                  batch_feature_tensor_pay_CHONGHE_discrete_mask,\n",
    "                                                                  batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "                                                                  batch_feature_tensor_pay_QOE_continue_mask,\n",
    "                                                                  batch_feature_tensor_pay_CHONGHE_continue_mask,\n",
    "                                                                  batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "                                                                  train_label_tensor)\n",
    "\n",
    "            # weight_result_dict = WeightResult(HistoryDimScaling_Weight_Result, TargetDimScaling_Weight_Result, target_history_pay_attention_QOE_weight,\n",
    "            #            target_history_pay_attention_CHONGHE_weight,target_history_pay_attention_FUFEI_weight)\n",
    "            # weight_result_dict = {key: torch.tensor(value).cpu() for key, value in weight_result_dict.items()}\n",
    "            # print('weight_result_dict_se_user_pay_QOE_weight',weight_result_dict['se_user_pay_QOE_weight'])\n",
    "            # print('HistoryDimScaling_Weight_Result, TargetDimScaling_Weight_Result, target_history_pay_attention_weight',\n",
    "            #      HistoryDimScaling_Weight_Result['mutli_QOE_weight'].shape, TargetDimScaling_Weight_Result['se_QOE_weight'].shape, target_history_pay_attention_weight.shape)\n",
    "            # sigmoid\n",
    "            # print('sigmoid_score',sigmoid_score)\n",
    "            sigmoid_score = sigmoid_score[:, 0]  # (样本数，1)\n",
    "            train_label_tensor = train_label_tensor[:, 0].to(device)  # (样本数，1)\n",
    "            # train_label_tensor[train_label_tensor == 1] = 0\n",
    "            # train_label_tensor[train_label_tensor == 2] = 1\n",
    "            # train_label_tensor = torch.where(train_label_tensor == 1, torch.tensor(0).to(device), torch.tensor(1).to(device))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "            loss = lossfunction(sigmoid_score, train_label_tensor.float())\n",
    "            # softmax\n",
    "            # softmax_score = softmax_score[:, 0]  # (样本数，1)\n",
    "            # train_label_tensor = train_label_tensor[:, 0].to(device)  # (样本数，1)\n",
    "            # train_label_tensor = torch.where(train_label_tensor == 1, torch.tensor(0).to(device), torch.tensor(1).to(device))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "            # loss = lossfunction(softmax_score, train_label_tensor.float())\n",
    "            loss.to(device)\n",
    "\n",
    "            # loss回传检查\n",
    "            # for name, parms in model.named_parameters():\t\n",
    "            #     if parms.grad is not None:  # 检查梯度是否为None\n",
    "            #         grad_mean = torch.mean(parms.grad)  # 计算梯度的均值\n",
    "            #         print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '-->grad_mean: {:.4f}'.format(grad_mean))\n",
    "            #     else:\n",
    "            #         print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '-->grad_mean: None')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(\"=============更新之后===========\")\n",
    "            # for name, parms in model.named_parameters():\t\n",
    "            #     if parms.grad is not None:  # 检查梯度是否为None\n",
    "            #         grad_mean = torch.mean(parms.grad)  # 计算梯度的均值\n",
    "            #         print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '-->grad_mean: {:.4f}'.format(grad_mean))\n",
    "            #     else:\n",
    "            #         print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '-->grad_mean: None')\n",
    "            # print(optimizer)\n",
    "            # input(\"=====迭代结束=====\")\n",
    "\n",
    "            # 损失\n",
    "            total_loss += loss.item()\n",
    "            train_time += 1\n",
    "            print('||--训练：----------', train_time, '个batch运行时间：', datetime.datetime.now(), '-------------')\n",
    "        # 平均损失\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1},loss:{average_loss}\")\n",
    "\n",
    "            # 验证集评估\n",
    "            model.eval()  # 将模型切换为评估模式\n",
    "            with torch.no_grad():  # 在评估模式下不计算梯度\n",
    "                total_loss_val = 0.0\n",
    "                total_auc_val = 0.0\n",
    "                total_acc_val = 0\n",
    "                total_f1_val = 0\n",
    "                total_precision_val = 0\n",
    "                total_recall_val = 0\n",
    "                val_time = 0\n",
    "                for batch_val in val_loader:  # 假设你有一个名为 val_loader 的验证集数据加载器\n",
    "                    batch_val = [data.to(device) for data in batch_val]\n",
    "                    val_batch_feature_tensor_pay_QOE_discrete, val_batch_feature_tensor_pay_CHONGHE_discrete, val_batch_feature_tensor_pay_FUFEI_discrete, \\\n",
    "                        val_batch_feature_tensor_pay_QOE_continue, val_batch_feature_tensor_pay_CHONGHE_continue, val_batch_feature_tensor_pay_FUFEI_continue, \\\n",
    "                        val_batch_feature_tensor_target_QOE_discrete, val_batch_feature_tensor_target_CHONGHE_discrete, val_batch_feature_tensor_target_FUFEI_discrete, \\\n",
    "                        val_batch_feature_tensor_target_QOE_continue, val_batch_feature_tensor_target_CHONGHE_continue, val_batch_feature_tensor_target_FUFEI_continue, \\\n",
    "                        val_batch_feature_tensor_pay_QOE_discrete_mask, val_batch_feature_tensor_pay_CHONGHE_discrete_mask, val_batch_feature_tensor_pay_FUFEI_discrete_mask, \\\n",
    "                        val_batch_feature_tensor_pay_QOE_continue_mask, val_batch_feature_tensor_pay_CHONGHE_continue_mask, val_batch_feature_tensor_pay_FUFEI_continue_mask, \\\n",
    "                        val_label_tensor = batch_val\n",
    "                    softmax_score_val, sigmoid_score_val, HistoryDimScaling_Weight_Result_val, TargetDimScaling_Weight_Result_val, \\\n",
    "                        target_history_pay_attention_QOE_weight_val, target_history_pay_attention_CHONGHE_weight_val, \\\n",
    "                        target_history_pay_attention_FUFEI_weight_val = model(val_batch_feature_tensor_pay_QOE_discrete,\n",
    "                                                                              val_batch_feature_tensor_pay_CHONGHE_discrete,\n",
    "                                                                              val_batch_feature_tensor_pay_FUFEI_discrete,\n",
    "                                                                              val_batch_feature_tensor_pay_QOE_continue,\n",
    "                                                                              val_batch_feature_tensor_pay_CHONGHE_continue,\n",
    "                                                                              val_batch_feature_tensor_pay_FUFEI_continue,\n",
    "                                                                              val_batch_feature_tensor_target_QOE_discrete,\n",
    "                                                                              val_batch_feature_tensor_target_CHONGHE_discrete,\n",
    "                                                                              val_batch_feature_tensor_target_FUFEI_discrete,\n",
    "                                                                              val_batch_feature_tensor_target_QOE_continue,\n",
    "                                                                              val_batch_feature_tensor_target_CHONGHE_continue,\n",
    "                                                                              val_batch_feature_tensor_target_FUFEI_continue,\n",
    "                                                                              val_batch_feature_tensor_pay_QOE_discrete_mask,\n",
    "                                                                              val_batch_feature_tensor_pay_CHONGHE_discrete_mask,\n",
    "                                                                              val_batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "                                                                              val_batch_feature_tensor_pay_QOE_continue_mask,\n",
    "                                                                              val_batch_feature_tensor_pay_CHONGHE_continue_mask,\n",
    "                                                                              val_batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "                                                                              val_label_tensor)\n",
    "\n",
    "                    # sigmoid                   \n",
    "                    sigmoid_score_val = sigmoid_score_val[:, 0]  # (样本数，1)\n",
    "                    sigmoid_score_val = sigmoid_score_val.cpu()  # .detach()  # 转为CPU\n",
    "                    val_label_tensor = val_label_tensor[:, 0]  # (样本数，1)\n",
    "                    val_label_tensor = val_label_tensor.cpu()\n",
    "                    # val_label_tensor[val_label_tensor == 1] = 0\n",
    "                    # val_label_tensor[val_label_tensor == 2] = 1\n",
    "                    # val_label_tensor = torch.where(val_label_tensor == 1, torch.tensor(0), torch.tensor(1))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "                    loss_val = lossfunction(sigmoid_score_val, val_label_tensor.float())\n",
    "                    # softmax\n",
    "                    # softmax_score_val = softmax_score_val[:, 0]  # (样本数，1)\n",
    "                    # softmax_score_val = softmax_score_val.cpu()# .detach()  # 转为CPU\n",
    "                    # val_label_tensor = val_label_tensor[:, 0]  # (样本数，1)\n",
    "                    # val_label_tensor = val_label_tensor.cpu()\n",
    "                    # val_label_tensor = torch.where(val_label_tensor == 1, torch.tensor(0), torch.tensor(1))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "                    # loss_val = lossfunction(softmax_score_val, val_label_tensor.float())\n",
    "\n",
    "                    # 损失\n",
    "                    total_loss_val += loss_val.item()\n",
    "                    # 计算验证集上的精度\n",
    "                    # predicted_classes_val = (sigmoid_score_val > 0.5).long()\n",
    "                    # total_acc_val += (predicted_classes_val == val_label_tensor).sum().item() / len(val_label_tensor)\n",
    "                    # total_f1_val += f1_score(val_label_tensor, predicted_classes_val)\n",
    "                    # total_recall_val += recall_score(val_label_tensor, predicted_classes_val)\n",
    "                    # precision_val = ((predicted_classes_val == 1) & (val_label_tensor == 1)).sum().item() / (predicted_classes_val == 1).sum().item()\n",
    "                    # total_precision_val += precision_val\n",
    "                    # total_auc_val += roc_auc_score(val_label_tensor, softmax_score_val)\n",
    "                    evaluation = evaluate(val_label_tensor, sigmoid_score_val)\n",
    "                    total_acc_val += evaluation['acc']\n",
    "                    total_f1_val += evaluation['F1']\n",
    "                    total_recall_val += evaluation['recall']\n",
    "                    total_precision_val += evaluation['precision']\n",
    "                    total_auc_val += evaluation['auc']\n",
    "\n",
    "                    val_time += 1\n",
    "                    print('||--验证：----------', val_time, '个batch运行时间：', datetime.datetime.now(), '-------------')\n",
    "                # 平均损失\n",
    "                average_loss_val = total_loss_val / len(val_loader)\n",
    "                average_auc_val = total_auc_val / len(val_loader)\n",
    "                average_acc_val = total_acc_val / len(val_loader)\n",
    "                average_f1_val = total_f1_val / len(val_loader)\n",
    "                average_precision_val = total_precision_val / len(val_loader)\n",
    "                average_recall_val = total_recall_val / len(val_loader)\n",
    "                print(\n",
    "                    f\"Validation Loss: {average_loss_val},AUC: {average_auc_val},ACC:{average_acc_val},F1:{average_f1_val},Precision:{average_precision_val},Recall:{average_recall_val}\")\n",
    "\n",
    "                if average_loss_val < best_val_loss:\n",
    "                    best_val_loss = average_loss_val\n",
    "                    early_stopping_counter = 0\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "                if early_stopping_counter >= patience:\n",
    "                    print(f\"早停策略触发，停止训练在第 {epoch} 个epoch.\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cf0a32d-b61b-484f-a801-8c16e3d792be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T02:29:05.361982Z",
     "start_time": "2024-09-04T02:29:05.256811Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型测试 Test\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 在评估模式下不计算梯度\n",
    "        total_loss_test = 0.0\n",
    "        total_auc_test = 0.0\n",
    "        total_acc_test = 0\n",
    "        total_f1_test = 0\n",
    "        total_precision_test = 0\n",
    "        total_recall_test = 0\n",
    "        test_time = 0\n",
    "        results = []  # 用于保存结果的列表\n",
    "        for batch_test in test_loader:  # 假设你有一个名为 val_loader 的验证集数据加载器\n",
    "            batch_test = [data.to(device) for data in batch_test]\n",
    "            test_batch_feature_tensor_pay_QOE_discrete, test_batch_feature_tensor_pay_CHONGHE_discrete, test_batch_feature_tensor_pay_FUFEI_discrete, \\\n",
    "                test_batch_feature_tensor_pay_QOE_continue, test_batch_feature_tensor_pay_CHONGHE_continue, test_batch_feature_tensor_pay_FUFEI_continue, \\\n",
    "                test_batch_feature_tensor_target_QOE_discrete, test_batch_feature_tensor_target_CHONGHE_discrete, test_batch_feature_tensor_target_FUFEI_discrete, \\\n",
    "                test_batch_feature_tensor_target_QOE_continue, test_batch_feature_tensor_target_CHONGHE_continue, test_batch_feature_tensor_target_FUFEI_continue, \\\n",
    "                test_batch_feature_tensor_pay_QOE_discrete_mask, test_batch_feature_tensor_pay_CHONGHE_discrete_mask, test_batch_feature_tensor_pay_FUFEI_discrete_mask, \\\n",
    "                test_batch_feature_tensor_pay_QOE_continue_mask, test_batch_feature_tensor_pay_CHONGHE_continue_mask, test_batch_feature_tensor_pay_FUFEI_continue_mask, \\\n",
    "                test_label_tensor = batch_test\n",
    "            softmax_score_test, sigmoid_score_test, HistoryDimScaling_Weight_Result_test, TargetDimScaling_Weight_Result_test, \\\n",
    "                target_history_pay_attention_QOE_weight_test, target_history_pay_attention_CHONGHE_weight_test, \\\n",
    "                target_history_pay_attention_FUFEI_weight_test = model(test_batch_feature_tensor_pay_QOE_discrete,\n",
    "                                                                       test_batch_feature_tensor_pay_CHONGHE_discrete,\n",
    "                                                                       test_batch_feature_tensor_pay_FUFEI_discrete,\n",
    "                                                                       test_batch_feature_tensor_pay_QOE_continue,\n",
    "                                                                       test_batch_feature_tensor_pay_CHONGHE_continue,\n",
    "                                                                       test_batch_feature_tensor_pay_FUFEI_continue,\n",
    "                                                                       test_batch_feature_tensor_target_QOE_discrete,\n",
    "                                                                       test_batch_feature_tensor_target_CHONGHE_discrete,\n",
    "                                                                       test_batch_feature_tensor_target_FUFEI_discrete,\n",
    "                                                                       test_batch_feature_tensor_target_QOE_continue,\n",
    "                                                                       test_batch_feature_tensor_target_CHONGHE_continue,\n",
    "                                                                       test_batch_feature_tensor_target_FUFEI_continue,\n",
    "                                                                       test_batch_feature_tensor_pay_QOE_discrete_mask,\n",
    "                                                                       test_batch_feature_tensor_pay_CHONGHE_discrete_mask,\n",
    "                                                                       test_batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "                                                                       test_batch_feature_tensor_pay_QOE_continue_mask,\n",
    "                                                                       test_batch_feature_tensor_pay_CHONGHE_continue_mask,\n",
    "                                                                       test_batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "                                                                       test_label_tensor)\n",
    "            weight_result_dict = WeightResult(HistoryDimScaling_Weight_Result_test, TargetDimScaling_Weight_Result_test,\n",
    "                                              target_history_pay_attention_QOE_weight_test,\n",
    "                                              target_history_pay_attention_CHONGHE_weight_test,\n",
    "                                              target_history_pay_attention_FUFEI_weight_test)\n",
    "            weight_result_dict = {key: torch.tensor(value).cpu() for key, value in weight_result_dict.items()}\n",
    "            # sigmoid\n",
    "            sigmoid_score_test = sigmoid_score_test[:, 0]  # (样本数，1)\n",
    "            sigmoid_score_test = sigmoid_score_test.cpu()  #.detach()  # 转为CPU\n",
    "            test_label_tensor = test_label_tensor[:, 0]  # (样本数，1)\n",
    "            test_label_tensor = test_label_tensor.cpu()\n",
    "            # test_label_tensor[test_label_tensor == 1] = 0\n",
    "            # test_label_tensor[test_label_tensor == 2] = 1\n",
    "            # test_label_tensor = torch.where(test_label_tensor == 1, torch.tensor(0), torch.tensor(1))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "            loss_test = lossfunction(sigmoid_score_test, test_label_tensor.float())\n",
    "            # softmax\n",
    "            # softmax_score_test = softmax_score_test[:, 0]  # (样本数，1)\n",
    "            # softmax_score_test = softmax_score_test.cpu()#.detach()  # 转为CPU\n",
    "            # test_label_tensor = test_label_tensor[:, 0]  # (样本数，1)\n",
    "            # test_label_tensor = test_label_tensor.cpu()\n",
    "            # test_label_tensor = torch.where(test_label_tensor == 1, torch.tensor(0), torch.tensor(1))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "            # loss_test = lossfunction(softmax_score_test, test_label_tensor.float())\n",
    "\n",
    "            # 损失\n",
    "            total_loss_test += loss_test.item()\n",
    "            # 计算验证集上的精度\n",
    "            # predicted_classes_test = (sigmoid_score_test > 0.5).long()\n",
    "            # total_acc_test += (predicted_classes_test == test_label_tensor).sum().item() / len(test_label_tensor)\n",
    "            # total_f1_test += f1_score(test_label_tensor, predicted_classes_test)\n",
    "            # total_recall_test += recall_score(test_label_tensor, predicted_classes_test)\n",
    "            # precision_test = ((predicted_classes_test == 1) & (test_label_tensor == 1)).sum().item() / (predicted_classes_test == 1).sum().item()\n",
    "            # total_precision_test += precision_test\n",
    "            # total_auc_test += roc_auc_score(test_label_tensor, sigmoid_score_test)\n",
    "            evaluation = evaluate(test_label_tensor, sigmoid_score_test)\n",
    "            total_acc_test += evaluation['acc']\n",
    "            total_f1_test += evaluation['F1']\n",
    "            total_recall_test += evaluation['recall']\n",
    "            total_precision_test += evaluation['precision']\n",
    "            total_auc_test += evaluation['auc']\n",
    "\n",
    "            test_time += 1\n",
    "            print('||--测试：----------', test_time, '个batch运行时间：', datetime.datetime.now(), '-------------')\n",
    "        # 平均损失\n",
    "        average_loss_test = total_loss_test / len(test_loader)\n",
    "        average_auc_test = total_auc_test / len(test_loader)\n",
    "        average_acc_test = total_acc_test / len(test_loader)\n",
    "        average_f1_test = total_f1_test / len(test_loader)\n",
    "        average_precision_test = total_precision_test / len(test_loader)\n",
    "        average_recall_test = total_recall_test / len(test_loader)\n",
    "        print(\n",
    "            f\"Test Loss: {average_loss_test},AUC: {average_auc_test},ACC:{average_acc_test},F1:{average_f1_test},Precision:{average_precision_test},Recall:{average_recall_test}\")\n",
    "        return average_loss_test, average_auc_test, average_acc_test, average_f1_test, average_precision_test, average_recall_test, weight_result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ccf0921-8a05-4ee5-beda-d085cdd1e5a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T06:08:42.127205Z",
     "start_time": "2024-09-04T05:36:22.501979Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=:1\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "tensor([[0.5393],\n",
      "        [0.5415],\n",
      "        [0.5403],\n",
      "        [0.5397],\n",
      "        [0.5389],\n",
      "        [0.5403],\n",
      "        [0.5404],\n",
      "        [0.5411],\n",
      "        [0.5407],\n",
      "        [0.5408],\n",
      "        [0.5386],\n",
      "        [0.5411],\n",
      "        [0.5407],\n",
      "        [0.5411],\n",
      "        [0.5400],\n",
      "        [0.5411],\n",
      "        [0.5412],\n",
      "        [0.5408],\n",
      "        [0.5408],\n",
      "        [0.5402],\n",
      "        [0.5425],\n",
      "        [0.5414],\n",
      "        [0.5423],\n",
      "        [0.5396],\n",
      "        [0.5397],\n",
      "        [0.5411],\n",
      "        [0.5413],\n",
      "        [0.5421],\n",
      "        [0.5409],\n",
      "        [0.5421],\n",
      "        [0.5405],\n",
      "        [0.5423],\n",
      "        [0.5403],\n",
      "        [0.5404],\n",
      "        [0.5413],\n",
      "        [0.5411],\n",
      "        [0.5399],\n",
      "        [0.5424],\n",
      "        [0.5402],\n",
      "        [0.5411],\n",
      "        [0.5413],\n",
      "        [0.5399],\n",
      "        [0.5405],\n",
      "        [0.5402],\n",
      "        [0.5400],\n",
      "        [0.5410],\n",
      "        [0.5408],\n",
      "        [0.5408],\n",
      "        [0.5391],\n",
      "        [0.5410],\n",
      "        [0.5403],\n",
      "        [0.5406],\n",
      "        [0.5420],\n",
      "        [0.5412],\n",
      "        [0.5411],\n",
      "        [0.5402],\n",
      "        [0.5459],\n",
      "        [0.5410],\n",
      "        [0.5409],\n",
      "        [0.5412],\n",
      "        [0.5395],\n",
      "        [0.5412],\n",
      "        [0.5426],\n",
      "        [0.5389],\n",
      "        [0.5401],\n",
      "        [0.5394],\n",
      "        [0.5426],\n",
      "        [0.5413],\n",
      "        [0.5415],\n",
      "        [0.5396],\n",
      "        [0.5411],\n",
      "        [0.5410],\n",
      "        [0.5406],\n",
      "        [0.5404],\n",
      "        [0.5426],\n",
      "        [0.5402],\n",
      "        [0.5408],\n",
      "        [0.5404],\n",
      "        [0.5413],\n",
      "        [0.5411],\n",
      "        [0.5412],\n",
      "        [0.5407],\n",
      "        [0.5411],\n",
      "        [0.5411],\n",
      "        [0.5382],\n",
      "        [0.5402],\n",
      "        [0.5405],\n",
      "        [0.5411],\n",
      "        [0.5410],\n",
      "        [0.5408],\n",
      "        [0.5408],\n",
      "        [0.5407],\n",
      "        [0.5405],\n",
      "        [0.5406],\n",
      "        [0.5414],\n",
      "        [0.5383],\n",
      "        [0.5414],\n",
      "        [0.5404],\n",
      "        [0.5430],\n",
      "        [0.5410],\n",
      "        [0.5406],\n",
      "        [0.5417],\n",
      "        [0.5399],\n",
      "        [0.5409],\n",
      "        [0.5401],\n",
      "        [0.5410],\n",
      "        [0.5408],\n",
      "        [0.5391],\n",
      "        [0.5401],\n",
      "        [0.5405],\n",
      "        [0.5416],\n",
      "        [0.5414],\n",
      "        [0.5419],\n",
      "        [0.5403],\n",
      "        [0.5390],\n",
      "        [0.5403],\n",
      "        [0.5390],\n",
      "        [0.5419],\n",
      "        [0.5418],\n",
      "        [0.5407],\n",
      "        [0.5401],\n",
      "        [0.5411],\n",
      "        [0.5402],\n",
      "        [0.5411],\n",
      "        [0.5413],\n",
      "        [0.5401],\n",
      "        [0.5386],\n",
      "        [0.5424]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 1 个batch运行时间： 2024-09-17 16:28:04.942917 -------------\n",
      "tensor([[0.5298],\n",
      "        [0.5290],\n",
      "        [0.5303],\n",
      "        [0.5286],\n",
      "        [0.5304],\n",
      "        [0.5311],\n",
      "        [0.5288],\n",
      "        [0.5309],\n",
      "        [0.5295],\n",
      "        [0.5306],\n",
      "        [0.5300],\n",
      "        [0.5294],\n",
      "        [0.5299],\n",
      "        [0.5279],\n",
      "        [0.5287],\n",
      "        [0.5301],\n",
      "        [0.5296],\n",
      "        [0.5293],\n",
      "        [0.5277],\n",
      "        [0.5299],\n",
      "        [0.5309],\n",
      "        [0.5301],\n",
      "        [0.5278],\n",
      "        [0.5281],\n",
      "        [0.5293],\n",
      "        [0.5294],\n",
      "        [0.5296],\n",
      "        [0.5301],\n",
      "        [0.5284],\n",
      "        [0.5295],\n",
      "        [0.5293],\n",
      "        [0.5308],\n",
      "        [0.5302],\n",
      "        [0.5298],\n",
      "        [0.5286],\n",
      "        [0.5292],\n",
      "        [0.5293],\n",
      "        [0.5290],\n",
      "        [0.5305],\n",
      "        [0.5291],\n",
      "        [0.5299],\n",
      "        [0.5320],\n",
      "        [0.5277],\n",
      "        [0.5292],\n",
      "        [0.5283],\n",
      "        [0.5312],\n",
      "        [0.5281],\n",
      "        [0.5300],\n",
      "        [0.5298],\n",
      "        [0.5341],\n",
      "        [0.5294],\n",
      "        [0.5296],\n",
      "        [0.5295],\n",
      "        [0.5293],\n",
      "        [0.5290],\n",
      "        [0.5307],\n",
      "        [0.5286],\n",
      "        [0.5282],\n",
      "        [0.5286],\n",
      "        [0.5314],\n",
      "        [0.5296],\n",
      "        [0.5296],\n",
      "        [0.5280],\n",
      "        [0.5300],\n",
      "        [0.5304],\n",
      "        [0.5316],\n",
      "        [0.5291],\n",
      "        [0.5286],\n",
      "        [0.5306],\n",
      "        [0.5282],\n",
      "        [0.5321],\n",
      "        [0.5300],\n",
      "        [0.5291],\n",
      "        [0.5293],\n",
      "        [0.5296],\n",
      "        [0.5280],\n",
      "        [0.5288],\n",
      "        [0.5324],\n",
      "        [0.5298],\n",
      "        [0.5301],\n",
      "        [0.5299],\n",
      "        [0.5289],\n",
      "        [0.5277],\n",
      "        [0.5288],\n",
      "        [0.5284],\n",
      "        [0.5274],\n",
      "        [0.5306],\n",
      "        [0.5284],\n",
      "        [0.5284],\n",
      "        [0.5305],\n",
      "        [0.5300],\n",
      "        [0.5294],\n",
      "        [0.5287],\n",
      "        [0.5290],\n",
      "        [0.5306],\n",
      "        [0.5296],\n",
      "        [0.5293],\n",
      "        [0.5313],\n",
      "        [0.5293],\n",
      "        [0.5302],\n",
      "        [0.5284],\n",
      "        [0.5311],\n",
      "        [0.5297],\n",
      "        [0.5279],\n",
      "        [0.5297],\n",
      "        [0.5295],\n",
      "        [0.5290],\n",
      "        [0.5296],\n",
      "        [0.5297],\n",
      "        [0.5293],\n",
      "        [0.5299],\n",
      "        [0.5303],\n",
      "        [0.5291],\n",
      "        [0.5303],\n",
      "        [0.5296],\n",
      "        [0.5298],\n",
      "        [0.5279],\n",
      "        [0.5305],\n",
      "        [0.5303],\n",
      "        [0.5295],\n",
      "        [0.5303],\n",
      "        [0.5285],\n",
      "        [0.5300],\n",
      "        [0.5293],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5296],\n",
      "        [0.5299]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 2 个batch运行时间： 2024-09-17 16:28:10.663827 -------------\n",
      "tensor([[0.5073],\n",
      "        [0.5071],\n",
      "        [0.5061],\n",
      "        [0.5066],\n",
      "        [0.5064],\n",
      "        [0.5055],\n",
      "        [0.5082],\n",
      "        [0.5064],\n",
      "        [0.5071],\n",
      "        [0.5074],\n",
      "        [0.5081],\n",
      "        [0.5083],\n",
      "        [0.5082],\n",
      "        [0.5056],\n",
      "        [0.5064],\n",
      "        [0.5075],\n",
      "        [0.5090],\n",
      "        [0.5075],\n",
      "        [0.5095],\n",
      "        [0.5067],\n",
      "        [0.5072],\n",
      "        [0.5061],\n",
      "        [0.5085],\n",
      "        [0.5057],\n",
      "        [0.5072],\n",
      "        [0.5065],\n",
      "        [0.5068],\n",
      "        [0.5096],\n",
      "        [0.5061],\n",
      "        [0.5065],\n",
      "        [0.5080],\n",
      "        [0.5068],\n",
      "        [0.5074],\n",
      "        [0.5079],\n",
      "        [0.5069],\n",
      "        [0.5068],\n",
      "        [0.5079],\n",
      "        [0.5064],\n",
      "        [0.5066],\n",
      "        [0.5063],\n",
      "        [0.5082],\n",
      "        [0.5070],\n",
      "        [0.5061],\n",
      "        [0.5087],\n",
      "        [0.5056],\n",
      "        [0.5064],\n",
      "        [0.5090],\n",
      "        [0.5055],\n",
      "        [0.5057],\n",
      "        [0.5083],\n",
      "        [0.5064],\n",
      "        [0.5083],\n",
      "        [0.5064],\n",
      "        [0.5056],\n",
      "        [0.5059],\n",
      "        [0.5065],\n",
      "        [0.5070],\n",
      "        [0.5070],\n",
      "        [0.5078],\n",
      "        [0.5068],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5058],\n",
      "        [0.5058],\n",
      "        [0.5076],\n",
      "        [0.5071],\n",
      "        [0.5058],\n",
      "        [0.5069],\n",
      "        [0.5067],\n",
      "        [0.5074],\n",
      "        [0.5059],\n",
      "        [0.5083],\n",
      "        [0.5065],\n",
      "        [0.5076],\n",
      "        [0.5068],\n",
      "        [0.5066],\n",
      "        [0.5074],\n",
      "        [0.5076],\n",
      "        [0.5065],\n",
      "        [0.5080],\n",
      "        [0.5069],\n",
      "        [0.5060],\n",
      "        [0.5088],\n",
      "        [0.5102],\n",
      "        [0.5072],\n",
      "        [0.5060],\n",
      "        [0.5064],\n",
      "        [0.5063],\n",
      "        [0.5066],\n",
      "        [0.5065],\n",
      "        [0.5057],\n",
      "        [0.5067],\n",
      "        [0.5057],\n",
      "        [0.5088],\n",
      "        [0.5070],\n",
      "        [0.5075],\n",
      "        [0.5070],\n",
      "        [0.5070],\n",
      "        [0.5073],\n",
      "        [0.5065],\n",
      "        [0.5078],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5061],\n",
      "        [0.5067],\n",
      "        [0.5061],\n",
      "        [0.5058],\n",
      "        [0.5055],\n",
      "        [0.5070],\n",
      "        [0.5072],\n",
      "        [0.5069],\n",
      "        [0.5075],\n",
      "        [0.5073],\n",
      "        [0.5082],\n",
      "        [0.5066],\n",
      "        [0.5083],\n",
      "        [0.5070],\n",
      "        [0.5081],\n",
      "        [0.5062],\n",
      "        [0.5064],\n",
      "        [0.5066],\n",
      "        [0.5066],\n",
      "        [0.5057],\n",
      "        [0.5063],\n",
      "        [0.5069],\n",
      "        [0.5090],\n",
      "        [0.5083],\n",
      "        [0.5074]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 3 个batch运行时间： 2024-09-17 16:28:16.532008 -------------\n",
      "tensor([[0.4745],\n",
      "        [0.4758],\n",
      "        [0.4751],\n",
      "        [0.4746],\n",
      "        [0.4744],\n",
      "        [0.4754],\n",
      "        [0.4736],\n",
      "        [0.4746],\n",
      "        [0.4755],\n",
      "        [0.4784],\n",
      "        [0.4766],\n",
      "        [0.4743],\n",
      "        [0.4785],\n",
      "        [0.4750],\n",
      "        [0.4751],\n",
      "        [0.4761],\n",
      "        [0.4765],\n",
      "        [0.4742],\n",
      "        [0.4742],\n",
      "        [0.4773],\n",
      "        [0.4752],\n",
      "        [0.4752],\n",
      "        [0.4760],\n",
      "        [0.4746],\n",
      "        [0.4743],\n",
      "        [0.4762],\n",
      "        [0.4754],\n",
      "        [0.4751],\n",
      "        [0.4749],\n",
      "        [0.4759],\n",
      "        [0.4738],\n",
      "        [0.4755],\n",
      "        [0.4760],\n",
      "        [0.4769],\n",
      "        [0.4754],\n",
      "        [0.4757],\n",
      "        [0.4732],\n",
      "        [0.4775],\n",
      "        [0.4743],\n",
      "        [0.4761],\n",
      "        [0.4747],\n",
      "        [0.4741],\n",
      "        [0.4742],\n",
      "        [0.4754],\n",
      "        [0.4762],\n",
      "        [0.4737],\n",
      "        [0.4766],\n",
      "        [0.4732],\n",
      "        [0.4746],\n",
      "        [0.4740],\n",
      "        [0.4758],\n",
      "        [0.4751],\n",
      "        [0.4779],\n",
      "        [0.4737],\n",
      "        [0.4741],\n",
      "        [0.4746],\n",
      "        [0.4757],\n",
      "        [0.4746],\n",
      "        [0.4743],\n",
      "        [0.4756],\n",
      "        [0.4747],\n",
      "        [0.4770],\n",
      "        [0.4739],\n",
      "        [0.4755],\n",
      "        [0.4770],\n",
      "        [0.4752],\n",
      "        [0.4742],\n",
      "        [0.4768],\n",
      "        [0.4753],\n",
      "        [0.4746],\n",
      "        [0.4770],\n",
      "        [0.4756],\n",
      "        [0.4750],\n",
      "        [0.4751],\n",
      "        [0.4758],\n",
      "        [0.4779],\n",
      "        [0.4756],\n",
      "        [0.4752],\n",
      "        [0.4747],\n",
      "        [0.4760],\n",
      "        [0.4748],\n",
      "        [0.4755],\n",
      "        [0.4768],\n",
      "        [0.4736],\n",
      "        [0.4741],\n",
      "        [0.4743],\n",
      "        [0.4759],\n",
      "        [0.4751],\n",
      "        [0.4749],\n",
      "        [0.4762],\n",
      "        [0.4742],\n",
      "        [0.4758],\n",
      "        [0.4748],\n",
      "        [0.4747],\n",
      "        [0.4760],\n",
      "        [0.4772],\n",
      "        [0.4752],\n",
      "        [0.4733],\n",
      "        [0.4754],\n",
      "        [0.4750],\n",
      "        [0.4764],\n",
      "        [0.4755],\n",
      "        [0.4757],\n",
      "        [0.4721],\n",
      "        [0.4752],\n",
      "        [0.4771],\n",
      "        [0.4772],\n",
      "        [0.4759],\n",
      "        [0.4758],\n",
      "        [0.4768],\n",
      "        [0.4763],\n",
      "        [0.4768],\n",
      "        [0.4756],\n",
      "        [0.4734],\n",
      "        [0.4751],\n",
      "        [0.4738],\n",
      "        [0.4742],\n",
      "        [0.4748],\n",
      "        [0.4749],\n",
      "        [0.4758],\n",
      "        [0.4753],\n",
      "        [0.4755],\n",
      "        [0.4744],\n",
      "        [0.4772],\n",
      "        [0.4742],\n",
      "        [0.4759],\n",
      "        [0.4761],\n",
      "        [0.4770]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 4 个batch运行时间： 2024-09-17 16:28:22.058791 -------------\n",
      "tensor([[0.4381],\n",
      "        [0.4338],\n",
      "        [0.4359],\n",
      "        [0.4346],\n",
      "        [0.4358],\n",
      "        [0.4343],\n",
      "        [0.4340],\n",
      "        [0.4353],\n",
      "        [0.4369],\n",
      "        [0.4372],\n",
      "        [0.4350],\n",
      "        [0.4409],\n",
      "        [0.4364],\n",
      "        [0.4383],\n",
      "        [0.4357],\n",
      "        [0.4383],\n",
      "        [0.4342],\n",
      "        [0.4337],\n",
      "        [0.4342],\n",
      "        [0.4351],\n",
      "        [0.4347],\n",
      "        [0.4345],\n",
      "        [0.4380],\n",
      "        [0.4376],\n",
      "        [0.4353],\n",
      "        [0.4338],\n",
      "        [0.4365],\n",
      "        [0.4338],\n",
      "        [0.4358],\n",
      "        [0.4382],\n",
      "        [0.4346],\n",
      "        [0.4347],\n",
      "        [0.4346],\n",
      "        [0.4352],\n",
      "        [0.4347],\n",
      "        [0.4388],\n",
      "        [0.4362],\n",
      "        [0.4338],\n",
      "        [0.4359],\n",
      "        [0.4338],\n",
      "        [0.4366],\n",
      "        [0.4364],\n",
      "        [0.4375],\n",
      "        [0.4386],\n",
      "        [0.4361],\n",
      "        [0.4352],\n",
      "        [0.4346],\n",
      "        [0.4339],\n",
      "        [0.4344],\n",
      "        [0.4359],\n",
      "        [0.4366],\n",
      "        [0.4338],\n",
      "        [0.4363],\n",
      "        [0.4371],\n",
      "        [0.4394],\n",
      "        [0.4335],\n",
      "        [0.4346],\n",
      "        [0.4358],\n",
      "        [0.4339],\n",
      "        [0.4370],\n",
      "        [0.4377],\n",
      "        [0.4338],\n",
      "        [0.4356],\n",
      "        [0.4375],\n",
      "        [0.4366],\n",
      "        [0.4358],\n",
      "        [0.4374],\n",
      "        [0.4349],\n",
      "        [0.4361],\n",
      "        [0.4352],\n",
      "        [0.4366],\n",
      "        [0.4360],\n",
      "        [0.4357],\n",
      "        [0.4358],\n",
      "        [0.4384],\n",
      "        [0.4347],\n",
      "        [0.4357],\n",
      "        [0.4355],\n",
      "        [0.4372],\n",
      "        [0.4362],\n",
      "        [0.4360],\n",
      "        [0.4351],\n",
      "        [0.4358],\n",
      "        [0.4363],\n",
      "        [0.4361],\n",
      "        [0.4369],\n",
      "        [0.4376],\n",
      "        [0.4355],\n",
      "        [0.4369],\n",
      "        [0.4367],\n",
      "        [0.4400],\n",
      "        [0.4341],\n",
      "        [0.4338],\n",
      "        [0.4361],\n",
      "        [0.4366],\n",
      "        [0.4354],\n",
      "        [0.4353],\n",
      "        [0.4382],\n",
      "        [0.4354],\n",
      "        [0.4341],\n",
      "        [0.4367],\n",
      "        [0.4362],\n",
      "        [0.4380],\n",
      "        [0.4349],\n",
      "        [0.4369],\n",
      "        [0.4338],\n",
      "        [0.4395],\n",
      "        [0.4364],\n",
      "        [0.4352],\n",
      "        [0.4378],\n",
      "        [0.4339],\n",
      "        [0.4362],\n",
      "        [0.4352],\n",
      "        [0.4343],\n",
      "        [0.4367],\n",
      "        [0.4381],\n",
      "        [0.4340],\n",
      "        [0.4365],\n",
      "        [0.4338],\n",
      "        [0.4386],\n",
      "        [0.4380],\n",
      "        [0.4356],\n",
      "        [0.4341],\n",
      "        [0.4350],\n",
      "        [0.4346],\n",
      "        [0.4363],\n",
      "        [0.4370],\n",
      "        [0.4366]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 5 个batch运行时间： 2024-09-17 16:28:27.760544 -------------\n",
      "tensor([[0.3938],\n",
      "        [0.3955],\n",
      "        [0.3962],\n",
      "        [0.3949],\n",
      "        [0.3919],\n",
      "        [0.3990],\n",
      "        [0.3977],\n",
      "        [0.3975],\n",
      "        [0.3928],\n",
      "        [0.3934],\n",
      "        [0.3947],\n",
      "        [0.3991],\n",
      "        [0.3939],\n",
      "        [0.3957],\n",
      "        [0.3923],\n",
      "        [0.3924],\n",
      "        [0.3948],\n",
      "        [0.3940],\n",
      "        [0.3933],\n",
      "        [0.3939],\n",
      "        [0.3977],\n",
      "        [0.3986],\n",
      "        [0.3969],\n",
      "        [0.3914],\n",
      "        [0.3914],\n",
      "        [0.3988],\n",
      "        [0.4000],\n",
      "        [0.3976],\n",
      "        [0.3973],\n",
      "        [0.3937],\n",
      "        [0.3989],\n",
      "        [0.3926],\n",
      "        [0.3923],\n",
      "        [0.3949],\n",
      "        [0.3934],\n",
      "        [0.3914],\n",
      "        [0.3957],\n",
      "        [0.3932],\n",
      "        [0.3936],\n",
      "        [0.3933],\n",
      "        [0.3944],\n",
      "        [0.3973],\n",
      "        [0.3955],\n",
      "        [0.3963],\n",
      "        [0.3957],\n",
      "        [0.3924],\n",
      "        [0.3924],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3960],\n",
      "        [0.3953],\n",
      "        [0.3983],\n",
      "        [0.3974],\n",
      "        [0.3956],\n",
      "        [0.3975],\n",
      "        [0.3923],\n",
      "        [0.3921],\n",
      "        [0.3934],\n",
      "        [0.3937],\n",
      "        [0.3932],\n",
      "        [0.3919],\n",
      "        [0.3976],\n",
      "        [0.3943],\n",
      "        [0.3954],\n",
      "        [0.3961],\n",
      "        [0.3947],\n",
      "        [0.3951],\n",
      "        [0.3966],\n",
      "        [0.3968],\n",
      "        [0.3928],\n",
      "        [0.3958],\n",
      "        [0.3937],\n",
      "        [0.3948],\n",
      "        [0.3920],\n",
      "        [0.3922],\n",
      "        [0.3937],\n",
      "        [0.3960],\n",
      "        [0.3957],\n",
      "        [0.3953],\n",
      "        [0.3936],\n",
      "        [0.3919],\n",
      "        [0.3914],\n",
      "        [0.3915],\n",
      "        [0.3919],\n",
      "        [0.3951],\n",
      "        [0.4001],\n",
      "        [0.3939],\n",
      "        [0.3924],\n",
      "        [0.3917],\n",
      "        [0.3974],\n",
      "        [0.3961],\n",
      "        [0.3922],\n",
      "        [0.3936],\n",
      "        [0.3953],\n",
      "        [0.3939],\n",
      "        [0.3986],\n",
      "        [0.3978],\n",
      "        [0.3943],\n",
      "        [0.3962],\n",
      "        [0.3952],\n",
      "        [0.3943],\n",
      "        [0.3833],\n",
      "        [0.3914],\n",
      "        [0.3965],\n",
      "        [0.3939],\n",
      "        [0.3948],\n",
      "        [0.4001],\n",
      "        [0.3960],\n",
      "        [0.3934],\n",
      "        [0.3971],\n",
      "        [0.3930],\n",
      "        [0.3922],\n",
      "        [0.3941],\n",
      "        [0.3959],\n",
      "        [0.3982],\n",
      "        [0.3945],\n",
      "        [0.3972],\n",
      "        [0.3936],\n",
      "        [0.3921],\n",
      "        [0.3942],\n",
      "        [0.3973],\n",
      "        [0.3981],\n",
      "        [0.3954],\n",
      "        [0.3917],\n",
      "        [0.3955],\n",
      "        [0.3949],\n",
      "        [0.3923],\n",
      "        [0.3986]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 6 个batch运行时间： 2024-09-17 16:28:33.256875 -------------\n",
      "tensor([[0.3543],\n",
      "        [0.3514],\n",
      "        [0.3538],\n",
      "        [0.3484],\n",
      "        [0.3548],\n",
      "        [0.3490],\n",
      "        [0.3477],\n",
      "        [0.3531],\n",
      "        [0.3505],\n",
      "        [0.3535],\n",
      "        [0.3509],\n",
      "        [0.3575],\n",
      "        [0.3515],\n",
      "        [0.3478],\n",
      "        [0.3518],\n",
      "        [0.3537],\n",
      "        [0.3517],\n",
      "        [0.3502],\n",
      "        [0.3513],\n",
      "        [0.3491],\n",
      "        [0.3518],\n",
      "        [0.3514],\n",
      "        [0.3523],\n",
      "        [0.3518],\n",
      "        [0.3504],\n",
      "        [0.3527],\n",
      "        [0.3503],\n",
      "        [0.3536],\n",
      "        [0.3518],\n",
      "        [0.3529],\n",
      "        [0.3493],\n",
      "        [0.3538],\n",
      "        [0.3514],\n",
      "        [0.3521],\n",
      "        [0.3522],\n",
      "        [0.3490],\n",
      "        [0.3556],\n",
      "        [0.3524],\n",
      "        [0.3512],\n",
      "        [0.3522],\n",
      "        [0.3523],\n",
      "        [0.3480],\n",
      "        [0.3492],\n",
      "        [0.3512],\n",
      "        [0.3537],\n",
      "        [0.3499],\n",
      "        [0.3493],\n",
      "        [0.3525],\n",
      "        [0.3549],\n",
      "        [0.3506],\n",
      "        [0.3506],\n",
      "        [0.3484],\n",
      "        [0.3545],\n",
      "        [0.3518],\n",
      "        [0.3526],\n",
      "        [0.3492],\n",
      "        [0.3528],\n",
      "        [0.3479],\n",
      "        [0.3515],\n",
      "        [0.3492],\n",
      "        [0.3514],\n",
      "        [0.3507],\n",
      "        [0.3554],\n",
      "        [0.3565],\n",
      "        [0.3563],\n",
      "        [0.3531],\n",
      "        [0.3530],\n",
      "        [0.3472],\n",
      "        [0.3487],\n",
      "        [0.3487],\n",
      "        [0.3488],\n",
      "        [0.3528],\n",
      "        [0.3506],\n",
      "        [0.3538],\n",
      "        [0.3515],\n",
      "        [0.3508],\n",
      "        [0.3496],\n",
      "        [0.3552],\n",
      "        [0.3500],\n",
      "        [0.3500],\n",
      "        [0.3547],\n",
      "        [0.3486],\n",
      "        [0.3447],\n",
      "        [0.3472],\n",
      "        [0.3517],\n",
      "        [0.3472],\n",
      "        [0.3549],\n",
      "        [0.3534],\n",
      "        [0.3498],\n",
      "        [0.3522],\n",
      "        [0.3513],\n",
      "        [0.3508],\n",
      "        [0.3524],\n",
      "        [0.3486],\n",
      "        [0.3506],\n",
      "        [0.3503],\n",
      "        [0.3495],\n",
      "        [0.3530],\n",
      "        [0.3538],\n",
      "        [0.3548],\n",
      "        [0.3541],\n",
      "        [0.3491],\n",
      "        [0.3495],\n",
      "        [0.3516],\n",
      "        [0.3541],\n",
      "        [0.3499],\n",
      "        [0.3526],\n",
      "        [0.3509],\n",
      "        [0.3536],\n",
      "        [0.3506],\n",
      "        [0.3518],\n",
      "        [0.3494],\n",
      "        [0.3560],\n",
      "        [0.3521],\n",
      "        [0.3500],\n",
      "        [0.3543],\n",
      "        [0.3536],\n",
      "        [0.3522],\n",
      "        [0.3508],\n",
      "        [0.3478],\n",
      "        [0.3494],\n",
      "        [0.3472],\n",
      "        [0.3504],\n",
      "        [0.3510],\n",
      "        [0.3516],\n",
      "        [0.3540],\n",
      "        [0.3514],\n",
      "        [0.3529]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 7 个batch运行时间： 2024-09-17 16:28:38.557400 -------------\n",
      "tensor([[0.3134],\n",
      "        [0.3184],\n",
      "        [0.3155],\n",
      "        [0.3037],\n",
      "        [0.3142],\n",
      "        [0.3206],\n",
      "        [0.3168],\n",
      "        [0.3109],\n",
      "        [0.3154],\n",
      "        [0.3129],\n",
      "        [0.3193],\n",
      "        [0.3167],\n",
      "        [0.3182],\n",
      "        [0.3151],\n",
      "        [0.3094],\n",
      "        [0.3208],\n",
      "        [0.3102],\n",
      "        [0.3147],\n",
      "        [0.3125],\n",
      "        [0.3159],\n",
      "        [0.3149],\n",
      "        [0.3159],\n",
      "        [0.3150],\n",
      "        [0.3162],\n",
      "        [0.3133],\n",
      "        [0.3142],\n",
      "        [0.3116],\n",
      "        [0.3190],\n",
      "        [0.3094],\n",
      "        [0.3178],\n",
      "        [0.3147],\n",
      "        [0.3179],\n",
      "        [0.3121],\n",
      "        [0.3163],\n",
      "        [0.3109],\n",
      "        [0.3126],\n",
      "        [0.3144],\n",
      "        [0.3146],\n",
      "        [0.3169],\n",
      "        [0.3122],\n",
      "        [0.3142],\n",
      "        [0.3214],\n",
      "        [0.3128],\n",
      "        [0.3132],\n",
      "        [0.3148],\n",
      "        [0.3147],\n",
      "        [0.3123],\n",
      "        [0.3151],\n",
      "        [0.3121],\n",
      "        [0.3162],\n",
      "        [0.3255],\n",
      "        [0.3103],\n",
      "        [0.3114],\n",
      "        [0.3124],\n",
      "        [0.3123],\n",
      "        [0.3186],\n",
      "        [0.3120],\n",
      "        [0.3103],\n",
      "        [0.3205],\n",
      "        [0.3195],\n",
      "        [0.3131],\n",
      "        [0.3175],\n",
      "        [0.3114],\n",
      "        [0.3191],\n",
      "        [0.3120],\n",
      "        [0.3094],\n",
      "        [0.3195],\n",
      "        [0.3094],\n",
      "        [0.3141],\n",
      "        [0.3145],\n",
      "        [0.3164],\n",
      "        [0.3146],\n",
      "        [0.3170],\n",
      "        [0.3182],\n",
      "        [0.3199],\n",
      "        [0.3222],\n",
      "        [0.3126],\n",
      "        [0.3137],\n",
      "        [0.3134],\n",
      "        [0.3121],\n",
      "        [0.3169],\n",
      "        [0.3135],\n",
      "        [0.3141],\n",
      "        [0.3179],\n",
      "        [0.3183],\n",
      "        [0.3151],\n",
      "        [0.3164],\n",
      "        [0.3147],\n",
      "        [0.3181],\n",
      "        [0.3141],\n",
      "        [0.3176],\n",
      "        [0.3174],\n",
      "        [0.3170],\n",
      "        [0.3134],\n",
      "        [0.3130],\n",
      "        [0.3156],\n",
      "        [0.3154],\n",
      "        [0.3120],\n",
      "        [0.3154],\n",
      "        [0.3120],\n",
      "        [0.3165],\n",
      "        [0.3157],\n",
      "        [0.3142],\n",
      "        [0.3144],\n",
      "        [0.3139],\n",
      "        [0.3113],\n",
      "        [0.3181],\n",
      "        [0.3094],\n",
      "        [0.3143],\n",
      "        [0.3124],\n",
      "        [0.3149],\n",
      "        [0.3176],\n",
      "        [0.3195],\n",
      "        [0.3188],\n",
      "        [0.3134],\n",
      "        [0.3168],\n",
      "        [0.3117],\n",
      "        [0.3155],\n",
      "        [0.3183],\n",
      "        [0.3170],\n",
      "        [0.3103],\n",
      "        [0.3127],\n",
      "        [0.3103],\n",
      "        [0.3103],\n",
      "        [0.3178],\n",
      "        [0.3180],\n",
      "        [0.3134],\n",
      "        [0.3146]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 8 个batch运行时间： 2024-09-17 16:28:43.743479 -------------\n",
      "tensor([[0.2887],\n",
      "        [0.2861],\n",
      "        [0.2866],\n",
      "        [0.2848],\n",
      "        [0.2846],\n",
      "        [0.2816],\n",
      "        [0.2871],\n",
      "        [0.2918],\n",
      "        [0.2822],\n",
      "        [0.2919],\n",
      "        [0.2855],\n",
      "        [0.2855],\n",
      "        [0.2907],\n",
      "        [0.2851],\n",
      "        [0.2873],\n",
      "        [0.2870],\n",
      "        [0.2900],\n",
      "        [0.2849],\n",
      "        [0.2831],\n",
      "        [0.2840],\n",
      "        [0.2888],\n",
      "        [0.2896],\n",
      "        [0.2884],\n",
      "        [0.2880],\n",
      "        [0.2821],\n",
      "        [0.2887],\n",
      "        [0.2832],\n",
      "        [0.2910],\n",
      "        [0.2832],\n",
      "        [0.2874],\n",
      "        [0.2814],\n",
      "        [0.2868],\n",
      "        [0.2858],\n",
      "        [0.2866],\n",
      "        [0.2880],\n",
      "        [0.2852],\n",
      "        [0.2894],\n",
      "        [0.2840],\n",
      "        [0.2862],\n",
      "        [0.2855],\n",
      "        [0.2858],\n",
      "        [0.2911],\n",
      "        [0.2804],\n",
      "        [0.2884],\n",
      "        [0.2867],\n",
      "        [0.2891],\n",
      "        [0.2937],\n",
      "        [0.2855],\n",
      "        [0.2900],\n",
      "        [0.2839],\n",
      "        [0.2896],\n",
      "        [0.2836],\n",
      "        [0.2904],\n",
      "        [0.2920],\n",
      "        [0.2851],\n",
      "        [0.2855],\n",
      "        [0.2864],\n",
      "        [0.2897],\n",
      "        [0.2845],\n",
      "        [0.2804],\n",
      "        [0.2809],\n",
      "        [0.2820],\n",
      "        [0.2887],\n",
      "        [0.2813],\n",
      "        [0.2836],\n",
      "        [0.2856],\n",
      "        [0.2830],\n",
      "        [0.2858],\n",
      "        [0.2872],\n",
      "        [0.2856],\n",
      "        [0.2825],\n",
      "        [0.2840],\n",
      "        [0.2900],\n",
      "        [0.2840],\n",
      "        [0.2853],\n",
      "        [0.2894],\n",
      "        [0.2869],\n",
      "        [0.2759],\n",
      "        [0.2936],\n",
      "        [0.2835],\n",
      "        [0.2914],\n",
      "        [0.2812],\n",
      "        [0.2844],\n",
      "        [0.2845],\n",
      "        [0.2903],\n",
      "        [0.2849],\n",
      "        [0.2962],\n",
      "        [0.2804],\n",
      "        [0.2894],\n",
      "        [0.2915],\n",
      "        [0.2887],\n",
      "        [0.2877],\n",
      "        [0.2913],\n",
      "        [0.2840],\n",
      "        [0.2822],\n",
      "        [0.2851],\n",
      "        [0.2875],\n",
      "        [0.2827],\n",
      "        [0.2866],\n",
      "        [0.2841],\n",
      "        [0.2974],\n",
      "        [0.2852],\n",
      "        [0.2884],\n",
      "        [0.2828],\n",
      "        [0.2910],\n",
      "        [0.2886],\n",
      "        [0.2923],\n",
      "        [0.2844],\n",
      "        [0.2895],\n",
      "        [0.2870],\n",
      "        [0.2975],\n",
      "        [0.2826],\n",
      "        [0.2926],\n",
      "        [0.2867],\n",
      "        [0.2884],\n",
      "        [0.2835],\n",
      "        [0.2856],\n",
      "        [0.2901],\n",
      "        [0.2928],\n",
      "        [0.2839],\n",
      "        [0.2880],\n",
      "        [0.2837],\n",
      "        [0.2818],\n",
      "        [0.2874],\n",
      "        [0.2844],\n",
      "        [0.2854],\n",
      "        [0.2975],\n",
      "        [0.2818]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 9 个batch运行时间： 2024-09-17 16:28:48.677817 -------------\n",
      "tensor([[0.2646],\n",
      "        [0.2662],\n",
      "        [0.2633],\n",
      "        [0.2678],\n",
      "        [0.2656],\n",
      "        [0.2632],\n",
      "        [0.2640],\n",
      "        [0.2673],\n",
      "        [0.2662],\n",
      "        [0.2678],\n",
      "        [0.2639],\n",
      "        [0.2616],\n",
      "        [0.2699],\n",
      "        [0.2643],\n",
      "        [0.2637],\n",
      "        [0.2679],\n",
      "        [0.2674],\n",
      "        [0.2639],\n",
      "        [0.2667],\n",
      "        [0.2664],\n",
      "        [0.2668],\n",
      "        [0.2661],\n",
      "        [0.2666],\n",
      "        [0.2727],\n",
      "        [0.2681],\n",
      "        [0.2676],\n",
      "        [0.2666],\n",
      "        [0.2643],\n",
      "        [0.2713],\n",
      "        [0.2624],\n",
      "        [0.2673],\n",
      "        [0.2627],\n",
      "        [0.2612],\n",
      "        [0.2626],\n",
      "        [0.2656],\n",
      "        [0.2716],\n",
      "        [0.2637],\n",
      "        [0.2759],\n",
      "        [0.2629],\n",
      "        [0.2714],\n",
      "        [0.2658],\n",
      "        [0.2718],\n",
      "        [0.2607],\n",
      "        [0.2747],\n",
      "        [0.2694],\n",
      "        [0.2707],\n",
      "        [0.2656],\n",
      "        [0.2622],\n",
      "        [0.2681],\n",
      "        [0.2683],\n",
      "        [0.2663],\n",
      "        [0.2676],\n",
      "        [0.2687],\n",
      "        [0.2686],\n",
      "        [0.2708],\n",
      "        [0.2619],\n",
      "        [0.2607],\n",
      "        [0.2644],\n",
      "        [0.2634],\n",
      "        [0.2718],\n",
      "        [0.2723],\n",
      "        [0.2685],\n",
      "        [0.2639],\n",
      "        [0.2654],\n",
      "        [0.2722],\n",
      "        [0.2642],\n",
      "        [0.2639],\n",
      "        [0.2631],\n",
      "        [0.2632],\n",
      "        [0.2653],\n",
      "        [0.2674],\n",
      "        [0.2657],\n",
      "        [0.2632],\n",
      "        [0.2673],\n",
      "        [0.2669],\n",
      "        [0.2614],\n",
      "        [0.2664],\n",
      "        [0.2693],\n",
      "        [0.2647],\n",
      "        [0.2699],\n",
      "        [0.2673],\n",
      "        [0.2607],\n",
      "        [0.2685],\n",
      "        [0.2670],\n",
      "        [0.2675],\n",
      "        [0.2695],\n",
      "        [0.2700],\n",
      "        [0.2657],\n",
      "        [0.2670],\n",
      "        [0.2659],\n",
      "        [0.2634],\n",
      "        [0.2661],\n",
      "        [0.2723],\n",
      "        [0.2642],\n",
      "        [0.2771],\n",
      "        [0.2717],\n",
      "        [0.2631],\n",
      "        [0.2665],\n",
      "        [0.2670],\n",
      "        [0.2670],\n",
      "        [0.2702],\n",
      "        [0.2717],\n",
      "        [0.2633],\n",
      "        [0.2736],\n",
      "        [0.2669],\n",
      "        [0.2685],\n",
      "        [0.2706],\n",
      "        [0.2607],\n",
      "        [0.2674],\n",
      "        [0.2654],\n",
      "        [0.2713],\n",
      "        [0.2681],\n",
      "        [0.2609],\n",
      "        [0.2671],\n",
      "        [0.2670],\n",
      "        [0.2643],\n",
      "        [0.2677],\n",
      "        [0.2658],\n",
      "        [0.2651],\n",
      "        [0.2693],\n",
      "        [0.2669],\n",
      "        [0.2724],\n",
      "        [0.2673],\n",
      "        [0.2688],\n",
      "        [0.2687],\n",
      "        [0.2689],\n",
      "        [0.2721],\n",
      "        [0.2651]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 10 个batch运行时间： 2024-09-17 16:28:53.562384 -------------\n",
      "tensor([[0.2611],\n",
      "        [0.2559],\n",
      "        [0.2542],\n",
      "        [0.2610],\n",
      "        [0.2572],\n",
      "        [0.2560],\n",
      "        [0.2568],\n",
      "        [0.2526],\n",
      "        [0.2581],\n",
      "        [0.2538],\n",
      "        [0.2556],\n",
      "        [0.2585],\n",
      "        [0.2473],\n",
      "        [0.2466],\n",
      "        [0.2536],\n",
      "        [0.2574],\n",
      "        [0.2562],\n",
      "        [0.2516],\n",
      "        [0.2494],\n",
      "        [0.2519],\n",
      "        [0.2466],\n",
      "        [0.2564],\n",
      "        [0.2466],\n",
      "        [0.2563],\n",
      "        [0.2487],\n",
      "        [0.2573],\n",
      "        [0.2533],\n",
      "        [0.2598],\n",
      "        [0.2511],\n",
      "        [0.2522],\n",
      "        [0.2543],\n",
      "        [0.2491],\n",
      "        [0.2541],\n",
      "        [0.2571],\n",
      "        [0.2549],\n",
      "        [0.2530],\n",
      "        [0.2539],\n",
      "        [0.2519],\n",
      "        [0.2536],\n",
      "        [0.2580],\n",
      "        [0.2537],\n",
      "        [0.2521],\n",
      "        [0.2519],\n",
      "        [0.2499],\n",
      "        [0.2520],\n",
      "        [0.2523],\n",
      "        [0.2475],\n",
      "        [0.2562],\n",
      "        [0.2520],\n",
      "        [0.2598],\n",
      "        [0.2558],\n",
      "        [0.2609],\n",
      "        [0.2496],\n",
      "        [0.2527],\n",
      "        [0.2518],\n",
      "        [0.2535],\n",
      "        [0.2571],\n",
      "        [0.2539],\n",
      "        [0.2540],\n",
      "        [0.2604],\n",
      "        [0.2554],\n",
      "        [0.2535],\n",
      "        [0.2534],\n",
      "        [0.2555],\n",
      "        [0.2554],\n",
      "        [0.2528],\n",
      "        [0.2488],\n",
      "        [0.2552],\n",
      "        [0.2512],\n",
      "        [0.2548],\n",
      "        [0.2589],\n",
      "        [0.2519],\n",
      "        [0.2522],\n",
      "        [0.2548],\n",
      "        [0.2509],\n",
      "        [0.2511],\n",
      "        [0.2565],\n",
      "        [0.2509],\n",
      "        [0.2550],\n",
      "        [0.2497],\n",
      "        [0.2517],\n",
      "        [0.2498],\n",
      "        [0.2549],\n",
      "        [0.2511],\n",
      "        [0.2579],\n",
      "        [0.2617],\n",
      "        [0.2517],\n",
      "        [0.2528],\n",
      "        [0.2486],\n",
      "        [0.2504],\n",
      "        [0.2537],\n",
      "        [0.2573],\n",
      "        [0.2522],\n",
      "        [0.2539],\n",
      "        [0.2595],\n",
      "        [0.2466],\n",
      "        [0.2524],\n",
      "        [0.2562],\n",
      "        [0.2587],\n",
      "        [0.2508],\n",
      "        [0.2542],\n",
      "        [0.2600],\n",
      "        [0.2566],\n",
      "        [0.2562],\n",
      "        [0.2481],\n",
      "        [0.2542],\n",
      "        [0.2534],\n",
      "        [0.2526],\n",
      "        [0.2515],\n",
      "        [0.2466],\n",
      "        [0.2509],\n",
      "        [0.2534],\n",
      "        [0.2506],\n",
      "        [0.2494],\n",
      "        [0.2489],\n",
      "        [0.2550],\n",
      "        [0.2587],\n",
      "        [0.2538],\n",
      "        [0.2627],\n",
      "        [0.2533],\n",
      "        [0.2598],\n",
      "        [0.2582],\n",
      "        [0.2493],\n",
      "        [0.2548],\n",
      "        [0.2545],\n",
      "        [0.2587],\n",
      "        [0.2554],\n",
      "        [0.2523]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 11 个batch运行时间： 2024-09-17 16:28:58.735891 -------------\n",
      "tensor([[0.2448],\n",
      "        [0.2457],\n",
      "        [0.2451],\n",
      "        [0.2509],\n",
      "        [0.2464],\n",
      "        [0.2521],\n",
      "        [0.2450],\n",
      "        [0.2424],\n",
      "        [0.2434],\n",
      "        [0.2539],\n",
      "        [0.2478],\n",
      "        [0.2489],\n",
      "        [0.2505],\n",
      "        [0.2450],\n",
      "        [0.2486],\n",
      "        [0.2490],\n",
      "        [0.2457],\n",
      "        [0.2486],\n",
      "        [0.2440],\n",
      "        [0.2491],\n",
      "        [0.2462],\n",
      "        [0.2495],\n",
      "        [0.2538],\n",
      "        [0.2429],\n",
      "        [0.2524],\n",
      "        [0.2429],\n",
      "        [0.2475],\n",
      "        [0.2493],\n",
      "        [0.2434],\n",
      "        [0.2547],\n",
      "        [0.2498],\n",
      "        [0.2450],\n",
      "        [0.2476],\n",
      "        [0.2449],\n",
      "        [0.2445],\n",
      "        [0.2443],\n",
      "        [0.2504],\n",
      "        [0.2498],\n",
      "        [0.2447],\n",
      "        [0.2488],\n",
      "        [0.2601],\n",
      "        [0.2476],\n",
      "        [0.2464],\n",
      "        [0.2516],\n",
      "        [0.2438],\n",
      "        [0.2468],\n",
      "        [0.2445],\n",
      "        [0.2538],\n",
      "        [0.2562],\n",
      "        [0.2451],\n",
      "        [0.2468],\n",
      "        [0.2448],\n",
      "        [0.2473],\n",
      "        [0.2497],\n",
      "        [0.2472],\n",
      "        [0.2512],\n",
      "        [0.2446],\n",
      "        [0.2564],\n",
      "        [0.2540],\n",
      "        [0.2426],\n",
      "        [0.2510],\n",
      "        [0.2461],\n",
      "        [0.2429],\n",
      "        [0.2454],\n",
      "        [0.2519],\n",
      "        [0.2489],\n",
      "        [0.2500],\n",
      "        [0.2509],\n",
      "        [0.2440],\n",
      "        [0.2433],\n",
      "        [0.2483],\n",
      "        [0.2431],\n",
      "        [0.2498],\n",
      "        [0.2413],\n",
      "        [0.2494],\n",
      "        [0.2413],\n",
      "        [0.2549],\n",
      "        [0.2463],\n",
      "        [0.2475],\n",
      "        [0.2468],\n",
      "        [0.2510],\n",
      "        [0.2470],\n",
      "        [0.2460],\n",
      "        [0.2422],\n",
      "        [0.2527],\n",
      "        [0.2473],\n",
      "        [0.2465],\n",
      "        [0.2473],\n",
      "        [0.2468],\n",
      "        [0.2512],\n",
      "        [0.2482],\n",
      "        [0.2459],\n",
      "        [0.2491],\n",
      "        [0.2508],\n",
      "        [0.2530],\n",
      "        [0.2512],\n",
      "        [0.2483],\n",
      "        [0.2496],\n",
      "        [0.2445],\n",
      "        [0.2493],\n",
      "        [0.2505],\n",
      "        [0.2451],\n",
      "        [0.2506],\n",
      "        [0.2474],\n",
      "        [0.2518],\n",
      "        [0.2484],\n",
      "        [0.2540],\n",
      "        [0.2278],\n",
      "        [0.2511],\n",
      "        [0.2463],\n",
      "        [0.2505],\n",
      "        [0.2445],\n",
      "        [0.2538],\n",
      "        [0.2487],\n",
      "        [0.2503],\n",
      "        [0.2438],\n",
      "        [0.2496],\n",
      "        [0.2469],\n",
      "        [0.2408],\n",
      "        [0.2487],\n",
      "        [0.2458],\n",
      "        [0.2469],\n",
      "        [0.2457],\n",
      "        [0.2430],\n",
      "        [0.2445],\n",
      "        [0.2519],\n",
      "        [0.2443],\n",
      "        [0.2464]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 12 个batch运行时间： 2024-09-17 16:29:06.677584 -------------\n",
      "tensor([[0.2490],\n",
      "        [0.2469],\n",
      "        [0.2509],\n",
      "        [0.2520],\n",
      "        [0.2491],\n",
      "        [0.2510],\n",
      "        [0.2466],\n",
      "        [0.2485],\n",
      "        [0.2478],\n",
      "        [0.2470],\n",
      "        [0.2466],\n",
      "        [0.2510],\n",
      "        [0.2504],\n",
      "        [0.2554],\n",
      "        [0.2509],\n",
      "        [0.2483],\n",
      "        [0.2451],\n",
      "        [0.2501],\n",
      "        [0.2521],\n",
      "        [0.2526],\n",
      "        [0.2473],\n",
      "        [0.2534],\n",
      "        [0.2489],\n",
      "        [0.2295],\n",
      "        [0.2498],\n",
      "        [0.2503],\n",
      "        [0.2544],\n",
      "        [0.2478],\n",
      "        [0.2512],\n",
      "        [0.2505],\n",
      "        [0.2537],\n",
      "        [0.2517],\n",
      "        [0.2483],\n",
      "        [0.2482],\n",
      "        [0.2460],\n",
      "        [0.2497],\n",
      "        [0.2540],\n",
      "        [0.2554],\n",
      "        [0.2542],\n",
      "        [0.2555],\n",
      "        [0.2476],\n",
      "        [0.2495],\n",
      "        [0.2470],\n",
      "        [0.2493],\n",
      "        [0.2519],\n",
      "        [0.2599],\n",
      "        [0.2451],\n",
      "        [0.2532],\n",
      "        [0.2451],\n",
      "        [0.2485],\n",
      "        [0.2492],\n",
      "        [0.2555],\n",
      "        [0.2529],\n",
      "        [0.2521],\n",
      "        [0.2510],\n",
      "        [0.2451],\n",
      "        [0.2517],\n",
      "        [0.2520],\n",
      "        [0.2576],\n",
      "        [0.2508],\n",
      "        [0.2520],\n",
      "        [0.2506],\n",
      "        [0.2497],\n",
      "        [0.2489],\n",
      "        [0.2532],\n",
      "        [0.2514],\n",
      "        [0.2513],\n",
      "        [0.2549],\n",
      "        [0.2500],\n",
      "        [0.2461],\n",
      "        [0.2498],\n",
      "        [0.2474],\n",
      "        [0.2564],\n",
      "        [0.2501],\n",
      "        [0.2451],\n",
      "        [0.2550],\n",
      "        [0.2451],\n",
      "        [0.2559],\n",
      "        [0.2478],\n",
      "        [0.2451],\n",
      "        [0.2505],\n",
      "        [0.2489],\n",
      "        [0.2551],\n",
      "        [0.2463],\n",
      "        [0.2511],\n",
      "        [0.2523],\n",
      "        [0.2476],\n",
      "        [0.2549],\n",
      "        [0.2558],\n",
      "        [0.2501],\n",
      "        [0.2522],\n",
      "        [0.2475],\n",
      "        [0.2507],\n",
      "        [0.2485],\n",
      "        [0.2530],\n",
      "        [0.2525],\n",
      "        [0.2468],\n",
      "        [0.2496],\n",
      "        [0.2509],\n",
      "        [0.2468],\n",
      "        [0.2486],\n",
      "        [0.2507],\n",
      "        [0.2499],\n",
      "        [0.2484],\n",
      "        [0.2519],\n",
      "        [0.2527],\n",
      "        [0.2506],\n",
      "        [0.2500],\n",
      "        [0.2485],\n",
      "        [0.2463],\n",
      "        [0.2492],\n",
      "        [0.2521],\n",
      "        [0.2537],\n",
      "        [0.2460],\n",
      "        [0.2535],\n",
      "        [0.2507],\n",
      "        [0.2494],\n",
      "        [0.2543],\n",
      "        [0.2470],\n",
      "        [0.2458],\n",
      "        [0.2484],\n",
      "        [0.2499],\n",
      "        [0.2513],\n",
      "        [0.2530],\n",
      "        [0.2505],\n",
      "        [0.2528],\n",
      "        [0.2507],\n",
      "        [0.2495]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 13 个batch运行时间： 2024-09-17 16:29:13.667293 -------------\n",
      "tensor([[0.2588],\n",
      "        [0.2593],\n",
      "        [0.2601],\n",
      "        [0.2596],\n",
      "        [0.2620],\n",
      "        [0.2586],\n",
      "        [0.2622],\n",
      "        [0.2616],\n",
      "        [0.2601],\n",
      "        [0.2563],\n",
      "        [0.2569],\n",
      "        [0.2593],\n",
      "        [0.2557],\n",
      "        [0.2626],\n",
      "        [0.2541],\n",
      "        [0.2569],\n",
      "        [0.2594],\n",
      "        [0.2608],\n",
      "        [0.2560],\n",
      "        [0.2602],\n",
      "        [0.2590],\n",
      "        [0.2551],\n",
      "        [0.2609],\n",
      "        [0.2610],\n",
      "        [0.2599],\n",
      "        [0.2565],\n",
      "        [0.2570],\n",
      "        [0.2692],\n",
      "        [0.2576],\n",
      "        [0.2603],\n",
      "        [0.2561],\n",
      "        [0.2577],\n",
      "        [0.2657],\n",
      "        [0.2569],\n",
      "        [0.2575],\n",
      "        [0.2592],\n",
      "        [0.2594],\n",
      "        [0.2695],\n",
      "        [0.2599],\n",
      "        [0.2605],\n",
      "        [0.2631],\n",
      "        [0.2565],\n",
      "        [0.2588],\n",
      "        [0.2627],\n",
      "        [0.2603],\n",
      "        [0.2641],\n",
      "        [0.2564],\n",
      "        [0.2635],\n",
      "        [0.2636],\n",
      "        [0.2657],\n",
      "        [0.2551],\n",
      "        [0.2543],\n",
      "        [0.2631],\n",
      "        [0.2572],\n",
      "        [0.2627],\n",
      "        [0.2615],\n",
      "        [0.2573],\n",
      "        [0.2578],\n",
      "        [0.2661],\n",
      "        [0.2561],\n",
      "        [0.2704],\n",
      "        [0.2592],\n",
      "        [0.2571],\n",
      "        [0.2602],\n",
      "        [0.2564],\n",
      "        [0.2610],\n",
      "        [0.2623],\n",
      "        [0.2583],\n",
      "        [0.2551],\n",
      "        [0.2593],\n",
      "        [0.2597],\n",
      "        [0.2654],\n",
      "        [0.2561],\n",
      "        [0.2574],\n",
      "        [0.2549],\n",
      "        [0.2554],\n",
      "        [0.2450],\n",
      "        [0.2605],\n",
      "        [0.2566],\n",
      "        [0.2608],\n",
      "        [0.2568],\n",
      "        [0.2606],\n",
      "        [0.2648],\n",
      "        [0.2630],\n",
      "        [0.2580],\n",
      "        [0.2592],\n",
      "        [0.2614],\n",
      "        [0.2571],\n",
      "        [0.2579],\n",
      "        [0.2571],\n",
      "        [0.2602],\n",
      "        [0.2543],\n",
      "        [0.2659],\n",
      "        [0.2600],\n",
      "        [0.2570],\n",
      "        [0.2596],\n",
      "        [0.2632],\n",
      "        [0.2567],\n",
      "        [0.2618],\n",
      "        [0.2606],\n",
      "        [0.2621],\n",
      "        [0.2568],\n",
      "        [0.2586],\n",
      "        [0.2573],\n",
      "        [0.2600],\n",
      "        [0.2594],\n",
      "        [0.2593],\n",
      "        [0.2632],\n",
      "        [0.2665],\n",
      "        [0.2640],\n",
      "        [0.2620],\n",
      "        [0.2640],\n",
      "        [0.2597],\n",
      "        [0.2613],\n",
      "        [0.2579],\n",
      "        [0.2602],\n",
      "        [0.2652],\n",
      "        [0.2605],\n",
      "        [0.2567],\n",
      "        [0.2557],\n",
      "        [0.2609],\n",
      "        [0.2588],\n",
      "        [0.2584],\n",
      "        [0.2636],\n",
      "        [0.2654],\n",
      "        [0.2621],\n",
      "        [0.2633],\n",
      "        [0.2621]], grad_fn=<SigmoidBackward0>)\n",
      "||--训练：---------- 14 个batch运行时间： 2024-09-17 16:29:19.513385 -------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zx/6cmjrfvx00b1fp30mrv9phkc0000gn/T/ipykernel_33942/3868383251.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# 训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mmodel_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'模型训练完成'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'||--------训练结束时间：'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/zx/6cmjrfvx00b1fp30mrv9phkc0000gn/T/ipykernel_33942/396570402.py\u001b[0m in \u001b[0;36mmodel_training\u001b[0;34m(model, train_loader, val_loader, lossfunction, optimizer, EPOCH, device)\u001b[0m\n\u001b[1;32m     45\u001b[0m                                                                   \u001b[0mbatch_feature_tensor_pay_CHONGHE_continue_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                                                                   \u001b[0mbatch_feature_tensor_pay_FUFEI_continue_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                                                                   train_label_tensor)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# weight_result_dict = WeightResult(HistoryDimScaling_Weight_Result, TargetDimScaling_Weight_Result, target_history_pay_attention_QOE_weight,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/maoerDL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/zx/6cmjrfvx00b1fp30mrv9phkc0000gn/T/ipykernel_33942/1440750094.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_feature_tensor_pay_QOE_discrete, batch_feature_tensor_pay_CHONGHE_discrete, batch_feature_tensor_pay_FUFEI_discrete, batch_feature_tensor_pay_QOE_continue, batch_feature_tensor_pay_CHONGHE_continue, batch_feature_tensor_pay_FUFEI_continue, batch_feature_tensor_target_QOE_discrete, batch_feature_tensor_target_CHONGHE_discrete, batch_feature_tensor_target_FUFEI_discrete, batch_feature_tensor_target_QOE_continue, batch_feature_tensor_target_CHONGHE_continue, batch_feature_tensor_target_FUFEI_continue, batch_feature_tensor_pay_QOE_discrete_mask, batch_feature_tensor_pay_CHONGHE_discrete_mask, batch_feature_tensor_pay_FUFEI_discrete_mask, batch_feature_tensor_pay_QOE_continue_mask, batch_feature_tensor_pay_CHONGHE_continue_mask, batch_feature_tensor_pay_FUFEI_continue_mask, label_tensor)\u001b[0m\n\u001b[1;32m     70\u001b[0m         HistoryDimScaling_Weight_Result, se_user_history_pay_QOE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_FUFEI_vec = self.history_pay_attention_layer(\n\u001b[1;32m     71\u001b[0m             \u001b[0muser_history_pay_QOE_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_history_pay_CHONGHE_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_history_pay_FUFEI_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             pay_QOE_mask=pay_QOE_mask, pay_CHONGHE_mask=pay_CHONGHE_mask, pay_FUFEI_mask=pay_FUFEI_mask)\n\u001b[0m\u001b[1;32m     73\u001b[0m         TargetDimScaling_Weight_Result, se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec = self.target_attention_layer(\n\u001b[1;32m     74\u001b[0m             target_QOE_vec, target_CHONGHE_vec, target_FUFEI_vec)\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/maoerDL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/zx/6cmjrfvx00b1fp30mrv9phkc0000gn/T/ipykernel_33942/2146736106.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, user_history_QOE_vec, user_history_CHONGHE_vec, user_history_FUFEI_vec, pay_QOE_mask, pay_CHONGHE_mask, pay_FUFEI_mask)\u001b[0m\n\u001b[1;32m     41\u001b[0m                                                                                     mask=pay_QOE_mask)\n\u001b[1;32m     42\u001b[0m         mutli_CHONGHE_weight, multi_user_history_CHONGHE_vec, _ = self.multi_head_attention(user_history_CHONGHE_vec,\n\u001b[0;32m---> 43\u001b[0;31m                                                                                             mask=pay_CHONGHE_mask)\n\u001b[0m\u001b[1;32m     44\u001b[0m         mutli_FUFEI_weight, multi_user_history_FUFEI_vec, _ = self.multi_head_attention(user_history_FUFEI_vec,\n\u001b[1;32m     45\u001b[0m                                                                                         mask=pay_FUFEI_mask)\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/maoerDL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/zx/6cmjrfvx00b1fp30mrv9phkc0000gn/T/ipykernel_33942/3972029649.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, history_matrix, mask)\u001b[0m\n\u001b[1;32m    203\u001b[0m                                                                                                 self.feature_dim)\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# 计算加权平均\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mweighted_avg_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 在 history_len 维度上取平均，保持维度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;31m# 调整维度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mweighted_avg_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_avg_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 模型运行\n",
    "for data_time_windows in data_time_windows_list:\n",
    "\n",
    "    data_path = \"../Dataset/\"\n",
    "    # path = './Dataset/' + data_time_windows + '_user_pay_pred_feature_deal.csv'\n",
    "    train_path = data_path + data_time_windows + '_all_feature_FS_deal.csv'\n",
    "    test_path = data_path + data_time_windows + '_all_feature_DL_deal.csv'\n",
    "    dataset_spilt_path = data_path + data_time_windows + '_user_pay_pred_feature_spilt.csv'\n",
    "    output_weight_result_path = data_path + data_time_windows + '_user_pay_pred_result_weight.csv'\n",
    "    data_feature_continue_discrete_namelist_path = data_path + 'DL_windows_fs_new.csv'  # 连续与离散划分表\n",
    "    # 获取时间窗内连续与离散特征名的列表(获取列名)\n",
    "    user_history_pay_QOE_continue_column, user_history_pay_CHONGHE_continue_column, \\\n",
    "        user_history_pay_FUFEI_continue_column, user_history_pay_QOE_discrete_column, \\\n",
    "        user_history_pay_CHONGHE_discrete_column, user_history_pay_FUFEI_discrete_column = get_continue_discrete_feature_namelist(\n",
    "        data_time_windows, data_feature_continue_discrete_namelist_path)\n",
    "    user_feature_continue_column = []\n",
    "    user_feature_discrete_column = []\n",
    "    # total continue feature\n",
    "    total_continue_feature = user_feature_continue_column + user_history_pay_QOE_continue_column + user_history_pay_CHONGHE_continue_column + user_history_pay_FUFEI_continue_column\n",
    "    total_discrete_feature = user_feature_discrete_column + user_history_pay_QOE_discrete_column + user_history_pay_CHONGHE_discrete_column + user_history_pay_FUFEI_discrete_column\n",
    "    # 付费label(离散特征)\n",
    "    total_discrete_feature_add_D = user_feature_discrete_column + user_history_pay_QOE_discrete_column + user_history_pay_CHONGHE_discrete_column + user_history_pay_FUFEI_discrete_column\n",
    "    total_discrete_feature_add_D.append('pay_DL')\n",
    "    user_history_pay_CHONGHE_discrete_column_add_D = copy.deepcopy(user_history_pay_CHONGHE_discrete_column)\n",
    "    user_history_pay_CHONGHE_discrete_column_add_D.append('pay_DL')\n",
    "    tensor_dict_idx = ['pay_QOE_continue', 'pay_QOE_discrete', 'pay_CHONGHE_continue', 'pay_CHONGHE_discrete',\n",
    "                       'pay_FUFEI_continue', 'pay_FUFEI_discrete', 'target_QOE_continue', 'target_QOE_discrete',\n",
    "                       'target_CHONGHE_continue', 'target_CHONGHE_discrete', 'target_FUFEI_continue',\n",
    "                       'target_FUFEI_discrete']\n",
    "\n",
    "    # 形成对应需要的特征名称列表\n",
    "    feature_column_dict = {\n",
    "        'user_info_continue': user_feature_continue_column,  #[]\n",
    "        'user_info_discrete': user_feature_discrete_column,  #[]\n",
    "        'history_QOE_continue': user_history_pay_QOE_continue_column,\n",
    "        'history_QOE_discrete': user_history_pay_QOE_discrete_column,\n",
    "        'history_CHONGHE_continue': user_history_pay_CHONGHE_continue_column,\n",
    "        'history_CHONGHE_discrete': user_history_pay_CHONGHE_discrete_column,\n",
    "        'history_FUFEI_continue': user_history_pay_FUFEI_continue_column,\n",
    "        'history_FUFEI_discrete': user_history_pay_FUFEI_discrete_column,\n",
    "        'history_CHONGHE_discrete_add_D': user_history_pay_CHONGHE_discrete_column_add_D\n",
    "    }\n",
    "    # 创建一个空的DataFrame来存储结果\n",
    "    test_auc_df = pd.DataFrame(\n",
    "        columns=['时间', 'model', '运行位置', 'Type', 'dataset', 'train_ratio', 'feature_embedding', 'batchSize', 'lr',\n",
    "                 'max_history_len', '实验数', '测试集总损失', 'AUC', 'ACC', 'F1', 'Precision', 'Recall'])\n",
    "    test_weight_df = pd.DataFrame(\n",
    "        columns=['时间', 'model', '运行位置', 'Type', 'dataset', 'train_ratio', 'feature_embedding', 'batchSize', 'lr',\n",
    "                 'max_history_len', '实验数', 'se_user_pay_QOE_weight', 'se_user_pay_CHONGHE_weight',\n",
    "                 'se_user_pay_FUFEI_weight', 'se_target_QOE_weight', 'se_target_CHONGHE_weight',\n",
    "                 'se_target_FUFEI_weight', \\\n",
    "                 'target_history_pay_attention_QOE_weight', 'target_history_pay_attention_CHONGHE_weight',\n",
    "                 'target_history_pay_attention_FUFEI_weight'])\n",
    "    for i in range(5):\n",
    "        \"\"\"\n",
    "        主要用于在反向传播（backward pass）过程中，如果有任何计算图中的操作产生了异常，比如 NaN（不是数字）或者 inf（无限大）值，它会给出详细的错误信息\n",
    "        \"\"\"\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        print(f\"i=:{i + 1}\")\n",
    "        n = i\n",
    "        # 数据集 train、val、test划分及总数据hash表(以user_id为key的存储对应对应行的hash表)及不同类特征数存储的字典\n",
    "\n",
    "        # xxx_list: user_id的列表\n",
    "        # data_hash: 所有数据（包括训练、验证、测试）\n",
    "        # feature_category_num_dict: 各列的值的数量的字典 key:列名, value:数量\n",
    "        train_list, val_list, test_list, train_data_hash, data_hash, feature_category_num_dict = data_input(\n",
    "            data_time_windows, train_path, test_path, dataset_spilt_path, val_ratio, test_ratio, total_continue_feature)\n",
    "\n",
    "        # 获取训练、验证、测试集对应的数据形成的向量hash存储及label\n",
    "        # 数据以key-value形式存储，key为user_id，value的维度为(max_history_len, feature_num), label的维度为(1, batch)\n",
    "        train_data_tensor_hash, train_label, train_data_tensor_hash_history_mask = get_feature_to_matrix(train_list,\n",
    "                                                                                                         train_data_hash,\n",
    "                                                                                                         feature_column_dict)\n",
    "        val_data_tensor_hash, val_label, val_data_tensor_hash_history_mask = get_feature_to_matrix(val_list, data_hash,\n",
    "                                                                                                   feature_column_dict)\n",
    "        test_data_tensor_hash, test_label, test_data_tensor_hash_history_mask = get_feature_to_matrix(test_list,\n",
    "                                                                                                      data_hash,\n",
    "                                                                                                      feature_column_dict)\n",
    "        # 输出查看结果\n",
    "        # for key1 in train_data_tensor_hash.keys():\n",
    "        #     dimensions1 = train_data_tensor_hash[key1]['pay_QOE_continue'].size()\n",
    "        #     dimensions2 = train_data_tensor_hash[key1]['pay_QOE_discrete'].size()\n",
    "        #     dimensions3 = train_data_tensor_hash[key1]['pay_CHONGHE_continue'].size()\n",
    "        #     dimensions4 = train_data_tensor_hash[key1]['target_QOE_continue'].size()\n",
    "        #     dimensions5 = train_data_tensor_hash[key1]['target_QOE_discrete'].size()\n",
    "        #     dimensions6 = train_data_tensor_hash[key1]['target_CHONGHE_continue'].size()\n",
    "        #     print(\"val_data_tensor_hash size=\", dimensions1,dimensions2,dimensions3,dimensions4,dimensions5,dimensions6)\n",
    "\n",
    "        # 生成batch再添加维度对齐张量（三个维度）这里张量输出的全是三维 (batch_size, 1 or max_history_len, feature_num)\n",
    "        train_batch_feature_tensor_dict = generate_user_feature_alignment_tensor(train_list, train_data_tensor_hash)\n",
    "        val_batch_feature_tensor_dict = generate_user_feature_alignment_tensor(val_list, val_data_tensor_hash)\n",
    "        test_batch_feature_tensor_dict = generate_user_feature_alignment_tensor(test_list, test_data_tensor_hash)\n",
    "\n",
    "        train_label_tensor = torch.tensor(train_label)\n",
    "        val_label_tensor = torch.tensor(val_label)\n",
    "        test_label_tensor = torch.tensor(test_label)\n",
    "\n",
    "        train_label_tensor = train_label_tensor.unsqueeze(-1)\n",
    "        val_label_tensor = val_label_tensor.unsqueeze(-1)\n",
    "        test_label_tensor = test_label_tensor.unsqueeze(-1)  # 在最后新增一个维度，因为TensorDataset要第一维大小相同 label变为(batch,1)\n",
    "        # mask矩阵的字典\n",
    "        train_batch_feature_tensor_history_mask_dict = generate_user_feature_alignment_tensor(train_list,\n",
    "                                                                                              train_data_tensor_hash_history_mask,\n",
    "                                                                                              is_mask=True)\n",
    "        val_batch_feature_tensor_history_mask_dict = generate_user_feature_alignment_tensor(val_list,\n",
    "                                                                                            val_data_tensor_hash_history_mask,\n",
    "                                                                                            is_mask=True)\n",
    "        test_batch_feature_tensor_history_mask_dict = generate_user_feature_alignment_tensor(test_list,\n",
    "                                                                                             test_data_tensor_hash_history_mask,\n",
    "                                                                                             is_mask=True)\n",
    "        print('张量生成完成')\n",
    "\n",
    "        # # TensorDataset输入得是张量，因此由字典转为张量\n",
    "        train_batch_feature_tensor_pay_QOE_discrete = train_batch_feature_tensor_dict['pay_QOE_discrete']\n",
    "        train_batch_feature_tensor_pay_CHONGHE_discrete = train_batch_feature_tensor_dict['pay_CHONGHE_discrete']\n",
    "        train_batch_feature_tensor_pay_FUFEI_discrete = train_batch_feature_tensor_dict['pay_FUFEI_discrete']\n",
    "        train_batch_feature_tensor_pay_QOE_continue = train_batch_feature_tensor_dict['pay_QOE_continue']\n",
    "        train_batch_feature_tensor_pay_CHONGHE_continue = train_batch_feature_tensor_dict['pay_CHONGHE_continue']\n",
    "        train_batch_feature_tensor_pay_FUFEI_continue = train_batch_feature_tensor_dict['pay_FUFEI_continue']\n",
    "        train_batch_feature_tensor_target_QOE_discrete = train_batch_feature_tensor_dict['target_QOE_discrete']\n",
    "        train_batch_feature_tensor_target_CHONGHE_discrete = train_batch_feature_tensor_dict['target_CHONGHE_discrete']\n",
    "        train_batch_feature_tensor_target_FUFEI_discrete = train_batch_feature_tensor_dict['target_FUFEI_discrete']\n",
    "        train_batch_feature_tensor_target_QOE_continue = train_batch_feature_tensor_dict['target_QOE_continue']\n",
    "        train_batch_feature_tensor_target_CHONGHE_continue = train_batch_feature_tensor_dict['target_CHONGHE_continue']\n",
    "        train_batch_feature_tensor_target_FUFEI_continue = train_batch_feature_tensor_dict['target_FUFEI_continue']\n",
    "        train_batch_feature_tensor_pay_QOE_discrete_mask = train_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_QOE_discrete']\n",
    "        train_batch_feature_tensor_pay_CHONGHE_discrete_mask = train_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_CHONGHE_discrete']\n",
    "        train_batch_feature_tensor_pay_FUFEI_discrete_mask = train_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_FUFEI_discrete']\n",
    "        train_batch_feature_tensor_pay_QOE_continue_mask = train_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_QOE_continue']\n",
    "        train_batch_feature_tensor_pay_CHONGHE_continue_mask = train_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_CHONGHE_continue']\n",
    "        train_batch_feature_tensor_pay_FUFEI_continue_mask = train_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_FUFEI_continue']\n",
    "\n",
    "        val_batch_feature_tensor_pay_QOE_discrete = val_batch_feature_tensor_dict['pay_QOE_discrete']\n",
    "        val_batch_feature_tensor_pay_CHONGHE_discrete = val_batch_feature_tensor_dict['pay_CHONGHE_discrete']\n",
    "        val_batch_feature_tensor_pay_FUFEI_discrete = val_batch_feature_tensor_dict['pay_FUFEI_discrete']\n",
    "        val_batch_feature_tensor_pay_QOE_continue = val_batch_feature_tensor_dict['pay_QOE_continue']\n",
    "        val_batch_feature_tensor_pay_CHONGHE_continue = val_batch_feature_tensor_dict['pay_CHONGHE_continue']\n",
    "        val_batch_feature_tensor_pay_FUFEI_continue = val_batch_feature_tensor_dict['pay_FUFEI_continue']\n",
    "        val_batch_feature_tensor_target_QOE_discrete = val_batch_feature_tensor_dict['target_QOE_discrete']\n",
    "        val_batch_feature_tensor_target_CHONGHE_discrete = val_batch_feature_tensor_dict['target_CHONGHE_discrete']\n",
    "        val_batch_feature_tensor_target_FUFEI_discrete = val_batch_feature_tensor_dict['target_FUFEI_discrete']\n",
    "        val_batch_feature_tensor_target_QOE_continue = val_batch_feature_tensor_dict['target_QOE_continue']\n",
    "        val_batch_feature_tensor_target_CHONGHE_continue = val_batch_feature_tensor_dict['target_CHONGHE_continue']\n",
    "        val_batch_feature_tensor_target_FUFEI_continue = val_batch_feature_tensor_dict['target_FUFEI_continue']\n",
    "        val_batch_feature_tensor_pay_QOE_discrete_mask = val_batch_feature_tensor_history_mask_dict['pay_QOE_discrete']\n",
    "        val_batch_feature_tensor_pay_CHONGHE_discrete_mask = val_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_CHONGHE_discrete']\n",
    "        val_batch_feature_tensor_pay_FUFEI_discrete_mask = val_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_FUFEI_discrete']\n",
    "        val_batch_feature_tensor_pay_QOE_continue_mask = val_batch_feature_tensor_history_mask_dict['pay_QOE_continue']\n",
    "        val_batch_feature_tensor_pay_CHONGHE_continue_mask = val_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_CHONGHE_continue']\n",
    "        val_batch_feature_tensor_pay_FUFEI_continue_mask = val_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_FUFEI_continue']\n",
    "\n",
    "        test_batch_feature_tensor_pay_QOE_discrete = test_batch_feature_tensor_dict['pay_QOE_discrete']\n",
    "        test_batch_feature_tensor_pay_CHONGHE_discrete = test_batch_feature_tensor_dict['pay_CHONGHE_discrete']\n",
    "        test_batch_feature_tensor_pay_FUFEI_discrete = test_batch_feature_tensor_dict['pay_FUFEI_discrete']\n",
    "        test_batch_feature_tensor_pay_QOE_continue = test_batch_feature_tensor_dict['pay_QOE_continue']\n",
    "        test_batch_feature_tensor_pay_CHONGHE_continue = test_batch_feature_tensor_dict['pay_CHONGHE_continue']\n",
    "        test_batch_feature_tensor_pay_FUFEI_continue = test_batch_feature_tensor_dict['pay_FUFEI_continue']\n",
    "        test_batch_feature_tensor_target_QOE_discrete = test_batch_feature_tensor_dict['target_QOE_discrete']\n",
    "        test_batch_feature_tensor_target_CHONGHE_discrete = test_batch_feature_tensor_dict['target_CHONGHE_discrete']\n",
    "        test_batch_feature_tensor_target_FUFEI_discrete = test_batch_feature_tensor_dict['target_FUFEI_discrete']\n",
    "        test_batch_feature_tensor_target_QOE_continue = test_batch_feature_tensor_dict['target_QOE_continue']\n",
    "        test_batch_feature_tensor_target_CHONGHE_continue = test_batch_feature_tensor_dict['target_CHONGHE_continue']\n",
    "        test_batch_feature_tensor_target_FUFEI_continue = test_batch_feature_tensor_dict['target_FUFEI_continue']\n",
    "        test_batch_feature_tensor_pay_QOE_discrete_mask = test_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_QOE_discrete']\n",
    "        test_batch_feature_tensor_pay_CHONGHE_discrete_mask = test_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_CHONGHE_discrete']\n",
    "        test_batch_feature_tensor_pay_FUFEI_discrete_mask = test_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_FUFEI_discrete']\n",
    "        test_batch_feature_tensor_pay_QOE_continue_mask = test_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_QOE_continue']\n",
    "        test_batch_feature_tensor_pay_CHONGHE_continue_mask = test_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_CHONGHE_continue']\n",
    "        test_batch_feature_tensor_pay_FUFEI_continue_mask = test_batch_feature_tensor_history_mask_dict[\n",
    "            'pay_FUFEI_continue']\n",
    "\n",
    "        # 训练集\n",
    "        train_dataset = TensorDataset(train_batch_feature_tensor_pay_QOE_discrete,\n",
    "                                      train_batch_feature_tensor_pay_CHONGHE_discrete,\n",
    "                                      train_batch_feature_tensor_pay_FUFEI_discrete,\n",
    "                                      train_batch_feature_tensor_pay_QOE_continue,\n",
    "                                      train_batch_feature_tensor_pay_CHONGHE_continue,\n",
    "                                      train_batch_feature_tensor_pay_FUFEI_continue,\n",
    "                                      train_batch_feature_tensor_target_QOE_discrete,\n",
    "                                      train_batch_feature_tensor_target_CHONGHE_discrete,\n",
    "                                      train_batch_feature_tensor_target_FUFEI_discrete,\n",
    "                                      train_batch_feature_tensor_target_QOE_continue,\n",
    "                                      train_batch_feature_tensor_target_CHONGHE_continue,\n",
    "                                      train_batch_feature_tensor_target_FUFEI_continue,\n",
    "                                      train_batch_feature_tensor_pay_QOE_discrete_mask,\n",
    "                                      train_batch_feature_tensor_pay_CHONGHE_discrete_mask,\n",
    "                                      train_batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "                                      train_batch_feature_tensor_pay_QOE_continue_mask,\n",
    "                                      train_batch_feature_tensor_pay_CHONGHE_continue_mask,\n",
    "                                      train_batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "                                      train_label_tensor)\n",
    "        val_dataset = TensorDataset(val_batch_feature_tensor_pay_QOE_discrete,\n",
    "                                    val_batch_feature_tensor_pay_CHONGHE_discrete,\n",
    "                                    val_batch_feature_tensor_pay_FUFEI_discrete,\n",
    "                                    val_batch_feature_tensor_pay_QOE_continue,\n",
    "                                    val_batch_feature_tensor_pay_CHONGHE_continue,\n",
    "                                    val_batch_feature_tensor_pay_FUFEI_continue,\n",
    "                                    val_batch_feature_tensor_target_QOE_discrete,\n",
    "                                    val_batch_feature_tensor_target_CHONGHE_discrete,\n",
    "                                    val_batch_feature_tensor_target_FUFEI_discrete,\n",
    "                                    val_batch_feature_tensor_target_QOE_continue,\n",
    "                                    val_batch_feature_tensor_target_CHONGHE_continue,\n",
    "                                    val_batch_feature_tensor_target_FUFEI_continue,\n",
    "                                    val_batch_feature_tensor_pay_QOE_discrete_mask,\n",
    "                                    val_batch_feature_tensor_pay_CHONGHE_discrete_mask,\n",
    "                                    val_batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "                                    val_batch_feature_tensor_pay_QOE_continue_mask,\n",
    "                                    val_batch_feature_tensor_pay_CHONGHE_continue_mask,\n",
    "                                    val_batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "                                    val_label_tensor)\n",
    "\n",
    "\n",
    "        # # 训练集\n",
    "        # train_dataset = TensorDataset(*train_batch_feature_tensor, *train_batch_feature_tensor_history_mask, train_label_tensor)\n",
    "        # val_dataset = TensorDataset(*val_batch_feature_tensor, *val_batch_feature_tensor_history_mask, val_label_tensor)\n",
    "\n",
    "        # 创建数据加载器\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)  # 记得改回随机\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "        # 确保您的计算机上有CUDA支持的GPU\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # 创建大模型的实例\n",
    "        model = MatchingModel(feature_category_num_dict, feature_column_dict, continue_embedding_dim,\n",
    "                              discrete_embedding_dim, num_heads, feature_dim, max_history_len)\n",
    "        print('模型搭建完成')\n",
    "        model.to(device)\n",
    "        # 进一步处理 列表转移到GPU\n",
    "        for i in range(len(model.user_history_pay_embedding_layer.user_pay_history_QOE_discrete_embeddings)):\n",
    "            model.user_history_pay_embedding_layer.user_pay_history_QOE_discrete_embeddings[i] = \\\n",
    "                model.user_history_pay_embedding_layer.user_pay_history_QOE_discrete_embeddings[i].to(device)\n",
    "        for i in range(len(model.user_history_pay_embedding_layer.user_pay_history_CHONGHE_discrete_embeddings)):\n",
    "            model.user_history_pay_embedding_layer.user_pay_history_CHONGHE_discrete_embeddings[i] = \\\n",
    "                model.user_history_pay_embedding_layer.user_pay_history_CHONGHE_discrete_embeddings[i].to(device)\n",
    "        for i in range(len(model.user_history_pay_embedding_layer.user_pay_history_FUFEI_discrete_embeddings)):\n",
    "            model.user_history_pay_embedding_layer.user_pay_history_FUFEI_discrete_embeddings[i] = \\\n",
    "                model.user_history_pay_embedding_layer.user_pay_history_FUFEI_discrete_embeddings[i].to(device)\n",
    "        for i in range(len(model.user_history_pay_embedding_layer.user_pay_history_QOE_continue_embedding)):\n",
    "            model.user_history_pay_embedding_layer.user_pay_history_QOE_continue_embedding[i] = \\\n",
    "                model.user_history_pay_embedding_layer.user_pay_history_QOE_continue_embedding[i].to(device)\n",
    "        for i in range(len(model.user_history_pay_embedding_layer.user_pay_history_CHONGHE_continue_embedding)):\n",
    "            model.user_history_pay_embedding_layer.user_pay_history_CHONGHE_continue_embedding[i] = \\\n",
    "                model.user_history_pay_embedding_layer.user_pay_history_CHONGHE_continue_embedding[i].to(device)\n",
    "        for i in range(len(model.user_history_pay_embedding_layer.user_pay_history_FUFEI_continue_embedding)):\n",
    "            model.user_history_pay_embedding_layer.user_pay_history_FUFEI_continue_embedding[i] = \\\n",
    "                model.user_history_pay_embedding_layer.user_pay_history_FUFEI_continue_embedding[i].to(device)\n",
    "\n",
    "        for i in range(len(model.target_embedding_layer.target_QOE_discrete_embeddings)):\n",
    "            model.target_embedding_layer.target_QOE_discrete_embeddings[i] = \\\n",
    "                model.target_embedding_layer.target_QOE_discrete_embeddings[i].to(device)\n",
    "        for i in range(len(model.target_embedding_layer.target_CHONGHE_discrete_embeddings)):\n",
    "            model.target_embedding_layer.target_CHONGHE_discrete_embeddings[i] = \\\n",
    "                model.target_embedding_layer.target_CHONGHE_discrete_embeddings[i].to(device)\n",
    "        for i in range(len(model.target_embedding_layer.target_FUFEI_discrete_embeddings)):\n",
    "            model.target_embedding_layer.target_FUFEI_discrete_embeddings[i] = \\\n",
    "                model.target_embedding_layer.target_FUFEI_discrete_embeddings[i].to(device)\n",
    "        for i in range(len(model.target_embedding_layer.target_QOE_continue_embedding)):\n",
    "            model.target_embedding_layer.target_QOE_continue_embedding[i] = \\\n",
    "                model.target_embedding_layer.target_QOE_continue_embedding[i].to(device)\n",
    "        for i in range(len(model.target_embedding_layer.target_CHONGHE_continue_embedding)):\n",
    "            model.target_embedding_layer.target_CHONGHE_continue_embedding[i] = \\\n",
    "                model.target_embedding_layer.target_CHONGHE_continue_embedding[i].to(device)\n",
    "        for i in range(len(model.target_embedding_layer.target_FUFEI_continue_embedding)):\n",
    "            model.target_embedding_layer.target_FUFEI_continue_embedding[i] = \\\n",
    "                model.target_embedding_layer.target_FUFEI_continue_embedding[i].to(device)\n",
    "        print('模型转移到GPU完成')\n",
    "        lossfunction = nn.BCELoss()\n",
    "        #     optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9)\n",
    "\n",
    "        # 训练\n",
    "        model_training(model, train_loader, val_loader, lossfunction, optimizer, 500, device)\n",
    "        print('模型训练完成')\n",
    "        print('||--------训练结束时间：', datetime.datetime.now(), '-------------')\n",
    "        # 测试\n",
    "        test_dataset = TensorDataset(test_batch_feature_tensor_pay_QOE_discrete,\n",
    "                                     test_batch_feature_tensor_pay_CHONGHE_discrete,\n",
    "                                     test_batch_feature_tensor_pay_FUFEI_discrete,\n",
    "                                     test_batch_feature_tensor_pay_QOE_continue,\n",
    "                                     test_batch_feature_tensor_pay_CHONGHE_continue,\n",
    "                                     test_batch_feature_tensor_pay_FUFEI_continue,\n",
    "                                     test_batch_feature_tensor_target_QOE_discrete,\n",
    "                                     test_batch_feature_tensor_target_CHONGHE_discrete,\n",
    "                                     test_batch_feature_tensor_target_FUFEI_discrete,\n",
    "                                     test_batch_feature_tensor_target_QOE_continue,\n",
    "                                     test_batch_feature_tensor_target_CHONGHE_continue,\n",
    "                                     test_batch_feature_tensor_target_FUFEI_continue,\n",
    "                                     test_batch_feature_tensor_pay_QOE_discrete_mask,\n",
    "                                     test_batch_feature_tensor_pay_CHONGHE_discrete_mask,\n",
    "                                     test_batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "                                     test_batch_feature_tensor_pay_QOE_continue_mask,\n",
    "                                     test_batch_feature_tensor_pay_CHONGHE_continue_mask,\n",
    "                                     test_batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "                                     test_label_tensor)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "        average_loss_test, average_auc_test, average_acc_test, average_f1_test, average_precision_test, average_recall_test, weight_result_dict = test_model(\n",
    "            model, test_loader)\n",
    "        # 测试的每个样本结果保存到csv\n",
    "        # 将本次训练的结果添加到DataFrame中\n",
    "        test_auc_df = test_auc_df.append(\n",
    "            {'时间': datetime.datetime.now(), 'model': 'model3.1', '运行位置': 'GPU', 'Type': 'Origin',\n",
    "             'dataset': data_time_windows, 'feature_embedding': feature_dim, 'batchSize': batch_size, 'lr': lr,\n",
    "             'max_history_len': max_history_len, '实验数': i + 1, '测试集总损失': average_loss_test,\n",
    "             'AUC': average_auc_test, 'ACC': average_acc_test, 'F1': average_f1_test,\n",
    "             'Precision': average_precision_test, 'Recall': average_recall_test}, ignore_index=True)\n",
    "        weight_result = {'时间': datetime.datetime.now(), 'model': 'model3.1', '运行位置': 'GPU', 'Type': 'Origin',\n",
    "                         'dataset': data_time_windows, 'feature_embedding': feature_dim, 'batchSize': batch_size,\n",
    "                         'lr': lr, 'max_history_len': max_history_len, '实验数': i + 1, \\\n",
    "                         'se_user_pay_QOE_weight': weight_result_dict['se_user_pay_QOE_weight'],\n",
    "                         'se_user_pay_CHONGHE_weight': weight_result_dict['se_user_pay_CHONGHE_weight'], \\\n",
    "                         'se_user_pay_FUFEI_weight': weight_result_dict['se_user_pay_FUFEI_weight'],\n",
    "                         'se_target_QOE_weight': weight_result_dict['se_target_QOE_weight'], \\\n",
    "                         'se_target_CHONGHE_weight': weight_result_dict['se_target_CHONGHE_weight'],\n",
    "                         'se_target_FUFEI_weight': weight_result_dict['se_target_FUFEI_weight'], \\\n",
    "                         'target_history_pay_attention_QOE_weight': weight_result_dict[\n",
    "                             'target_history_pay_attention_QOE_weight'], \\\n",
    "                         'target_history_pay_attention_CHONGHE_weight': weight_result_dict[\n",
    "                             'target_history_pay_attention_CHONGHE_weight'], \\\n",
    "                         'target_history_pay_attention_FUFEI_weight': weight_result_dict[\n",
    "                             'target_history_pay_attention_FUFEI_weight']}\n",
    "        test_weight_df = test_weight_df.append(weight_result, ignore_index=True)\n",
    "    # 将结果保存到CSV文件中\n",
    "    with open(data_path + 'maoerDL_result_maoer_pay_pred_model3_1.csv', 'a') as f:\n",
    "        test_auc_df.to_csv(f, index=False)\n",
    "    with open(data_path + 'maoerDL_result_maoer_pay_pred_weight_model3_1.csv', 'a') as f:\n",
    "        test_weight_df.to_csv(f, index=False)\n",
    "    #     test_auc_df.to_csv('./Dataset/maoerDL_result_maoer_pay_pred_model3_1.csv', index=False)\n",
    "    #     test_weight_df.to_csv('./Dataset/maoerDL_result_maoer_pay_pred_weight_model3_1.csv', index=False)\n",
    "    print('结果已输出')\n",
    "    print('||--------当前时间窗', data_time_windows, '结束时间：', datetime.datetime.now(), '-------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f4de78-e6d2-4b0c-ab58-5a7cc163e30b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:05:51.337696Z",
     "start_time": "2024-06-19T09:05:51.318553Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3bad54",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-19T09:05:51.321948Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
