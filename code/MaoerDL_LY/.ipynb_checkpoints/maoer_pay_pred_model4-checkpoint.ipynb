{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "042e0f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--------开始时间： 2024-03-12 10:34:41.121615 -------------\n"
     ]
    }
   ],
   "source": [
    "# maoer_data深度学习模型 双层注意力机制  第4版 改回付费与非付费对比学习\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "# from torch.nn.functional import cosine_similarity\n",
    "import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('||--------开始时间：',datetime.datetime.now(),'-------------')\n",
    "# data input\n",
    "data_time_windows = '1101_1130'\n",
    "path = './Dataset/' + data_time_windows + '_user_pay_pred_feature_deal.csv'\n",
    "dataset_spilt_path = './Dataset/' + data_time_windows + '_user_pay_pred_feature_spilt.csv'\n",
    "data_feature_continue_discrete_namelist_path = './Dataset/maoer_timewindows_continue_discrete_feature_column.csv'    # 连续与离散划分表\n",
    "output_weight_result_path = './Dataset/' + data_time_windows + '_user_pay_pred_result_weight.csv'\n",
    "\n",
    "# 参数设置\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "num_heads = 10\n",
    "feature_dim = 200\n",
    "max_history_len = 6\n",
    "num_experts = 3\n",
    "num_tasks = 2\n",
    "# 设置嵌入维度\n",
    "continue_embedding_dim = 200\n",
    "discrete_embedding_dim = 200\n",
    "lr = 0.5\n",
    "batch_size = 128\n",
    "threshold = 0.5\n",
    "# 真实数据集中标签后面，要将它映射到 0,1，中间判断是否付费也要用\n",
    "label_True = 2\n",
    "label_False = 1\n",
    "\n",
    "\n",
    "\n",
    "# 获取时间窗内连续与离散特征名的列表\n",
    "def get_continue_discrete_feature_namelist(time_windows, datapath):\n",
    "    data = pd.read_csv(datapath)\n",
    "    time_windows_data = data[(data['DataSet'] == time_windows)]\n",
    "    user_history_pay_QOE_continue_column = eval([time_windows_data['QOE_continue'].values.tolist()][0][0])\n",
    "    user_history_pay_CHONGHE_continue_column = eval([time_windows_data['CHONGHE_continue'].values.tolist()][0][0])\n",
    "    user_history_pay_FUFEI_continue_column = eval([time_windows_data['FUFEI_continue'].values.tolist()][0][0])\n",
    "    user_history_pay_QOE_discrete_column = eval([time_windows_data['QOE_discrete'].values.tolist()][0][0])\n",
    "    user_history_pay_CHONGHE_discrete_column = eval([time_windows_data['CHONGHE_discrete'].values.tolist()][0][0])\n",
    "    user_history_pay_FUFEI_discrete_column = eval([time_windows_data['FUFEI_discrete'].values.tolist()][0][0])\n",
    "\n",
    "\n",
    "    return user_history_pay_QOE_continue_column, user_history_pay_CHONGHE_continue_column,user_history_pay_FUFEI_continue_column,\\\n",
    "            user_history_pay_QOE_discrete_column,user_history_pay_CHONGHE_discrete_column,user_history_pay_FUFEI_discrete_column\n",
    "\n",
    "# # user history bav\n",
    "# user_history_pay_QOE_continue_column = ['user_in_sound_submit_review_num','user_in_sound_submit_danmu_total_len','sound_view_num','sound_danmu_num','sound_review_avg_len','drama_total_sound_num','drama_sound_has_max_cv_num_sound_point_num','drama_upuser_submit_sound_max_view_num','drama_sound_min_time_sound_view_num','pcm_RMSenergy_sma_range numeric','pcm_fftMag_mfcc_sma[1]_maxPos numeric','pcm_fftMag_mfcc_sma[2]_max numeric','pcm_fftMag_mfcc_sma[5]_min numeric','pcm_fftMag_mfcc_sma[8]_maxPos numeric','pcm_fftMag_mfcc_sma[10]_max numeric','voiceProb_sma_stddev numeric','F0_sma_stddev numeric','pcm_fftMag_mfcc_sma_de[4]_min numeric','pcm_fftMag_mfcc_sma_de[6]_maxPos numeric','pcm_fftMag_mfcc_sma_de[8]_kurtosis numeric','pcm_fftMag_mfcc_sma_de[9]_min numeric','pcm_fftMag_mfcc_sma_de[10]_linregc1 numeric']\n",
    "# user_history_pay_CHONGHE_continue_column = ['user_name_len','user_intro_len','user_fish_num','user_follower_num','user_subscribe_drama_num','user_submit_danmu_drama_total_view_num','user_submit_danmu_drama_max_view_num','user_submit_danmu_drama_avg_view_num','user_submit_danmu_drama_total_danmu_num','user_submit_danmu_drama_max_danmu_num','user_submit_danmu_drama_min_danmu_num','user_submit_danmu_drama_avg_danmu_num','user_submit_danmu_drama_min_review_num','user_in_sound_submit_danmu_max_len','user_in_sound_submit_danmu_min_len','user_in_sound_submit_danmu_avg_len','user_in_sound_danmu_around_15s_total_danmu_max_num','user_in_sound_danmu_around_15s_total_danmu_min_num','user_in_sound_danmu_around_15s_total_danmu_avg_num','drama_upuser_submit_sound_avg_danmu_num','pcm_fftMag_mfcc_sma[5]_maxPos numeric','pcm_fftMag_mfcc_sma_de[10]_minPos numeric']\n",
    "# user_history_pay_FUFEI_continue_column = ['user_submit_danmu_drama_min_view_num','user_submit_danmu_drama_max_review_num','user_submit_danmu_drama_avg_review_num','drama_sound_has_min_view_num_sound_favorite_num','drama_sound_max_time_sound_view_num','drama_sound_min_traffic_position_in_sound_avg','pcm_fftMag_mfcc_sma[1]_range numeric','pcm_fftMag_mfcc_sma[1]_minPos numeric','pcm_fftMag_mfcc_sma[2]_min numeric','pcm_fftMag_mfcc_sma[2]_skewness numeric','pcm_fftMag_mfcc_sma[5]_range numeric','pcm_fftMag_mfcc_sma[6]_linregc1 numeric','pcm_fftMag_mfcc_sma[11]_kurtosis numeric','pcm_RMSenergy_sma_de_minPos numeric','pcm_fftMag_mfcc_sma_de[2]_max numeric','pcm_fftMag_mfcc_sma_de[4]_stddev numeric','pcm_fftMag_mfcc_sma_de[4]_skewness numeric','pcm_fftMag_mfcc_sma_de[5]_linregc1 numeric','pcm_fftMag_mfcc_sma_de[8]_amean numeric','pcm_fftMag_mfcc_sma_de[8]_skewness numeric','pcm_fftMag_mfcc_sma_de[9]_max numeric','pcm_fftMag_mfcc_sma_de[10]_linregerrQ numeric','pcm_fftMag_mfcc_sma_de[11]_maxPos numeric','voiceProb_sma_de_max numeric','F0_sma_de_linregerrQ numeric']\n",
    "# user_history_pay_QOE_discrete_column = ['user_name_has_english','user_in_sound_is_submit_review','drama_danmu_time_between_sound_time_in_7days_num_min']\n",
    "# user_history_pay_CHONGHE_discrete_column = ['user_name_has_chinese','user_intro_has_chinese','user_intro_has_english','user_submit_danmu_drama_completed_num_now','sound_title_len','sound_intro_len','sound_danmu_15s_max_traffic_position_in_sound']\n",
    "# user_history_pay_FUFEI_discrete_column = ['drama_intro_len','drama_upuser_subscriptions_num','drama_sound_max_traffic_position_in_sound_avg','label1']\n",
    "\n",
    "# 获取时间窗内连续与离散特征名的列表\n",
    "user_history_pay_QOE_continue_column, user_history_pay_CHONGHE_continue_column, \\\n",
    "        user_history_pay_FUFEI_continue_column, user_history_pay_QOE_discrete_column,\\\n",
    "        user_history_pay_CHONGHE_discrete_column, user_history_pay_FUFEI_discrete_column = get_continue_discrete_feature_namelist(data_time_windows, data_feature_continue_discrete_namelist_path)\n",
    "\n",
    "# total continue feature\n",
    "total_continue_feature = user_feature_continue_column+user_history_pay_QOE_continue_column+user_history_pay_CHONGHE_continue_column+user_history_pay_FUFEI_continue_column\n",
    "total_discrete_feature = user_feature_discrete_column+user_history_pay_QOE_discrete_column+user_history_pay_CHONGHE_discrete_column+user_history_pay_FUFEI_discrete_column\n",
    "tensor_dict_idx = ['pay_QOE_continue','pay_QOE_discrete','pay_CHONGHE_continue','pay_CHONGHE_discrete','pay_FUFEI_continue','pay_FUFEI_discrete','target_QOE_continue','target_QOE_discrete','target_CHONGHE_continue','target_CHONGHE_discrete','target_FUFEI_continue','target_FUFEI_discrete']\n",
    "# print(len(user_history_pay_QOE_continue_column),len(user_history_pay_CHONGHE_continue_column),len(user_history_pay_FUFEI_continue_column))\n",
    "# 形成对应需要的特征名称列表\n",
    "feature_column_dict = {\n",
    "    'user_info_continue': user_feature_continue_column,\n",
    "    'user_info_discrete': user_feature_discrete_column,\n",
    "    'history_QOE_continue': user_history_pay_QOE_continue_column,\n",
    "    'history_QOE_discrete': user_history_pay_QOE_discrete_column,\n",
    "    'history_CHONGHE_continue': user_history_pay_CHONGHE_continue_column,\n",
    "    'history_CHONGHE_discrete': user_history_pay_CHONGHE_discrete_column,\n",
    "    'history_FUFEI_continue': user_history_pay_FUFEI_continue_column,\n",
    "    'history_FUFEI_discrete': user_history_pay_FUFEI_discrete_column\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "db025e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n"
     ]
    }
   ],
   "source": [
    "# 1.数据处理+划分训练、验证、测试集\n",
    "\n",
    "# 划分数据集 给定输出后固定结果 输出形式定为存储user_id 形成train_dataset,val_dataset,test_dataset\n",
    "def split_data_unique(input_file, output_file, train_ratio, val_ratio, test_ratio):\n",
    "    df = pd.read_csv(input_file)\n",
    "    data = df[df.columns[0]].unique()  # 提取第一列数据并去重\n",
    "    # print(data)\n",
    "    np.random.shuffle(data)  # 随机打乱数据\n",
    "    # 划分数据\n",
    "    total_len = len(data)\n",
    "    x_end = int(total_len * train_ratio)\n",
    "    y_end = x_end + int(total_len * val_ratio)\n",
    "    train_data = data[:x_end]\n",
    "    val_data = data[x_end:y_end]\n",
    "    test_data = data[y_end:]\n",
    "    # 存储结果是去重的user_id\n",
    "    result = {\n",
    "        'Train': train_data,\n",
    "        'Val': val_data,\n",
    "        'Test': test_data\n",
    "    }   \n",
    "    # 创建每个子集的DataFrame  \n",
    "    train_df = pd.DataFrame(train_data, columns=['Train'])\n",
    "    val_df = pd.DataFrame(val_data, columns=['Val'])\n",
    "    test_df = pd.DataFrame(test_data, columns=['Test'])\n",
    "    # 将每个DataFrame转换为一列Series  \n",
    "    train_series = train_df.iloc[:, 0]\n",
    "    val_series = val_df.iloc[:, 0]\n",
    "    test_series = test_df.iloc[:, 0]\n",
    "    # 为了确保所有Series有相同的长度，我们需要找到最大长度并截断较短的Series  \n",
    "    max_len = max(len(train_series), len(val_series), len(test_series))\n",
    "    train_series = train_series.reindex(range(max_len)).fillna(value=pd.NA)\n",
    "    val_series = val_series.reindex(range(max_len)).fillna(value=pd.NA)\n",
    "    test_series = test_series.reindex(range(max_len)).fillna(value=pd.NA)\n",
    "    # 创建一个新的DataFrame，将Series作为列  \n",
    "    combined_df = pd.DataFrame({\n",
    "        'Train': train_series,\n",
    "        'Val': val_series,\n",
    "        'Test': test_series\n",
    "    })\n",
    "    # 写入CSV文件，不包含索引和列名  \n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print('已输出划分数据集结果')\n",
    "\n",
    "# 数据预处理 将连续特征变离散特征 分桶 不处理user_id、sound_id、drama_id、time\n",
    "def data_pre_deal(input_path,continue_feature_list):\n",
    "    df = pd.read_csv(input_path)\n",
    "    deal_data_df = [] # 待修改********\n",
    "    # # 获取离散特征的类别数量，并存储为字典\n",
    "    # category_counts = {}\n",
    "    # for column in deal_data_df.columns:\n",
    "    #     unique_values = deal_data_df[column].nunique()  # 获取列的唯一值数量\n",
    "    #     category_counts[column] = unique_values\n",
    "    print('数据预处理结束')\n",
    "    return df\n",
    "\n",
    "# 根据划分好的数据集中user_id 找到对应csv文件中对应user_id的所有行数据取出，即包含了历史数据（付费+非付费）+目标数据（最后一次行为）\n",
    "# def find_data_by_list(user_list, intput_data_df, data_hash):\n",
    "#     df = intput_data_df\n",
    "#     # result_list = []\n",
    "#     # 遍历列表中的值，在CSV文件中找到所有匹配的行数据并加入结果列表\n",
    "#     for user_id in user_list:\n",
    "#         result_df = df[df[df.columns[0]] == user_id]\n",
    "#         # result_list.append(result_df)\n",
    "#         if user_id in data_hash:\n",
    "#             data_hash[user_id].update({col: result_df for col in df.columns})  # 使用列名作为键\n",
    "#         else:\n",
    "#             data_hash[user_id] = {col: result_df for col in df.columns}\n",
    "#     #result = pd.concat(result_list)  # 合并所有匹配的行数据\n",
    "#     return data_hash\n",
    "\n",
    "def find_data_by_list(user_list, intput_data_df, data_hash):  \n",
    "    # 遍历列表中的值，在DataFrame中找到所有匹配的行数据并加入data_hash  \n",
    "    for user_id in user_list:  \n",
    "        result_df = intput_data_df[intput_data_df[intput_data_df.columns[0]] == user_id]  \n",
    "        data_hash[user_id] = result_df  # 直接存储DataFrame对象  \n",
    "    return data_hash\n",
    "    \n",
    "# 获取列唯一值数量表，并对离散特征的值转化为从0开始的索引\n",
    "def get_unique_feature_num_and_discrete_valueChange(datadf,discrete_feature_column_list):\n",
    "    # 获取离散特征的类别数量，并存储为字典\n",
    "    feature_category_num_dict = {}\n",
    "    for column in datadf.columns:\n",
    "        unique_values_len = datadf[column].nunique()  # 获取列的唯一值数量\n",
    "        feature_category_num_dict[column] = unique_values_len\n",
    "        if column in discrete_feature_column_list:\n",
    "            unique_values = datadf[column].unique()\n",
    "            value_mapping_dict = {value: index for index, value in enumerate(unique_values) if\n",
    "                              value != -1 and value != '' and value is not None}\n",
    "            datadf[column] = datadf[column].map(value_mapping_dict)\n",
    "    return feature_category_num_dict,datadf\n",
    "\n",
    "# 总的特征输入，生成划分后数据集及其输入\n",
    "def data_input(data_time_windows, path, spilt_outpath, train_ratio, val_ratio, test_ratio, total_continue_feature):\n",
    "    dataset_path = path  # 待修改********\n",
    "    dataset_spilt_path = spilt_outpath  # 待修改********\n",
    "    if os.path.exists(dataset_spilt_path):  # 划分训练、验证、测试集\n",
    "        print(\"划分文件已存在，不再进行数据划分\")\n",
    "    else:\n",
    "        split_data_unique(dataset_path, dataset_spilt_path, train_ratio, val_ratio, test_ratio)\n",
    "    deal_data_df = data_pre_deal(dataset_path, total_continue_feature)  # 数据预处理\n",
    "    # print('deal_data_df',deal_data_df)\n",
    "    # 获取离散特征的类别数量，并存储为字典\n",
    "    feature_category_num_dict,deal_data_df  = get_unique_feature_num_and_discrete_valueChange(deal_data_df,total_discrete_feature)\n",
    "    # print('deal_data_df',deal_data_df)\n",
    "    # 读取划分文件的结果\n",
    "    spilt_data_df = pd.read_csv(dataset_spilt_path)\n",
    "    # 输出每一列数据为列表\n",
    "    train_list = spilt_data_df['Train'].tolist()\n",
    "    val_list = spilt_data_df['Val'].tolist()\n",
    "    test_list = spilt_data_df['Test'].tolist()\n",
    "    train_list = [x for x in train_list if not math.isnan(x)]\n",
    "    val_list = [x for x in val_list if not math.isnan(x)]\n",
    "    test_list = [x for x in test_list if not math.isnan(x)]\n",
    "    # print('训练集、验证集、测试集大小=', len(train_list),len(val_list),len(test_list))\n",
    "    # 根据划分好的生成以user_id为key的hash（特征集合）将最后一行看做目标数据\n",
    "    data_hash = {}  # 存成一个hash形式\n",
    "    find_data_by_list(train_list, deal_data_df, data_hash)\n",
    "    find_data_by_list(val_list, deal_data_df, data_hash)\n",
    "    find_data_by_list(test_list, deal_data_df, data_hash)\n",
    "    print('数据划分完成')\n",
    "    # print(feature_category_num_dict)\n",
    "    return train_list, val_list, test_list, data_hash, feature_category_num_dict\n",
    "\n",
    "# test\n",
    "# 数据集 train、val、test划分及总数据hash表(以user_id为key的存储对应对应行的hash表)及不同类特征数存储的字典\n",
    "train_list, val_list, test_list, data_hash, feature_category_num_dict = data_input(data_time_windows, path,dataset_spilt_path, train_ratio, val_ratio, test_ratio, total_continue_feature)\n",
    "# print(data_hash[3617476])\n",
    "# print(feature_category_num_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "59420a1d-a80d-4242-80c7-bc15ea0497dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch张量的维度： torch.Size([6, 23]) torch.Size([6, 2]) torch.Size([6, 18]) torch.Size([23]) torch.Size([2]) torch.Size([18])\n",
      "PyTorch添加batch后张量的维度： torch.Size([6, 23]) torch.Size([6, 2]) torch.Size([6, 18]) torch.Size([23]) torch.Size([2]) torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "# 2. 形成张量矩阵 目标特征为：（batch,1,feature_num; 用户历史行为特征为（batch,max_history_len(固定长度的历史记录数),feature_num）\n",
    "\n",
    "# mask 对用户历史行为长度的固定\n",
    "# 转换 history 列为长度为max_history_len的数组\n",
    "def process_history(history, max_history_len):\n",
    "    if len(history) >= max_history_len:\n",
    "        processed_history = history[-max_history_len:]\n",
    "    else:\n",
    "        processed_history = [-1] * (max_history_len - len(history)) + history\n",
    "    return processed_history\n",
    "# 将填充-1的位置标记为True\n",
    "def create_mask(history):\n",
    "    mask = [True if item == -1 else False for item in history]\n",
    "    return mask\n",
    "# 将历史行为记录处理为固定长度并进行mask\n",
    "def history_feature_mask(user_history_feature_index, data_matrix_user_history, max_history_len):\n",
    "    mask_history_feature_matrix = []\n",
    "    origin_history_feature_matrix = []\n",
    "    for feature_index in range(len(user_history_feature_index)):\n",
    "        feature_data = [data_row[feature_index] for data_row in data_matrix_user_history]  # 获取一列特征值\n",
    "        processed_feature_data = process_history(feature_data, max_history_len)  # 处理为固定长度 max_history_len\n",
    "        origin_history_feature_matrix.append(processed_feature_data)\n",
    "        mask_feature_data = create_mask(processed_feature_data)  # 将空的mask\n",
    "        mask_history_feature_matrix.append(mask_feature_data)\n",
    "        \n",
    "    # print('mask',len(origin_history_feature_matrix),len(origin_history_feature_matrix[0]))\n",
    "    return origin_history_feature_matrix, mask_history_feature_matrix\n",
    "\n",
    "# 将输入形成的data_hash和连续、离散特征列名,按照划分的训练或测试的user_id的列表，提取用户特征形成张量矩阵存储到data_tensor_hash中，以user_id为key，多个张量矩阵为value\n",
    "def get_feature_to_matrix(train_or_val_or_test_list, data_hash, feature_column_dict):\n",
    "    # 存储新的张量hash\n",
    "    data_tensor_hash = {}\n",
    "    # 存储历史记录的掩码矩阵\n",
    "    data_tensor_history_mask_hash = {}\n",
    "    target_label = []  # 预测目标值的标签\n",
    "\n",
    "    for user_id in train_or_val_or_test_list:\n",
    "        user_data = data_hash[user_id]\n",
    "        # 创建空的二维矩阵\n",
    "        # data_matrix_user_info_continue = []\n",
    "        # data_matrix_user_info_discrete = []\n",
    "        data_matrix_pay_QOE_continue = []\n",
    "        data_matrix_pay_QOE_discrete = []\n",
    "        data_matrix_pay_CHONGHE_continue = []\n",
    "        data_matrix_pay_CHONGHE_discrete = []\n",
    "        data_matrix_pay_FUFEI_continue = []\n",
    "        data_matrix_pay_FUFEI_discrete = []\n",
    "        data_matrix_not_pay_QOE_continue = []\n",
    "        data_matrix_not_pay_QOE_discrete = []\n",
    "        data_matrix_not_pay_CHONGHE_continue = []\n",
    "        data_matrix_not_pay_CHONGHE_discrete = []\n",
    "        data_matrix_not_pay_FUFEI_continue = []\n",
    "        data_matrix_not_pay_FUFEI_discrete = []\n",
    "        data_matrix_target_QOE_continue = []\n",
    "        data_matrix_target_CHONGHE_continue = []\n",
    "        data_matrix_target_FUFEI_continue = []\n",
    "        data_matrix_target_QOE_discrete = []\n",
    "        data_matrix_target_CHONGHE_discrete = []\n",
    "        data_matrix_target_FUFEI_discrete = []\n",
    "        # 提取特征列对应的索引\n",
    "        # user_feature_continue_index = [user_data.columns.get_loc(col) for col in feature_column_dict['user_info_continue'] if col in user_data.columns]\n",
    "        # user_feature_discrete_index = [user_data.columns.get_loc(col) for col in feature_column_dict['user_info_discrete'] if\n",
    "        #                                col in user_data.columns]\n",
    "        user_history_QOE_continue_index = [user_data.columns.get_loc(col) for col in feature_column_dict['history_QOE_continue'] if\n",
    "                                       col in user_data.columns]\n",
    "        user_history_QOE_discrete_index = [user_data.columns.get_loc(col) for col in feature_column_dict['history_QOE_discrete'] if\n",
    "                                       col in user_data.columns]\n",
    "        user_history_CHONGHE_continue_index = [user_data.columns.get_loc(col) for col in\n",
    "                                           feature_column_dict['history_CHONGHE_continue'] if\n",
    "                                           col in user_data.columns]\n",
    "        user_history_CHONGHE_discrete_index = [user_data.columns.get_loc(col) for col in\n",
    "                                           feature_column_dict['history_CHONGHE_discrete'] if\n",
    "                                           col in user_data.columns]\n",
    "        user_history_FUFEI_continue_index = [user_data.columns.get_loc(col) for col in\n",
    "                                           feature_column_dict['history_FUFEI_continue'] if\n",
    "                                           col in user_data.columns]\n",
    "        user_history_FUFEI_discrete_index = [user_data.columns.get_loc(col) for col in\n",
    "                                           feature_column_dict['history_FUFEI_discrete'] if\n",
    "                                           col in user_data.columns]\n",
    "        # 填充数据矩阵\n",
    "        for i in range(len(user_data)):\n",
    "            if i != (len(user_data) - 1):  # 除最后一行即所有历史记录，不包括目标记录\n",
    "                 if user_data.iloc[i, -1] == label_False:  # 非付费  label_False在一开始设置为1，这是真实数据中最后一列 代表非付费\n",
    "                    data_matrix_not_pay_QOE_continue.append(\n",
    "                        [user_data.iloc[i, col] for col in user_history_QOE_continue_index])  # 用户历史QOE连续特征\n",
    "                    data_matrix_not_pay_QOE_discrete.append(\n",
    "                        [user_data.iloc[i, col] for col in user_history_QOE_discrete_index])  # 用户历史QOE离散特征\n",
    "                    data_matrix_not_pay_CHONGHE_continue.append(\n",
    "                        [user_data.iloc[i, col] for col in user_history_CHONGHE_continue_index])  # 用户历史CHONGHE连续特征\n",
    "                    data_matrix_not_pay_CHONGHE_discrete.append(\n",
    "                        [user_data.iloc[i, col] for col in user_history_CHONGHE_discrete_index])  # 用户历史CHONGHE离散特征\n",
    "                    data_matrix_not_pay_FUFEI_continue.append(\n",
    "                        [user_data.iloc[i, col] for col in user_history_FUFEI_continue_index])  # 用户历史FUFEI连续特征\n",
    "                    data_matrix_not_pay_FUFEI_discrete.append(\n",
    "                        [user_data.iloc[i, col] for col in user_history_FUFEI_discrete_index])  # 用户历史FUFEI离散特征\n",
    "                 else:\n",
    "                    data_matrix_pay_QOE_continue.append(\n",
    "                        [user_data.iloc[i, col] for col in user_history_QOE_continue_index])  # 用户历史QOE连续特征\n",
    "                    data_matrix_pay_QOE_discrete.append(\n",
    "                        [user_data.iloc[i, col] for col in user_history_QOE_discrete_index])  # 用户历史QOE离散特征\n",
    "                    data_matrix_pay_CHONGHE_continue.append(\n",
    "                        [user_data.iloc[i, col] for col in user_history_CHONGHE_continue_index])  # 用户历史CHONGHE连续特征\n",
    "                    data_matrix_pay_CHONGHE_discrete.append(\n",
    "                        [user_data.iloc[i, col] for col in user_history_CHONGHE_discrete_index])  # 用户历史CHONGHE离散特征\n",
    "                    data_matrix_pay_FUFEI_continue.append(\n",
    "                        [user_data.iloc[i, col] for col in user_history_FUFEI_continue_index])  # 用户历史FUFEI连续特征\n",
    "                    data_matrix_pay_FUFEI_discrete.append(\n",
    "                        [user_data.iloc[i, col] for col in user_history_FUFEI_discrete_index])  # 用户历史FUFEI离散特征\n",
    "\n",
    "            else:   # 目标记录\n",
    "                # data_matrix_user_info_continue.append([user_data.iloc[i, col] for col in user_feature_continue_index])  # 用户连续特征\n",
    "                # data_matrix_user_info_discrete.append([user_data.iloc[i, col] for col in user_feature_discrete_index])  # 用户离散特征\n",
    "                target_label.append(user_data.iloc[i, -1])  # 预测目标的y值\n",
    "                data_matrix_target_QOE_continue.append([user_data.iloc[i, col] for col in user_history_QOE_continue_index])  # 目标QOE连续特征\n",
    "                data_matrix_target_QOE_discrete.append([user_data.iloc[i, col] for col in user_history_QOE_discrete_index])  # 目标QOE离散特征\n",
    "                data_matrix_target_CHONGHE_continue.append([user_data.iloc[i, col] for col in user_history_CHONGHE_continue_index])  # 目标CHONGHE连续特征\n",
    "                data_matrix_target_CHONGHE_discrete.append([user_data.iloc[i, col] for col in user_history_CHONGHE_discrete_index])  # 目标CHONGHE离散特征\n",
    "                data_matrix_target_FUFEI_continue.append([user_data.iloc[i, col] for col in user_history_FUFEI_continue_index])  # 目标FUFEI连续特征\n",
    "                data_matrix_target_FUFEI_discrete.append([user_data.iloc[i, col] for col in user_history_FUFEI_discrete_index])  # 目标FUFEI离散特征\n",
    "        # print('data_matrix_pay_QOE_continue:', len(data_matrix_pay_QOE_continue),len(data_matrix_pay_QOE_continue))\n",
    "        # print('data_matrix_not_pay_QOE_continue:', len(data_matrix_not_pay_QOE_continue),len(data_matrix_not_pay_QOE_continue))\n",
    "        # print('data_matrix_target_FUFEI_discrete',len(data_matrix_target_FUFEI_continue),len(data_matrix_target_FUFEI_discrete[0]))\n",
    "        # 将历史行为记录处理为固定长度并进行mask\n",
    "        data_matrix_pay_QOE_continue,data_matrix_pay_QOE_continue_mask = history_feature_mask(user_history_QOE_continue_index, data_matrix_pay_QOE_continue, max_history_len)\n",
    "        data_matrix_pay_QOE_discrete,data_matrix_pay_QOE_discrete_mask = history_feature_mask(user_history_QOE_discrete_index, data_matrix_pay_QOE_discrete, max_history_len)\n",
    "        data_matrix_pay_CHONGHE_continue,data_matrix_pay_CHONGHE_continue_mask = history_feature_mask(user_history_CHONGHE_continue_index, data_matrix_pay_CHONGHE_continue,max_history_len)\n",
    "        data_matrix_pay_CHONGHE_discrete,data_matrix_pay_CHONGHE_discrete_mask = history_feature_mask(user_history_CHONGHE_discrete_index, data_matrix_pay_CHONGHE_discrete,max_history_len)\n",
    "        data_matrix_pay_FUFEI_continue,data_matrix_pay_FUFEI_continue_mask = history_feature_mask(user_history_FUFEI_continue_index, data_matrix_pay_FUFEI_continue,max_history_len)\n",
    "        data_matrix_pay_FUFEI_discrete,data_matrix_pay_FUFEI_discrete_mask = history_feature_mask(user_history_FUFEI_discrete_index, data_matrix_pay_FUFEI_discrete,max_history_len)\n",
    "        # print('data_matrix_pay_QOE_discrete',len(data_matrix_pay_QOE_discrete),len(data_matrix_pay_QOE_discrete[0]))\n",
    "        # print('(ata_matrix_pay_QOE_discrete',data_matrix_pay_QOE_discrete[0])\n",
    "        data_matrix_not_pay_QOE_continue,data_matrix_not_pay_QOE_continue_mask = history_feature_mask(user_history_QOE_continue_index, data_matrix_not_pay_QOE_continue, max_history_len)\n",
    "        data_matrix_not_pay_QOE_discrete,data_matrix_not_pay_QOE_discrete_mask = history_feature_mask(user_history_QOE_discrete_index, data_matrix_not_pay_QOE_discrete, max_history_len)\n",
    "        data_matrix_not_pay_CHONGHE_continue,data_matrix_not_pay_CHONGHE_continue_mask = history_feature_mask(user_history_CHONGHE_continue_index, data_matrix_not_pay_CHONGHE_continue,max_history_len)\n",
    "        data_matrix_not_pay_CHONGHE_discrete,data_matrix_not_pay_CHONGHE_discrete_mask = history_feature_mask(user_history_CHONGHE_discrete_index, data_matrix_not_pay_CHONGHE_discrete,max_history_len)\n",
    "        data_matrix_not_pay_FUFEI_continue,data_matrix_not_pay_FUFEI_continue_mask = history_feature_mask(user_history_FUFEI_continue_index, data_matrix_not_pay_FUFEI_continue,max_history_len)\n",
    "        data_matrix_not_pay_FUFEI_discrete,data_matrix_not_pay_FUFEI_discrete_mask = history_feature_mask(user_history_FUFEI_discrete_index, data_matrix_not_pay_FUFEI_discrete,max_history_len)\n",
    "\n",
    "\n",
    "        # 将numpy数组转换为PyTorch张量       # history   得到的data_matrix_user_history及data_tensor_pay_QOE_continue维度是(feature_num,history_len)需要转成tensor后转置\n",
    "        data_tensor_pay_QOE_continue = torch.transpose(torch.tensor(np.array(data_matrix_pay_QOE_continue), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_pay_QOE_discrete = torch.transpose(torch.tensor(np.array(data_matrix_pay_QOE_discrete), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_pay_CHONGHE_continue = torch.transpose(torch.tensor(np.array(data_matrix_pay_CHONGHE_continue), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_pay_CHONGHE_discrete = torch.transpose(torch.tensor(np.array(data_matrix_pay_CHONGHE_discrete), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_pay_FUFEI_continue = torch.transpose(torch.tensor(np.array(data_matrix_pay_FUFEI_continue), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_pay_FUFEI_discrete = torch.transpose(torch.tensor(np.array(data_matrix_pay_FUFEI_discrete), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_not_pay_QOE_continue = torch.transpose(torch.tensor(np.array(data_matrix_not_pay_QOE_continue), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_not_pay_QOE_discrete = torch.transpose(torch.tensor(np.array(data_matrix_not_pay_QOE_discrete), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_not_pay_CHONGHE_continue = torch.transpose(torch.tensor(np.array(data_matrix_not_pay_CHONGHE_continue), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_not_pay_CHONGHE_discrete = torch.transpose(torch.tensor(np.array(data_matrix_not_pay_CHONGHE_discrete), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_not_pay_FUFEI_continue = torch.transpose(torch.tensor(np.array(data_matrix_not_pay_FUFEI_continue), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_not_pay_FUFEI_discrete = torch.transpose(torch.tensor(np.array(data_matrix_not_pay_FUFEI_discrete), dtype=torch.float32),-2,-1)\n",
    "\n",
    "        #  mask矩阵   得到的data_matrix_user_history及data_tensor_pay_QOE_continue维度是(feature_num,history_len)需要转成tensor后转置\n",
    "        data_tensor_pay_QOE_continue_mask = torch.transpose(torch.tensor(np.array(data_matrix_pay_QOE_continue_mask), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_pay_QOE_discrete_mask = torch.transpose(torch.tensor(np.array(data_matrix_pay_QOE_discrete_mask), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_pay_CHONGHE_continue_mask = torch.transpose(torch.tensor(np.array(data_matrix_pay_CHONGHE_continue_mask), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_pay_CHONGHE_discrete_mask = torch.transpose(torch.tensor(np.array(data_matrix_pay_CHONGHE_discrete_mask), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_pay_FUFEI_continue_mask = torch.transpose(torch.tensor(np.array(data_matrix_pay_FUFEI_continue_mask), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_pay_FUFEI_discrete_mask = torch.transpose(torch.tensor(np.array(data_matrix_pay_FUFEI_discrete_mask), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_not_pay_QOE_continue_mask = torch.transpose(torch.tensor(np.array(data_matrix_not_pay_QOE_continue_mask), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_not_pay_QOE_discrete_mask = torch.transpose(torch.tensor(np.array(data_matrix_not_pay_QOE_discrete_mask), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_not_pay_CHONGHE_continue_mask = torch.transpose(torch.tensor(np.array(data_matrix_not_pay_CHONGHE_continue_mask), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_not_pay_CHONGHE_discrete_mask = torch.transpose(torch.tensor(np.array(data_matrix_not_pay_CHONGHE_discrete_mask), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_not_pay_FUFEI_continue_mask = torch.transpose(torch.tensor(np.array(data_matrix_not_pay_FUFEI_continue_mask), dtype=torch.float32),-2,-1)\n",
    "        data_tensor_not_pay_FUFEI_discrete_mask = torch.transpose(torch.tensor(np.array(data_matrix_not_pay_FUFEI_discrete_mask), dtype=torch.float32),-2,-1)\n",
    "     \n",
    "        # user + target   输出维度为（1，feature_num）,一处第一个为1的维度变为（feature_num）\n",
    "        # data_tensor_user_info_continue = torch.tensor(np.array(data_matrix_user_info_continue), dtype=torch.float32)\n",
    "        # data_tensor_user_info_discrete = torch.tensor(np.array(data_matrix_user_info_discrete), dtype=torch.float32)\n",
    "        data_tensor_target_QOE_continue = torch.squeeze(torch.tensor(np.array(data_matrix_target_QOE_continue), dtype=torch.float32),dim=0)\n",
    "        data_tensor_target_QOE_discrete = torch.squeeze(torch.tensor(np.array(data_matrix_target_QOE_discrete), dtype=torch.float32),dim=0)\n",
    "        data_tensor_target_CHONGHE_continue = torch.squeeze(torch.tensor(np.array(data_matrix_target_CHONGHE_continue),dtype=torch.float32),dim=0)\n",
    "        data_tensor_target_CHONGHE_discrete = torch.squeeze(torch.tensor(np.array(data_matrix_target_CHONGHE_discrete),dtype=torch.float32),dim=0)\n",
    "        data_tensor_target_FUFEI_continue = torch.squeeze(torch.tensor(np.array(data_matrix_target_FUFEI_continue), dtype=torch.float32),dim=0)\n",
    "        data_tensor_target_FUFEI_discrete = torch.squeeze(torch.tensor(np.array(data_matrix_target_FUFEI_discrete), dtype=torch.float32),dim=0)\n",
    "\n",
    "        # print('data_tensor_pay_QOE_continue',data_tensor_pay_QOE_continue)\n",
    "        # print('not_pay_QOE_continue',data_tensor_not_pay_QOE_continue)\n",
    "        # 生成hash值，按user_id为key存储成hash\n",
    "        tensor_hash_value = {\n",
    "            'pay_QOE_continue': data_tensor_pay_QOE_continue,\n",
    "            'pay_QOE_discrete': data_tensor_pay_QOE_discrete,\n",
    "            'pay_CHONGHE_continue': data_tensor_pay_CHONGHE_continue,\n",
    "            'pay_CHONGHE_discrete': data_tensor_pay_CHONGHE_discrete,\n",
    "            'pay_FUFEI_continue': data_tensor_pay_FUFEI_continue,\n",
    "            'pay_FUFEI_discrete': data_tensor_pay_FUFEI_discrete,\n",
    "            'not_pay_QOE_continue': data_tensor_not_pay_QOE_continue,\n",
    "            'not_pay_QOE_discrete': data_tensor_not_pay_QOE_discrete,\n",
    "            'not_pay_CHONGHE_continue': data_tensor_not_pay_CHONGHE_continue,\n",
    "            'not_pay_CHONGHE_discrete': data_tensor_not_pay_CHONGHE_discrete,\n",
    "            'not_pay_FUFEI_continue': data_tensor_not_pay_FUFEI_continue,\n",
    "            'not_pay_FUFEI_discrete': data_tensor_not_pay_FUFEI_discrete,\n",
    "            'target_QOE_continue': data_tensor_target_QOE_continue,\n",
    "            'target_QOE_discrete': data_tensor_target_QOE_discrete,\n",
    "            'target_CHONGHE_continue': data_tensor_target_CHONGHE_continue,\n",
    "            'target_CHONGHE_discrete': data_tensor_target_CHONGHE_discrete,\n",
    "            'target_FUFEI_continue': data_tensor_target_FUFEI_continue,\n",
    "            'target_FUFEI_discrete': data_tensor_target_FUFEI_discrete\n",
    "        }\n",
    "        tensor_hash_value_history_mask = {\n",
    "            'pay_QOE_continue': data_tensor_pay_QOE_continue_mask,\n",
    "            'pay_QOE_discrete': data_tensor_pay_QOE_discrete_mask,\n",
    "            'pay_CHONGHE_continue': data_tensor_pay_CHONGHE_continue_mask,\n",
    "            'pay_CHONGHE_discrete': data_tensor_pay_CHONGHE_discrete_mask,\n",
    "            'pay_FUFEI_continue': data_tensor_pay_FUFEI_continue_mask,\n",
    "            'pay_FUFEI_discrete': data_tensor_pay_FUFEI_discrete_mask,\n",
    "            'not_pay_QOE_continue': data_tensor_not_pay_QOE_continue_mask,\n",
    "            'not_pay_QOE_discrete': data_tensor_not_pay_QOE_discrete_mask,\n",
    "            'not_pay_CHONGHE_continue': data_tensor_not_pay_CHONGHE_continue_mask,\n",
    "            'not_pay_CHONGHE_discrete': data_tensor_not_pay_CHONGHE_discrete_mask,\n",
    "            'not_pay_FUFEI_continue': data_tensor_not_pay_FUFEI_continue_mask,\n",
    "            'not_pay_FUFEI_discrete': data_tensor_not_pay_FUFEI_discrete_mask\n",
    "        }\n",
    "        if user_id in data_tensor_hash:\n",
    "            data_tensor_hash[user_id].update(tensor_hash_value)\n",
    "            data_tensor_history_mask_hash[user_id].update(tensor_hash_value_history_mask)\n",
    "        else:\n",
    "            data_tensor_hash[user_id] = tensor_hash_value\n",
    "            data_tensor_history_mask_hash[user_id] = tensor_hash_value_history_mask\n",
    "    \n",
    "    # 如果需要合并成一个张量，可以使用torch.cat方法\n",
    "    # combined_tensor = torch.cat((data_matrix_1_tensor, data_matrix_2_tensor), dim=1)\n",
    "    # data_tensor_hash中用户历史的输出维度(max_history_len,feature_num)，目标的输出维度是（feature_num）\n",
    "    return data_tensor_hash, target_label, data_tensor_history_mask_hash   \n",
    "\n",
    "\n",
    "# 张量矩阵添加一个batch维度，并在用户特征与目标特征的张量中再添加一维使其与用户历史行为张量对齐， 形成两种：\n",
    "# 原数据为：1.用户特征与目标特征都为：（1,feature_num）; 2.用户历史行为特征为（max_history_len(固定长度的历史记录数),feature_num）\n",
    "# 新数据为：1.用户特征与目标特征都为：（batch,1,1,feature_num); 2.用户历史行为特征为（batch,max_history_len(固定长度的历史记录数),feature_num）\n",
    "# 形成batch维度的特征\n",
    "def generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, feature_category):  # 例:feature_category = 'user_info_continue' 就是上面生成的tensor_hash_value字典的键\n",
    "    tensor_list = []\n",
    "    for user_id in train_or_val_or_test_list:  # 遍历data_tensor_hash的所有key (user_id)\n",
    "        if feature_category in data_tensor_hash[user_id]:\n",
    "            tensor = data_tensor_hash[user_id][feature_category]  # 获取feature_category对应的张量\n",
    "            tensor_list.append(tensor)  # 添加到tensor_list中\n",
    "    # print('tensor_list shape',tensor_list.shape)\n",
    "    batch_feature_tensor = torch.stack(tensor_list, dim=0)  # 在第一个维度上合并所有张量(其实相当于生成一个新维度)\n",
    "    return batch_feature_tensor\n",
    "# 生成batch再添加维度对齐张量（三个维度）\n",
    "def generate_user_feature_alignment_tensor(train_or_val_or_test_list,data_tensor_hash,is_mask=False):\n",
    "    # 用户历史行为矩阵（max_history_len(固定长度的历史记录数),feature_num）->（batch,max_history_len(固定长度的历史记录数),feature_num）\n",
    "    pay_QOE_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'pay_QOE_continue')\n",
    "    pay_QOE_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'pay_QOE_discrete')\n",
    "    pay_CHONGHE_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'pay_CHONGHE_continue')\n",
    "    pay_CHONGHE_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'pay_CHONGHE_discrete')\n",
    "    pay_FUFEI_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'pay_FUFEI_continue')\n",
    "    pay_FUFEI_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'pay_FUFEI_discrete')\n",
    "    # print('pay_QOE_discrete_batch_feature_tensor1',pay_QOE_discrete_batch_feature_tensor[0,:,0])\n",
    "    not_pay_QOE_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'not_pay_QOE_continue')\n",
    "    not_pay_QOE_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'not_pay_QOE_discrete')\n",
    "    not_pay_CHONGHE_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'not_pay_CHONGHE_continue')\n",
    "    not_pay_CHONGHE_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'not_pay_CHONGHE_discrete')\n",
    "    not_pay_FUFEI_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'not_pay_FUFEI_continue')\n",
    "    not_pay_FUFEI_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'not_pay_FUFEI_discrete')\n",
    "\n",
    "    # 看是否是掩码矩阵，不是则xxx，是则没有user+target\n",
    "    if is_mask==False:\n",
    "        # 用户矩阵 (feature_num) ->(batch,feature_num)\n",
    "        # user_info_continue_batch_feature_tensor = generate_batch_feature(data_tensor_hash, 'user_info_continue')\n",
    "        # user_info_discrete_batch_feature_tensor = generate_batch_feature(data_tensor_hash, 'user_info_discrete')\n",
    "        # 目标矩阵 (feature_num) ->(batch,feature_num)\n",
    "        target_QOE_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'target_QOE_continue')\n",
    "        target_QOE_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'target_QOE_discrete')\n",
    "        target_CHONGHE_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'target_CHONGHE_continue')\n",
    "        target_CHONGHE_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'target_CHONGHE_discrete')\n",
    "        target_FUFEI_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'target_FUFEI_continue')\n",
    "        target_FUFEI_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'target_FUFEI_discrete')\n",
    "\n",
    "        # 假设原始张量矩阵为 tensor，形状为 (batch_size, feature_num)将其加一个维度变为 (batch_size, 1, feature_num)\n",
    "        # user_info_continue_batch_feature_tensor = torch.unsqueeze(user_info_continue_batch_feature_tensor, dim=1)\n",
    "        # user_info_discrete_batch_feature_tensor = torch.unsqueeze(user_info_discrete_batch_feature_tensor, dim=1)\n",
    "        target_QOE_continue_batch_feature_tensor = torch.unsqueeze(target_QOE_continue_batch_feature_tensor, dim=1)\n",
    "        target_QOE_discrete_batch_feature_tensor = torch.unsqueeze(target_QOE_discrete_batch_feature_tensor, dim=1)\n",
    "        target_CHONGHE_continue_batch_feature_tensor = torch.unsqueeze(target_CHONGHE_continue_batch_feature_tensor, dim=1)\n",
    "        target_CHONGHE_discrete_batch_feature_tensor = torch.unsqueeze(target_CHONGHE_discrete_batch_feature_tensor, dim=1)\n",
    "        target_FUFEI_continue_batch_feature_tensor = torch.unsqueeze(target_FUFEI_continue_batch_feature_tensor, dim=1)\n",
    "        target_FUFEI_discrete_batch_feature_tensor = torch.unsqueeze(target_FUFEI_discrete_batch_feature_tensor, dim=1)\n",
    "\n",
    "        batch_feature_tensor_dict = {\n",
    "            'pay_QOE_discrete': pay_QOE_discrete_batch_feature_tensor,\n",
    "            'pay_CHONGHE_discrete': pay_CHONGHE_discrete_batch_feature_tensor,\n",
    "            'pay_FUFEI_discrete': pay_FUFEI_discrete_batch_feature_tensor,\n",
    "            'pay_QOE_continue': pay_QOE_continue_batch_feature_tensor,\n",
    "            'pay_CHONGHE_continue': pay_CHONGHE_continue_batch_feature_tensor,\n",
    "            'pay_FUFEI_continue': pay_FUFEI_continue_batch_feature_tensor,\n",
    "            'not_pay_QOE_discrete': not_pay_QOE_discrete_batch_feature_tensor,\n",
    "            'not_pay_CHONGHE_discrete': not_pay_CHONGHE_discrete_batch_feature_tensor,\n",
    "            'not_pay_FUFEI_discrete': not_pay_FUFEI_discrete_batch_feature_tensor,\n",
    "            'not_pay_QOE_continue': not_pay_QOE_continue_batch_feature_tensor,\n",
    "            'not_pay_CHONGHE_continue': not_pay_CHONGHE_continue_batch_feature_tensor,\n",
    "            'not_pay_FUFEI_continue': not_pay_FUFEI_continue_batch_feature_tensor,\n",
    "            'target_QOE_discrete': target_QOE_discrete_batch_feature_tensor,\n",
    "            'target_CHONGHE_discrete': target_CHONGHE_discrete_batch_feature_tensor,\n",
    "            'target_FUFEI_discrete': target_FUFEI_discrete_batch_feature_tensor,       \n",
    "            'target_QOE_continue': target_QOE_continue_batch_feature_tensor,\n",
    "            'target_CHONGHE_continue': target_CHONGHE_continue_batch_feature_tensor,\n",
    "            'target_FUFEI_continue': target_FUFEI_continue_batch_feature_tensor,\n",
    "            \n",
    "        }\n",
    "    else:\n",
    "        batch_feature_tensor_dict = {\n",
    "            'pay_QOE_discrete': pay_QOE_discrete_batch_feature_tensor,\n",
    "            'pay_CHONGHE_discrete': pay_CHONGHE_discrete_batch_feature_tensor,\n",
    "            'pay_FUFEI_discrete': pay_FUFEI_discrete_batch_feature_tensor,\n",
    "            'pay_QOE_continue': pay_QOE_continue_batch_feature_tensor,\n",
    "            'pay_CHONGHE_continue': pay_CHONGHE_continue_batch_feature_tensor,\n",
    "            'pay_FUFEI_continue': pay_FUFEI_continue_batch_feature_tensor,\n",
    "            'not_pay_QOE_discrete': not_pay_QOE_discrete_batch_feature_tensor,\n",
    "            'not_pay_CHONGHE_discrete': not_pay_CHONGHE_discrete_batch_feature_tensor,\n",
    "            'not_pay_FUFEI_discrete': not_pay_FUFEI_discrete_batch_feature_tensor,\n",
    "            'not_pay_QOE_continue': not_pay_QOE_continue_batch_feature_tensor,\n",
    "            'not_pay_CHONGHE_continue': not_pay_CHONGHE_continue_batch_feature_tensor,\n",
    "            'not_pay_FUFEI_continue': not_pay_FUFEI_continue_batch_feature_tensor\n",
    "        }\n",
    "    return batch_feature_tensor_dict  # 这里张量输出的全是三维 (batch_size, 1 or max_history_len, feature_num)\n",
    "\n",
    "\n",
    "# 由于模型输入得是张量，因此在之前将字典转化为了张量，现在将它转换回去\n",
    "class TensorDatasettoDict(Dataset):\n",
    "    def __init__(self, dataset, keys):\n",
    "        self.dataset = dataset\n",
    "        self.keys = keys\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        sample = {key: data[i] for i, key in enumerate(self.keys)}\n",
    "        return sample\n",
    "\n",
    "# test\n",
    "# 获取训练、验证、测试集对应的数据形成的向量hash存储及label\n",
    "# print(data_hash[24488])\n",
    "train_data_tensor_hash, train_label, train_data_tensor_hash_history_mask = get_feature_to_matrix(train_list, data_hash, feature_column_dict)\n",
    "first_key = list(train_data_tensor_hash.keys())[0]\n",
    "# print(train_data_tensor_hash[first_key]['pay_QOE_discrete'][:,0])\n",
    "# print(train_label)\n",
    "# print(train_data_tensor_hash[3617476])\n",
    "dimensions1 = train_data_tensor_hash[14481314]['pay_QOE_continue'].size()\n",
    "dimensions2 = train_data_tensor_hash[14481314]['pay_QOE_discrete'].size()\n",
    "dimensions3 = train_data_tensor_hash[14481314]['pay_CHONGHE_continue'].size()\n",
    "dimensions4 = train_data_tensor_hash[14481314]['target_QOE_continue'].size()\n",
    "dimensions5 = train_data_tensor_hash[14481314]['target_QOE_discrete'].size()\n",
    "dimensions6 = train_data_tensor_hash[14481314]['target_CHONGHE_continue'].size()\n",
    "print(\"PyTorch张量的维度：\", dimensions1,dimensions2,dimensions3,dimensions4,dimensions5,dimensions6)\n",
    "train_batch_feature_tensor_dict = generate_user_feature_alignment_tensor(train_list,train_data_tensor_hash)\n",
    "train_batch_feature_tensor_history_mask_dict = generate_user_feature_alignment_tensor(train_list,train_data_tensor_hash_history_mask,is_mask=True)\n",
    "# print(train_batch_feature_tensor_dict['pay_QOE_discrete'][0,:,0])\n",
    "dimensions1 = train_data_tensor_hash[14481314]['pay_QOE_continue'].size()\n",
    "dimensions2 = train_data_tensor_hash[14481314]['pay_QOE_discrete'].size()\n",
    "dimensions3 = train_data_tensor_hash[14481314]['pay_CHONGHE_continue'].size()\n",
    "dimensions4 = train_data_tensor_hash[14481314]['target_QOE_continue'].size()\n",
    "dimensions5 = train_data_tensor_hash[14481314]['target_QOE_discrete'].size()\n",
    "dimensions6 = train_data_tensor_hash[14481314]['target_CHONGHE_continue'].size()\n",
    "print(\"PyTorch添加batch后张量的维度：\", dimensions1,dimensions2,dimensions3,dimensions4,dimensions5,dimensions6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6535f848-5c74-494a-84e9-884c8f6d42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.基础模型 embedding、attention\n",
    "# 构建离散特征的embedding\n",
    "def discrete_embedding(feature_category_num_dict, feature_column_name_list, embedding_dim): # 输入特征取值大小的集合,特征数,维度\n",
    "    # 创建一个列表来存储每个嵌入层\n",
    "    embeddings = []\n",
    "    for i in range(0, len(feature_column_name_list)):\n",
    "        # print(feature_column_name_list[i], feature_category_num_dict[feature_column_name_list[i]])\n",
    "        embedding_layer1 = nn.Embedding(feature_category_num_dict[feature_column_name_list[i]]+2, embedding_dim)\n",
    "        embeddings.append(embedding_layer1)\n",
    "    #     print('embedding维度',feature_category_num_dict[feature_column_name_list[i]]+1)\n",
    "    # print('本轮embedding层：',len(feature_column_name_list))\n",
    "    return embeddings\n",
    "\n",
    "# 全连接层 MLP\n",
    "def dense_layer(in_features, out_features):\n",
    "    # in_features=hidden_size,out_features=1\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features, bias=True),\n",
    "        nn.ReLU())\n",
    "# 全连接层 MLP\n",
    "def dense_layer_noReLu(in_features, out_features):\n",
    "    # in_features=hidden_size,out_features=1\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features, bias=True))\n",
    "\n",
    "# 连续特征离散化\n",
    "def continuous_embedding(num_continuous_features, out_features):\n",
    "    continuous_embedding_layers = []\n",
    "    for i in range(0,len(num_continuous_features)):\n",
    "        num_continuous_feature = num_continuous_features[i]\n",
    "        embedding_layer = dense_layer_noReLu(1, out_features)\n",
    "        continuous_embedding_layers.append(embedding_layer)\n",
    "    return continuous_embedding_layers\n",
    "\n",
    "# 根据全特征数量表及类别，得到类别下的对应特征数量  feature_column_name_list = feature_column_dict['user_info_continue']\n",
    "def category_feature_num(feature_category_num_dict, feature_column_name_list):\n",
    "    category_feature_num_list = []\n",
    "    for i in range(len(feature_column_name_list)):\n",
    "        category_feature_num_list.append(feature_category_num_dict[feature_column_name_list[i]])\n",
    "    # print('category_feature_num',len(category_feature_num_list))\n",
    "    return category_feature_num_list \n",
    "\n",
    "# SE层中找到合适的reduction使channel // reduction得到整数\n",
    "def find_reduction(channel, min_reduction=2, max_reduction=19):  \n",
    "    # 对于质数，直接取自己作为reduction  \n",
    "    if is_prime(channel):  \n",
    "        return channel  \n",
    "      \n",
    "    # 计算介于min_reduction和max_reduction之间的候选reduction值  \n",
    "    candidates = [i for i in range(min_reduction, max_reduction + 1) if channel % i == 0]  \n",
    "      \n",
    "    # 如果候选列表为空，则至少取2作为reduction  \n",
    "    if not candidates:  \n",
    "        return min_reduction  \n",
    "      \n",
    "    # 尝试找到最大的候选值，使得channel // reduction的结果尽可能大  \n",
    "    reduction = max(candidates)  \n",
    "      \n",
    "    return reduction  \n",
    "def is_prime(n):  \n",
    "    \"\"\"判断一个数是否为质数\"\"\"  \n",
    "    if n < 2:  \n",
    "        return False  \n",
    "    for i in range(2, int(math.sqrt(n)) + 1):  \n",
    "        if n % i == 0:  \n",
    "            return False  \n",
    "    return True  \n",
    "    \n",
    "# 输入(batch,feature_num,embedding_dim,1) ->(batch,feature_num,embedding_dim,1)->输出特征权重及权重乘后的(batch,embedding_dim) \n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.reduction = reduction\n",
    "        self.reduction = find_reduction(channel)\n",
    "        self.fc = nn.Sequential(       \n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        # print('b, c, h, w',b, c, h, w)\n",
    "        y = self.avg_pool(x).view(b, c)   \n",
    "        # print('y',y)\n",
    "        weight = self.fc(y).view(b, c, 1, 1)\n",
    "        new_x = x * weight.expand_as(x)  # 利用了 PyTorch 的广播机制，使得张量 weight 被复制成与输入 x 相同的形状，然后进行逐元素相乘 \n",
    "        # 加权平均 (batch, embedding_dim)\n",
    "        weighted_avg_out_x = new_x.mean(dim=1, keepdim=True)  # 在 feature_num维度上取平均，保持维度\n",
    "        # 调整维度\n",
    "        weighted_avg_out_x = weighted_avg_out_x.view(b, 1, h, w)\n",
    "        # 去除最后一维\n",
    "        new_x = new_x.squeeze(dim=3)\n",
    "        weighted_avg_out_x = weighted_avg_out_x.squeeze(dim=3)\n",
    "        \n",
    "        return  weight, weighted_avg_out_x,new_x\n",
    "# 旧 弃用\n",
    "# class SELayer(nn.Module):\n",
    "#     def __init__(self, feature_dim, feature_num, reduction=16):\n",
    "#         super(SELayer, self).__init__()\n",
    "#         self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(in_features=feature_dim, out_features=feature_dim // reduction, bias=False),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(in_features=feature_dim // reduction, out_features=feature_num, bias=False),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         # Apply average pooling along the feature_dim dimension  x(batch, embedding_dim, feature_num)\n",
    "#         b, c, h = x.size()\n",
    "#         print('b, c, h', b, c, h)\n",
    "#         y = self.pool(x.unsqueeze(-1)).view(b, c, -1)  # (batch, embedding_dim, 1)\n",
    "#         print('y', y)\n",
    "#         print('b, h', b, h)\n",
    "#         # Generate attention weights for each feature\n",
    "#         attention_weights = self.fc(y).view(b, h, -1)  # 权重batch, 1, feature_num\n",
    "#         print(attention_weights.shape)\n",
    "#         # Apply attention weights to the original input\n",
    "#         weighted_x = x * attention_weights.unsqueeze(1)\n",
    "#         # 输出的是一个形状为(batch, embedding_dim, feature_num)的张量。\n",
    "#         # 这个张量是对原始输入x进行加权后的结果，其中每个特征都被相应的注意力权重所乘。\n",
    "\n",
    "#         # Sum over the feature_num dimension to get (batch, embedding_dim)\n",
    "#         weighted_sum = torch.sum(weighted_x, dim=2)\n",
    "\n",
    "#         return attention_weights, weighted_sum, weighted_x\n",
    "    # def forward(self, x):\n",
    "    #     # Apply average pooling along the feature_dim dimension  x(batch, feature_dim, feature_num)\n",
    "    #     b, c, h, w = x.size()\n",
    "    #     print('b, c, h, w',b, c, h, w)\n",
    "    #     y = self.pool(x).view(b, c, -1)  # (batch, feature_dim, 1, 1)\n",
    "    #     print('y',y)\n",
    "    #     print('b, h * w',b, h * w)\n",
    "    #     # Generate attention weights for each feature\n",
    "    #     attention_weights = self.fc(y).view(b, h * w, -1)  # 权重batch, 1, 1, feature_num)\n",
    "    #     print(attention_weights.shape)\n",
    "    #     # Apply attention weights to the original input\n",
    "    #     weighted_x = x.view(b, c, -1) * attention_weights\n",
    "    #     # 输出的是一个形状为(batch, feature_dim, 1, feature_num)的张量。\n",
    "    #     # 这个张量是对原始输入x进行加权后的结果，其中每个特征都被相应的注意力权重所乘。\n",
    "    #     weighted_x = weighted_x.view(b, c, h, w)\n",
    "\n",
    "    #     # Sum over the feature_num dimension to get (batch, feature_dim, 1)\n",
    "    #     # weighted_sum = torch.sum(weighted_x, dim=2, keepdim=True)的具体意思是沿着feature_num维度\n",
    "    #     # （即第三个维度，索引为2）对weighted_x进行求和。由于keepdim=True，求和后的结果保持了一个额外的维度，\n",
    "    #     # 形状为(batch, feature_dim, 1)。这一步实现了对每个样本的所有特征进行加权求和，得到一个新的特征表示。\n",
    "    #     weighted_sum = torch.sum(weighted_x, dim=2, keepdim=True)\n",
    "    #     # 转置最后两维\n",
    "    #     weighted_sum = torch.transpose(weighted_sum, -2, -1)\n",
    "\n",
    "    #     return attention_weights, weighted_sum, weighted_x\n",
    "   \n",
    "    # 多头自注意力\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, num_heads, feature_dim, max_history_len):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.num_heads = num_heads  #10\n",
    "        self.feature_dim = feature_dim   #200\n",
    "        self.head_dim = feature_dim // num_heads\n",
    "        self.max_history_len = max_history_len\n",
    "\n",
    "        self.WQ = nn.Linear(feature_dim, feature_dim)\n",
    "        self.WK = nn.Linear(feature_dim, feature_dim)\n",
    "        self.WV = nn.Linear(feature_dim, feature_dim)\n",
    "\n",
    "    def forward(self, history_matrix, mask=None):\n",
    "        batch_size, history_len, _ = history_matrix.size()\n",
    "\n",
    "        Q = self.WQ(history_matrix)\n",
    "        K = self.WK(history_matrix)\n",
    "        V = self.WV(history_matrix)\n",
    "\n",
    "        Q = Q.view(batch_size, history_len, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  #(batch,num_heads,history_len,head_dim)\n",
    "        K = K.view(batch_size, history_len, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, history_len, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "        attention_scores = torch.matmul(Q, K.permute(0, 1, 3, 2)) / (self.head_dim ** 0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.permute(0, 2, 1)  # 二、三维度互换  变为(batch, feature_num, history)\n",
    "            temp_dim=mask.shape[1]\n",
    "            #（样本数*特征数,历史数）\n",
    "            mask=mask.reshape(-1,max_history_len)\n",
    "            attention_scores = attention_scores.masked_fill(mask.unsqueeze(1).unsqueeze(2).bool(), float('-inf'))  #()\n",
    "\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)  #shape(batch,head,history_len,history_len)\n",
    "        #(batch,history_len,200)\n",
    "        weighted_sum = torch.matmul(attention_weights, V).permute(0, 2, 1, 3).contiguous().view(batch_size, history_len,\n",
    "                                                                                                self.feature_dim)\n",
    "        # 计算加权平均\n",
    "        weighted_avg_out = weighted_sum.mean(dim=1, keepdim=True)  # 在 history_len 维度上取平均，保持维度\n",
    "        # 调整维度\n",
    "        weighted_avg_out = weighted_avg_out.view(batch_size, 1,self.feature_dim)\n",
    "        # print('weighted_sum',weighted_avg_out.shape)\n",
    "        \n",
    "        return attention_weights, weighted_avg_out, weighted_sum\n",
    "\n",
    "# class MultiHeadSelfAttention(nn.Module):\n",
    "#     def __init__(self, num_heads, feature_dim):\n",
    "#         super(MultiHeadSelfAttention, self).__init__()\n",
    "#         self.num_heads = num_heads\n",
    "#         self.feature_dim = feature_dim\n",
    "#         self.head_dim = feature_dim // num_heads\n",
    "\n",
    "#         # 线性变换的权重\n",
    "#         self.wq = nn.Parameter(torch.Tensor(feature_dim, self.num_heads * self.head_dim))\n",
    "#         self.wk = nn.Parameter(torch.Tensor(feature_dim, self.num_heads * self.head_dim))\n",
    "#         self.wv = nn.Parameter(torch.Tensor(feature_dim, self.num_heads * self.head_dim))\n",
    "\n",
    "#         # 初始化权重\n",
    "#         nn.init.normal_(self.wq, std=0.02)\n",
    "#         nn.init.normal_(self.wk, std=0.02)\n",
    "#         nn.init.normal_(self.wv, std=0.02)\n",
    "\n",
    "#     def forward(self, history_embedding_vec, mask=None):\n",
    "#         batch_size, history_len, feature_num, feature_dim = history_embedding_vec.size()\n",
    "#         # 将feature_num和batch_size合并\n",
    "#         x = history_embedding_vec.view(batch_size * feature_num, history_len, feature_dim)\n",
    "#         # 线性变换\n",
    "#         q = torch.matmul(x, self.wq).view(batch_size * feature_num, history_len, self.num_heads,self.head_dim).transpose(1, 2)\n",
    "#         k = torch.matmul(x, self.wk).view(batch_size * feature_num, history_len, self.num_heads,self.head_dim).transpose(1, 2)\n",
    "#         v = torch.matmul(x, self.wv).view(batch_size * feature_num, history_len, self.num_heads,self.head_dim).transpose(1, 2)\n",
    "#         # 缩放点积注意力\n",
    "#         scores = torch.matmul(q, k.transpose(-1, -2)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
    "#         if mask is not None:\n",
    "#             mask = mask.view(batch_size * feature_num, history_len)\n",
    "#             scores = scores.masked_fill(mask.unsqueeze(1).unsqueeze(2).bool(), float('-inf'))\n",
    "#         attention_weights = nn.Softmax(dim=-1)(scores)\n",
    "#         out = torch.matmul(attention_weights, v).transpose(1, 2).contiguous().view(batch_size, feature_num, history_len,self.num_heads * self.head_dim)\n",
    "#         # 合并多头\n",
    "#         out = torch.matmul(out, self.wq.view(self.num_heads * self.head_dim, feature_dim)).view(batch_size, feature_num,history_len,feature_dim)\n",
    "#         # 恢复到原始形状\n",
    "#         # out = out.view(batch_size, feature_num, history_len, feature_dim)\n",
    "        \n",
    "#           # 计算加权平均后的结果\n",
    "#         # 计算加权平均\n",
    "#         weighted_avg_out = out.mean(dim=2, keepdim=True)  # 在 history_len 维度上取平均，保持维度\n",
    "#         # 调整维度\n",
    "#         weighted_avg_out = weighted_avg_out.view(batch_size, 1, feature_num, feature_dim)\n",
    "        \n",
    "#         return attention_weights, weighted_avg_out\n",
    "\n",
    "# 注意力机制 关于用\n",
    "class MultiHeadHistory_TargetAttention(nn.Module):\n",
    "    def __init__(self, num_heads, embed_dim, dropout=0.1):\n",
    "        super(MultiHeadHistory_TargetAttention, self).__init__()\n",
    "        \n",
    "        assert embed_dim % num_heads == 0, f\"Embedding dimension ({embed_dim}) should be divisible by the number of heads ({num_heads}).\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        \n",
    "        # 定义权重矩阵\n",
    "        self.q_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self.scaling = self.head_dim ** -0.5\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None):\n",
    "        batch_size = query.size(0)       \n",
    "        # 进行线性投影并分离成多个头\n",
    "        q = self.q_linear(query).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.k_linear(key).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.v_linear(value).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        # 计算注意力得分\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scaling\n",
    "        if attn_mask is not None:\n",
    "            scores.masked_fill_(attn_mask.unsqueeze(1), float('-inf'))\n",
    "        # 应用softmax函数\n",
    "        attn_weights = self.softmax(scores)\n",
    "        # 应用dropout\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        # 进行值的加权求和\n",
    "        context = torch.matmul(attn_weights, v).transpose(1, 2).contiguous().view(batch_size, -1, self.embed_dim)\n",
    "        # 输出层的线性变换\n",
    "        output = self.out_proj(context)\n",
    "        return attn_weights, output\n",
    "\n",
    "# class MultiHeadHistory_TargetAttention(nn.Module):\n",
    "#     def __init__(self, num_heads, feature_dim):\n",
    "#         super(MultiHeadHistory_TargetAttention, self).__init__()\n",
    "#         self.feature_dim = feature_dim\n",
    "#         self.num_heads = num_heads\n",
    "#         self.head_dim = feature_dim // num_heads\n",
    "\n",
    "#         assert (\n",
    "#                 self.head_dim * num_heads == feature_dim\n",
    "#         ), \"Embedding dimension must be divisible by num_heads.\"\n",
    "\n",
    "#         self.values = nn.Linear(self.num_heads * self.head_dim, self.num_heads * self.head_dim, bias=False)\n",
    "#         # self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "#         self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "#         self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "#         # 其他部分保持不变\n",
    "\n",
    "#     def forward(self, student_embeddings, unit_embeddings, mask=None):\n",
    "#         batch_size = student_embeddings.size(0)\n",
    "\n",
    "#         # Split the embedding into self.num_heads different pieces\n",
    "#         student_values = student_embeddings.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "#         student_keys = student_embeddings.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "#         student_queries = student_embeddings.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "\n",
    "#         unit_values = unit_embeddings.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "#         unit_keys = unit_embeddings.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "#         # print('student_queries',student_queries.shape)\n",
    "#         # print('unit_keys',unit_keys.shape)\n",
    "\n",
    "#         # Compute the attention weights\n",
    "#         energy = torch.matmul(student_queries, unit_keys.transpose(-2, -1)) / torch.sqrt(\n",
    "#             torch.tensor(self.head_dim, dtype=torch.float32))\n",
    "#         if mask is not None:\n",
    "#             attention_weights = energy.masked_fill(mask.unsqueeze(1).unsqueeze(2), float('-inf'))\n",
    "#         attention_weights = torch.softmax(energy, dim=-1)\n",
    "\n",
    "#         # Apply attention weights to the values\n",
    "#         out = torch.matmul(attention_weights, unit_values)\n",
    "#         # print(out.shape)\n",
    "\n",
    "#         # Concatenate the outputs of the different heads\n",
    "#         out = out.view(batch_size, -1, self.num_heads * self.head_dim)\n",
    "#         # print(out.shape)\n",
    "\n",
    "#         # Finally, apply a linear layer to get the final output\n",
    "#         out = self.values(out)\n",
    "\n",
    "#         return attention_weights, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "f2b1a312-5627-4a04-9e2f-dd5dc3889a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Embedding层\n",
    "\n",
    "# user_history_feature 对于一个user的多个历史行为，将其拼接成一维向量 要先经过一层通道注意力机制得到最后结果\n",
    "# (样本数,history,20,200) ->多头 ->(样本数,20,200)->转置->(样本数,200,20) ->SE->特征权重->(样本数,200,20) ->转置-> 加权->(样本数,1，200)\n",
    "# user_pay_history_feature 加上batch的\n",
    "# 用户历史\n",
    "class UserPayHistoryEmbedding(nn.Module):\n",
    "    def __init__(self, continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict):\n",
    "        super(UserPayHistoryEmbedding, self).__init__()\n",
    "        # 连续特征\n",
    "        # 离散特征\n",
    "        self.feature_category_num_dict = feature_category_num_dict\n",
    "        # 离散embedding\n",
    "        self.user_pay_history_QOE_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,\n",
    "                                                                feature_column_dict['history_QOE_discrete'],\n",
    "                                                                discrete_embedding_dim)\n",
    "        self.user_pay_history_CHONGHE_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,\n",
    "                                                                           feature_column_dict['history_CHONGHE_discrete'],\n",
    "                                                                           discrete_embedding_dim)\n",
    "        self.user_pay_history_FUFEI_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,\n",
    "                                                                           feature_column_dict['history_FUFEI_discrete'],\n",
    "                                                                           discrete_embedding_dim)\n",
    "        # MLP  连续embedding\n",
    "        # category_feature_num_list = category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_continue'])\n",
    "        self.user_pay_history_QOE_continue_embedding = continuous_embedding(category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_continue']), continue_embedding_dim)\n",
    "        self.user_pay_history_CHONGHE_continue_embedding = continuous_embedding(category_feature_num(feature_category_num_dict, feature_column_dict['history_CHONGHE_continue']), continue_embedding_dim)\n",
    "        self.user_pay_history_FUFEI_continue_embedding = continuous_embedding(category_feature_num(feature_category_num_dict, feature_column_dict['history_FUFEI_continue']), continue_embedding_dim)\n",
    "\n",
    "    def forward(self, batch_feature_tensor_pay_QOE_discrete,batch_feature_tensor_pay_CHONGHE_discrete,batch_feature_tensor_pay_FUFEI_discrete,batch_feature_tensor_pay_QOE_continue,batch_feature_tensor_pay_CHONGHE_continue,batch_feature_tensor_pay_FUFEI_continue):\n",
    "        # user_history Embedding\n",
    "        # user_history_continue_features_embedding 得到(batch, 1, continue_feature_num, continue_embedding_dim)\n",
    "        # user_history_discrete_features_embedding 得到(batch, 1, discrete_feature_num, discrete_embedding_dim)\n",
    "        # history中有三种：QOE/CHONGHE/FUFEI,将其分别转化为embedding然后合并\n",
    "        # embedding的数据要求输入是整数类型 因此转为int，输入数据得是从0开始的索引后的数据，因此mask后得到-1以及在输入时得到了从0开始的索引后值，\n",
    "        # 现在所有discrete数据输入时+1，即 batch_feature_tensor_pay_QOE_discrete[:, :, i]+1 \n",
    "        # for i in range(batch_feature_tensor_pay_QOE_discrete.shape[2]):\n",
    "        #     print(i,batch_feature_tensor_pay_QOE_discrete.shape[2],batch_feature_tensor_pay_QOE_discrete[:, :, i]+1,self.user_pay_history_QOE_discrete_embeddings[i].num_embeddings )\n",
    "        batch_feature_tensor_pay_QOE_discrete = batch_feature_tensor_pay_QOE_discrete.int()\n",
    "        batch_feature_tensor_pay_CHONGHE_discrete = batch_feature_tensor_pay_CHONGHE_discrete.int()\n",
    "        batch_feature_tensor_pay_FUFEI_discrete = batch_feature_tensor_pay_FUFEI_discrete.int()\n",
    "        \n",
    "        user_history_pay_QOE_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_pay_QOE_discrete[:, :, i]+1) for i, embedding_layer in\n",
    "             enumerate(self.user_pay_history_QOE_discrete_embeddings)], dim=-2)\n",
    "        user_history_pay_QOE_continue_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_pay_QOE_continue[:,:, i].unsqueeze(-1).float()) for i, embedding_layer in\n",
    "             enumerate(self.user_pay_history_QOE_continue_embedding)], dim=-2)\n",
    "        user_history_pay_QOE_vec = torch.cat(\n",
    "            [user_history_pay_QOE_discrete_column_discrete_features_embedding, user_history_pay_QOE_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "        \n",
    "        user_history_pay_CHONGHE_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_pay_CHONGHE_discrete[:, :, i]+1) for i, embedding_layer in\n",
    "             enumerate(self.user_pay_history_CHONGHE_discrete_embeddings)], dim=-2)\n",
    "        user_history_pay_CHONGHE_continue_column_discrete_features_embedding = torch.stack(\n",
    "             [embedding_layer(batch_feature_tensor_pay_CHONGHE_continue[:,:, i].unsqueeze(2).float()) for i, embedding_layer in\n",
    "             enumerate(self.user_pay_history_CHONGHE_continue_embedding)], dim=-2)\n",
    "        user_history_pay_CHONGHE_vec = torch.cat(\n",
    "            [user_history_pay_CHONGHE_discrete_column_discrete_features_embedding,\n",
    "             user_history_pay_CHONGHE_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "        \n",
    "        user_history_pay_FUFEI_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_pay_FUFEI_discrete[:, :, i]+1) for i, embedding_layer in\n",
    "             enumerate(self.user_pay_history_FUFEI_discrete_embeddings)], dim=-2)\n",
    "        user_history_pay_FUFEI_continue_column_discrete_features_embedding = torch.stack(\n",
    "             [embedding_layer(batch_feature_tensor_pay_FUFEI_continue[:,:, i].unsqueeze(2).float()) for i, embedding_layer in\n",
    "             enumerate(self.user_pay_history_FUFEI_continue_embedding)], dim=-2)\n",
    "        user_history_pay_FUFEI_vec = torch.cat(\n",
    "            [user_history_pay_FUFEI_discrete_column_discrete_features_embedding,\n",
    "             user_history_pay_FUFEI_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "        # print(user_history_pay_FUFEI_discrete_column_discrete_features_embedding.shape,user_history_pay_FUFEI_continue_column_discrete_features_embedding.shape)\n",
    "        # print('user_history_pay_QOE_vec',user_history_pay_QOE_vec.shape,user_history_pay_QOE_vec)\n",
    "        \n",
    "        return user_history_pay_QOE_vec, user_history_pay_CHONGHE_vec, user_history_pay_FUFEI_vec\n",
    "\n",
    "# target_feature\n",
    "class TargetEmbedding(nn.Module):\n",
    "    def __init__(self, continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict):\n",
    "        super(TargetEmbedding, self).__init__()\n",
    "        # 连续特征  与付费、非付费共享一套特征\n",
    "        # 离散特征  与付费、非付费共享一套特征\n",
    "        self.feature_category_num_dict = feature_category_num_dict\n",
    "        # 离散embedding\n",
    "        self.target_QOE_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,feature_column_dict['history_QOE_discrete'],discrete_embedding_dim)\n",
    "        self.target_CHONGHE_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,feature_column_dict['history_CHONGHE_discrete'],discrete_embedding_dim)\n",
    "        self.target_FUFEI_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,feature_column_dict['history_FUFEI_discrete'],discrete_embedding_dim)\n",
    "        # MLP  连续embedding\n",
    "        self.target_QOE_continue_embedding = continuous_embedding(category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_continue']), continue_embedding_dim)\n",
    "        self.target_CHONGHE_continue_embedding = continuous_embedding(category_feature_num(feature_category_num_dict, feature_column_dict['history_CHONGHE_continue']), continue_embedding_dim)\n",
    "        self.target_FUFEI_continue_embedding = continuous_embedding(category_feature_num(feature_category_num_dict, feature_column_dict['history_FUFEI_continue']), continue_embedding_dim)\n",
    "\n",
    "    def forward(self, batch_feature_tensor_target_QOE_discrete,batch_feature_tensor_target_CHONGHE_discrete,batch_feature_tensor_target_FUFEI_discrete,batch_feature_tensor_target_QOE_continue,batch_feature_tensor_target_CHONGHE_continue,batch_feature_tensor_target_FUFEI_continue):\n",
    "        # target Embedding\n",
    "        # target_continue_features_embedding 得到(batch, 1, continue_feature_num, continue_embedding_dim)\n",
    "        # target_discrete_features_embedding 得到(batch, 1, discrete_feature_num, discrete_embedding_dim)\n",
    "        # 有三种：QOE/CHONGHE/FUFEI,将其分别转化为embedding然后合并\n",
    "        batch_feature_tensor_target_QOE_discrete = batch_feature_tensor_target_QOE_discrete.int()\n",
    "        batch_feature_tensor_target_CHONGHE_discrete = batch_feature_tensor_target_CHONGHE_discrete.int()\n",
    "        batch_feature_tensor_target_FUFEI_discrete = batch_feature_tensor_target_FUFEI_discrete.int()\n",
    "        target_QOE_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_target_QOE_discrete[:, :, i]+1) for i, embedding_layer in\n",
    "             enumerate(self.target_QOE_discrete_embeddings)], dim=-2)\n",
    "        target_QOE_continue_column_discrete_features_embedding = torch.stack(\n",
    "             [embedding_layer(batch_feature_tensor_target_QOE_continue[:,:, i].unsqueeze(2).float()) for i, embedding_layer in\n",
    "             enumerate(self.target_QOE_continue_embedding)], dim=-2)\n",
    "        target_QOE_vec = torch.cat(\n",
    "            [target_QOE_discrete_column_discrete_features_embedding, target_QOE_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "        \n",
    "        target_CHONGHE_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_target_CHONGHE_discrete[:, :, i]+1) for i, embedding_layer in\n",
    "             enumerate(self.target_CHONGHE_discrete_embeddings)], dim=-2)\n",
    "        target_CHONGHE_continue_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_target_CHONGHE_continue[:,:, i].unsqueeze(2).float()) for i, embedding_layer in\n",
    "             enumerate(self.target_CHONGHE_continue_embedding)], dim=-2)\n",
    "        target_CHONGHE_vec = torch.cat(\n",
    "            [target_CHONGHE_discrete_column_discrete_features_embedding,\n",
    "             target_CHONGHE_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "        \n",
    "        target_FUFEI_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_target_FUFEI_discrete[:, :, i]+1) for i, embedding_layer in\n",
    "             enumerate(self.target_FUFEI_discrete_embeddings)], dim=-2)\n",
    "        target_FUFEI_continue_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_target_FUFEI_continue[:,:, i].unsqueeze(2).float()) for i, embedding_layer in\n",
    "             enumerate(self.target_FUFEI_continue_embedding)], dim=-2)\n",
    "        target_FUFEI_vec = torch.cat(\n",
    "            [target_FUFEI_discrete_column_discrete_features_embedding,\n",
    "             target_FUFEI_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "\n",
    "        return target_QOE_vec, target_CHONGHE_vec, target_FUFEI_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "53d8814f-4dd7-4f2f-a6c0-e9af13389f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.Attention层\n",
    "\n",
    "\n",
    "# 用户历史embedding 多头+SE  (batch, history, feature_num, feature_dim)->(batch, 1，feature_dim)\n",
    "class HistoryDimScalingLayer(nn.Module):\n",
    "    def __init__(self, num_heads, feature_dim, feature_category_num_dict, max_history_len):\n",
    "        super(HistoryDimScalingLayer, self).__init__()\n",
    "        # 多头注意力\n",
    "        self.multi_head_attention = MultiHeadSelfAttention(num_heads, feature_dim,max_history_len)\n",
    "        # SE注意力\n",
    "        self.se_attention_QOE = SELayer(len(category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_continue']))+len(category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_discrete'])))\n",
    "        self.se_attention_CHONGHE = SELayer(len(category_feature_num(feature_category_num_dict, feature_column_dict['history_CHONGHE_continue']))+len(category_feature_num(feature_category_num_dict, feature_column_dict['history_CHONGHE_discrete'])))\n",
    "        self.se_attention_FUFEI = SELayer(len(category_feature_num(feature_category_num_dict, feature_column_dict['history_FUFEI_continue']))+len(category_feature_num(feature_category_num_dict, feature_column_dict['history_FUFEI_discrete'])))\n",
    "\n",
    "    def forward(self, user_history_QOE_vec,  user_history_CHONGHE_vec, user_history_FUFEI_vec, pay_QOE_mask=None, pay_CHONGHE_mask=None, pay_FUFEI_mask=None):\n",
    "        # (batch, history, feature_num, feature_dim) ->多头 ->(batch, feature_num, feature_dim)->转置->(batch, feature_dim, feature_num) ->SE->特征权重->(batch, feature_dim, feature_num) ->转置-> 加权->(batch, 1，feature_dim)\n",
    "        # 多头注意力  例(batch, history, 20, 200) ->多头 ->(batch, 20, 200)\n",
    "        print('1.Embedding:user_history_QOE_vec',user_history_QOE_vec.shape,pay_QOE_mask.shape)\n",
    "        # ********多头注意力前转化************\n",
    "        # 二、三维度互换  变为(batch, feature_num, history, 200)\n",
    "        user_history_QOE_vec = user_history_QOE_vec.permute(0, 2, 1, 3)  \n",
    "        user_history_CHONGHE_vec = user_history_CHONGHE_vec.permute(0, 2, 1, 3) \n",
    "        user_history_FUFEI_vec = user_history_FUFEI_vec.permute(0, 2, 1, 3) \n",
    "        print('2.0.二、三维度互换 ）user_history_QOE_vec',user_history_QOE_vec.shape,user_history_QOE_vec) #,multi_user_history_QOE_vec[0,0,:])\n",
    "\n",
    "        # 记录特征数\n",
    "        user_history_QOE_temp_dim=user_history_QOE_vec.shape[1]  \n",
    "        user_history_CHONGHE_temp_dim=user_history_CHONGHE_vec.shape[1]\n",
    "        user_history_FUFEI_temp_dim=user_history_FUFEI_vec.shape[1]\n",
    "        #（样本数*特征数,历史数，200）\n",
    "        user_history_QOE_vec=user_history_QOE_vec.reshape(-1,max_history_len,feature_dim)\n",
    "        user_history_CHONGHE_vec=user_history_CHONGHE_vec.reshape(-1,max_history_len,feature_dim)\n",
    "        user_history_FUFEI_vec=user_history_FUFEI_vec.reshape(-1,max_history_len,feature_dim)\n",
    "        print('2.样本数*特征数,历史数，200）user_history_QOE_vec',user_history_QOE_vec.shape,user_history_QOE_vec) #,multi_user_history_QOE_vec[0,0,:])\n",
    "        print('pay_QOE_mask',pay_QOE_mask)\n",
    "        #(样本数*特征数，200）\n",
    "        mutli_QOE_weight, multi_user_history_QOE_vec,_ = self.multi_head_attention(user_history_QOE_vec, mask=pay_QOE_mask)\n",
    "        mutli_CHONGHE_weight, multi_user_history_CHONGHE_vec,_ = self.multi_head_attention(user_history_CHONGHE_vec, mask=pay_CHONGHE_mask)\n",
    "        mutli_FUFEI_weight, multi_user_history_FUFEI_vec,_ = self.multi_head_attention(user_history_FUFEI_vec, mask=pay_FUFEI_mask)\n",
    "        print('3.(样本数*特征数，200）multi_user_history_QOE_vec',multi_user_history_QOE_vec.shape,multi_user_history_QOE_vec) #,multi_user_history_QOE_vec[0,0,:])\n",
    "\n",
    "        #(样本数,特征数，200）\n",
    "        multi_user_history_QOE_vec=multi_user_history_QOE_vec.view(-1,user_history_QOE_temp_dim,feature_dim)\n",
    "        multi_user_history_CHONGHE_vec=multi_user_history_CHONGHE_vec.view(-1,user_history_CHONGHE_temp_dim,feature_dim)\n",
    "        multi_user_history_FUFEI_vec=multi_user_history_FUFEI_vec.view(-1,user_history_FUFEI_temp_dim,feature_dim)\n",
    "        print('4.(样本数,特征数，200）multi_user_history_QOE_vec',multi_user_history_QOE_vec.shape,multi_user_history_QOE_vec) #,multi_user_history_QOE_vec[0,0,:])\n",
    "        print('multi_user_history_CHONGHE_vec',multi_user_history_CHONGHE_vec.shape,multi_user_history_CHONGHE_vec) #,multi_user_history_CHONGHE_vec[0,0,:])\n",
    "        print('multi_user_history_FUFEI_vec',multi_user_history_FUFEI_vec.shape,multi_user_history_FUFEI_vec) #,multi_user_history_FUFEI_vec[0,0,:])\n",
    "        \n",
    "        # 去掉第二维  (batch, 1, 20, 200)->(batch, 20, 200)\n",
    "        # multi_user_history_QOE_vec = multi_user_history_QOE_vec.squeeze(dim=1)\n",
    "        # multi_user_history_CHONGHE_vec = multi_user_history_CHONGHE_vec.squeeze(dim=1)\n",
    "        # multi_user_history_FUFEI_vec= multi_user_history_FUFEI_vec.squeeze(dim=1)\n",
    "        # 调整维度 (batch, 20, 200)->(batch,20,200,1)  (batch,feature_num.embedding_dim,1)\n",
    "        multi_user_history_QOE_vec = multi_user_history_QOE_vec.unsqueeze(-1)\n",
    "        multi_user_history_CHONGHE_vec = multi_user_history_CHONGHE_vec.unsqueeze(-1)\n",
    "        multi_user_history_FUFEI_vec= multi_user_history_FUFEI_vec.unsqueeze(-1)\n",
    "        # 转置 交换最后两个维度 (feature_num 和 embedding_dim)\n",
    "        # multi_user_history_QOE_vec = torch.transpose(multi_user_history_QOE_vec, 1, 2)\n",
    "        # multi_user_history_CHONGHE_vec = torch.transpose(multi_user_history_CHONGHE_vec, 1, 2)\n",
    "        # multi_user_history_FUFEI_vec = torch.transpose(multi_user_history_FUFEI_vec, 1, 2)\n",
    "\n",
    "        # SE注意力  (batch,feature_num,feature_dim,1) ->SE->特征权重->(batch,feature_num,feature_dim,1)->去除最后一列-> 加权->(batch, 1，feature_dim)\n",
    "        se_QOE_weight, se_user_history_QOE_vec,_= self.se_attention_QOE(multi_user_history_QOE_vec)\n",
    "        se_CHONGHE_weight, se_user_history_CHONGHE_vec,_ = self.se_attention_CHONGHE(multi_user_history_CHONGHE_vec)\n",
    "        se_FUFEI_weight, se_user_history_FUFEI_vec,_ = self.se_attention_FUFEI(multi_user_history_FUFEI_vec)\n",
    "        print('se_user_history_QOE_vec',se_user_history_QOE_vec.shape,se_user_history_QOE_vec)\n",
    "\n",
    "\n",
    "        HistoryDimScaling_Weight_Result = {\n",
    "            'mutli_QOE_weight': mutli_QOE_weight,\n",
    "            'mutli_CHONGHE_weight': mutli_CHONGHE_weight,\n",
    "            'mutli_FUFEI_weight': mutli_FUFEI_weight,\n",
    "            'se_QOE_weight': se_QOE_weight,\n",
    "            'se_CHONGHE_weight': se_CHONGHE_weight,\n",
    "            'se_FUFEI_weight': se_FUFEI_weight\n",
    "        }\n",
    "        return HistoryDimScaling_Weight_Result, se_user_history_QOE_vec, se_user_history_CHONGHE_vec, se_user_history_FUFEI_vec\n",
    "\n",
    "# 目标产品embedding SE  (batch, 1, feature_num, feature_dim)->(batch, 1，feature_dim)\n",
    "class TargetDimScalingLayer(nn.Module):\n",
    "    def __init__(self, feature_dim, feature_category_num_dict):\n",
    "        super(TargetDimScalingLayer, self).__init__()\n",
    "        # SE注意力\n",
    "        self.se_attention_QOE = SELayer(len(category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_continue']))+len(category_feature_num(feature_category_num_dict, feature_column_dict['history_QOE_discrete'])))\n",
    "        self.se_attention_CHONGHE = SELayer(len(category_feature_num(feature_category_num_dict, feature_column_dict['history_CHONGHE_continue']))+len(category_feature_num(feature_category_num_dict, feature_column_dict['history_CHONGHE_discrete'])))\n",
    "        self.se_attention_FUFEI = SELayer(len(category_feature_num(feature_category_num_dict, feature_column_dict['history_FUFEI_continue']))+len(category_feature_num(feature_category_num_dict, feature_column_dict['history_FUFEI_discrete'])))\n",
    "\n",
    "    def forward(self, target_QOE_vec,  target_CHONGHE_vec, target_FUFEI_vec, mask=None):\n",
    "        # (batch, 1, feature_num, feature_dim) (batch, feature_num, feature_dim)->转置->(batch, feature_dim, feature_num) ->SE->特征权重->(batch, feature_dim, feature_num) ->转置-> 加权->(batch, 1，feature_dim)\n",
    "        # target_QOE_vec = target_QOE_vec.squeeze(1)  # 使用 squeeze 函数移除大小为 1 的维度\n",
    "        # target_CHONGHE_vec = target_CHONGHE_vec.squeeze(1)  # 使用 squeeze 函数移除大小为 1 的维度\n",
    "        # target_FUFEI_vec = target_FUFEI_vec.squeeze(1)  # 使用 squeeze 函数移除大小为 1 的维度\n",
    "        # 转置 交换最后两个维度 (20 和 200)\n",
    "        # target_QOE_vec = torch.transpose(target_QOE_vec, -2, -1)\n",
    "        # target_CHONGHE_vec = torch.transpose(target_CHONGHE_vec, -2, -1)\n",
    "        # target_FUFEI_vec = torch.transpose(target_FUFEI_vec, -2, -1)\n",
    "        # 去掉第二维  (batch, 1, 20, 200)->(batch, 20, 200)\n",
    "        target_QOE_vec = target_QOE_vec.squeeze(dim=1)\n",
    "        target_CHONGHE_vec = target_CHONGHE_vec.squeeze(dim=1)\n",
    "        target_FUFEI_vec= target_FUFEI_vec.squeeze(dim=1)\n",
    "        # 调整维度 (batch, 20, 200)->(batch,20,200,1)  (batch,feature_num.embedding_dim,1)\n",
    "        target_QOE_vec = target_QOE_vec.unsqueeze(-1)\n",
    "        target_CHONGHE_vec = target_CHONGHE_vec.unsqueeze(-1)\n",
    "        target_FUFEI_vec= target_FUFEI_vec.unsqueeze(-1)\n",
    "\n",
    "        # SE注意力  (batch, feature_dim, feature_num) ->SE->特征权重->(batch, feature_dim, feature_num)->转置-> 加权->(batch, 1，feature_dim)\n",
    "        # 结果为权重，合并后向量，合并前向量\n",
    "        se_QOE_weight, se_target_QOE_vec,_ = self.se_attention_QOE(target_QOE_vec)\n",
    "        se_CHONGHE_weight, se_target_CHONGHE_vec,_ = self.se_attention_CHONGHE(target_CHONGHE_vec)\n",
    "        se_FUFEI_weight, se_target_FUFEI_vec,_ = self.se_attention_FUFEI(target_FUFEI_vec)\n",
    "        print('se_target_QOE_vec',se_target_QOE_vec.shape,se_target_QOE_vec)\n",
    "\n",
    "        TargetDimScaling_Weight_Result = {\n",
    "            'se_QOE_weight': se_QOE_weight,\n",
    "            'se_CHONGHE_weight': se_CHONGHE_weight,\n",
    "            'se_FUFEI_weight': se_FUFEI_weight\n",
    "        }\n",
    "        return TargetDimScaling_Weight_Result, se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec\n",
    "\n",
    "# 用户历史与目标记录的attention层\n",
    "class History_Target_AttentionLayer(nn.Module):\n",
    "    def __init__(self, num_heads, feature_dim):\n",
    "        super(History_Target_AttentionLayer, self).__init__()\n",
    "        self.target_history_pay_feature_pianhao_QOE_layer = MultiHeadHistory_TargetAttention(num_heads, feature_dim)\n",
    "        self.target_history_pay_feature_pianhao_CHONGHE_layer = MultiHeadHistory_TargetAttention(num_heads, feature_dim)\n",
    "        self.target_history_pay_feature_pianhao_FUFEI_layer = MultiHeadHistory_TargetAttention(num_heads, feature_dim)\n",
    "\n",
    "    def forward(self, se_user_history_pay_QOE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_FUFEI_vec, se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec, pay_QOE_mask=None, pay_CHONGHE_mask=None, pay_FUFEI_mask=None):\n",
    "        # 将QOE、CHONGHE、FUFEI分别做attention\n",
    "        # se_user_history_pay_QOE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_FUFEI_vec\n",
    "        # se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec\n",
    "        # 对目标特征求对历史特征的偏好   (batch, 1，feature_dim)输出\n",
    "        target_history_pay_attention_QOE_weight, target_history_pay_attention_QOE_vec = self.target_history_pay_feature_pianhao_QOE_layer(se_target_QOE_vec, se_user_history_pay_QOE_vec, se_user_history_pay_QOE_vec)\n",
    "        target_history_pay_attention_CHONGHE_weight, target_history_pay_attention_CHONGHE_vec = self.target_history_pay_feature_pianhao_CHONGHE_layer(se_target_CHONGHE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_CHONGHE_vec)\n",
    "        target_history_pay_attention_FUFEI_weight, target_history_pay_attention_FUFEI_vec = self.target_history_pay_feature_pianhao_FUFEI_layer(se_target_FUFEI_vec, se_user_history_pay_FUFEI_vec, se_user_history_pay_FUFEI_vec)\n",
    "        # CONCAT  (batch, 3，feature_dim)输出\n",
    "        target_history_pay_attention_vec = torch.cat((target_history_pay_attention_QOE_vec, target_history_pay_attention_CHONGHE_vec, target_history_pay_attention_FUFEI_vec), dim=1)\n",
    "        return target_history_pay_attention_vec, target_history_pay_attention_QOE_weight,target_history_pay_attention_CHONGHE_weight,target_history_pay_attention_FUFEI_weight\n",
    "\n",
    "# class History_Target_AttentionLayer(nn.Module):\n",
    "#     def __init__(self, num_heads, feature_dim):\n",
    "#         super(History_Target_AttentionLayer, self).__init__()\n",
    "#         self.target_history_pay_feature_pianhao_layer = MultiHeadHistory_TargetAttention(num_heads, feature_dim)\n",
    "#         self.target_history_not_pay_feature_pianhao_layer = MultiHeadHistory_TargetAttention(num_heads, feature_dim)\n",
    "\n",
    "#     def forward(self, se_user_history_pay_QOE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_FUFEI_vec, se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec, pay_QOE_mask=None, pay_CHONGHE_mask=None, pay_FUFEI_mask=None):\n",
    "#         # 将QOE、CHONGHE、FUFEI叠加，形成三个特征的向量  (batch, 1，feature_dim)->(batch, 3，feature_dim)\n",
    "#         user_history_pay_vec = torch.cat((se_user_history_pay_QOE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_FUFEI_vec), dim=1)\n",
    "#         target_vec = torch.cat((se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec), dim=1)\n",
    "        \n",
    "#         # 对目标特征求对历史特征的偏好   (batch, 3，feature_dim)输出\n",
    "#         target_history_pay_attention_weight, target_history_pay_attention_vec = self.target_history_pay_feature_pianhao_layer(target_vec, user_history_pay_vec)\n",
    "\n",
    "#         return target_history_pay_attention_weight, target_history_pay_attention_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "4d760278-5e3a-43c8-b530-3676babfb88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.整合模型\n",
    "\n",
    "\n",
    "# (batch,600)经过网络变成200 +(batch,featuer_user*200)经过网络变成200 -> (batch,200)\n",
    "# (batch,200) ->MLP ->(batch，1) ->sigmoid -> (batch,1)\n",
    "\n",
    "# 整合层\n",
    "class MatchingModel(nn.Module):\n",
    "    def __init__(self, feature_category_num_dict, feature_column_dict, continue_embedding_dim,\n",
    "                 discrete_embedding_dim,num_heads, feature_dim, max_history_len):\n",
    "        super(MatchingModel, self).__init__()\n",
    "        # Embedding层\n",
    "        # self.user_info_embedding_layer = UserInfoEmbedding(continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict)\n",
    "        self.user_history_pay_embedding_layer = UserPayHistoryEmbedding(continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict)\n",
    "        self.user_history_not_pay_embedding_layer = UserPayHistoryEmbedding(continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict)\n",
    "\n",
    "        #print('embedding user_history结果')\n",
    "        self.target_embedding_layer = TargetEmbedding(continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict)\n",
    "        \n",
    "        # User History & Target Attention层\n",
    "        self.history_pay_attention_layer = HistoryDimScalingLayer(num_heads, feature_dim, feature_category_num_dict, max_history_len)\n",
    "        self.history_not_pay_attention_layer = HistoryDimScalingLayer(num_heads, feature_dim, feature_category_num_dict, max_history_len)\n",
    "        self.target_attention_layer = TargetDimScalingLayer(feature_dim, feature_category_num_dict)\n",
    "\n",
    "        # Target History Attention层\n",
    "        self.target_pay_history_attention_layer = History_Target_AttentionLayer(num_heads, feature_dim)\n",
    "        self.target_not_pay_history_attention_layer = History_Target_AttentionLayer(num_heads, feature_dim)\n",
    "\n",
    "        # 维度转换层\n",
    "        final_dim = 20\n",
    "        self.target_dim_change = dense_layer(3*feature_dim, final_dim)  # (batch,3,200)->(batch,600)->(batch,200)\n",
    "        # user_info_feature_num = feature_category_num_dict['user_info_continue'].shape[2] + feature_category_num_dict['user_info_discrete'].shape[2]\n",
    "        # self.user_info_dim_change = dense_layer(user_info_feature_num, 200)  # (batch,user_info_feature,200)->(batch,user_info_feature*200)->(batch,200)\n",
    "        # MLP\n",
    "        self.pay_vec_MLP_layer = dense_layer(final_dim, 1)\n",
    "\n",
    "\n",
    "    def forward(self, batch_feature_tensor_pay_QOE_discrete,batch_feature_tensor_pay_CHONGHE_discrete,batch_feature_tensor_pay_FUFEI_discrete,\n",
    "                batch_feature_tensor_pay_QOE_continue,batch_feature_tensor_pay_CHONGHE_continue,batch_feature_tensor_pay_FUFEI_continue,\n",
    "                batch_feature_tensor_not_pay_QOE_discrete,batch_feature_tensor_not_pay_CHONGHE_discrete,batch_feature_tensor_not_pay_FUFEI_discrete,\n",
    "                batch_feature_tensor_not_pay_QOE_continue,batch_feature_tensor_not_pay_CHONGHE_continue,batch_feature_tensor_not_pay_FUFEI_continue,\n",
    "                batch_feature_tensor_target_QOE_discrete,batch_feature_tensor_target_CHONGHE_discrete,batch_feature_tensor_target_FUFEI_discrete,\n",
    "                batch_feature_tensor_target_QOE_continue,batch_feature_tensor_target_CHONGHE_continue,batch_feature_tensor_target_FUFEI_continue, \n",
    "                batch_feature_tensor_pay_QOE_discrete_mask,batch_feature_tensor_pay_CHONGHE_discrete_mask,batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "                batch_feature_tensor_pay_QOE_continue_mask,batch_feature_tensor_pay_CHONGHE_continue_mask,batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "                batch_feature_tensor_not_pay_QOE_discrete_mask,batch_feature_tensor_not_pay_CHONGHE_discrete_mask,batch_feature_tensor_not_pay_FUFEI_discrete_mask,\n",
    "                batch_feature_tensor_not_pay_QOE_continue_mask,batch_feature_tensor_not_pay_CHONGHE_continue_mask,batch_feature_tensor_not_pay_FUFEI_continue_mask,\n",
    "                label_tensor):\n",
    "        # Embedding层\n",
    "        user_history_pay_QOE_vec, user_history_pay_CHONGHE_vec, user_history_pay_FUFEI_vec = self.user_history_pay_embedding_layer(batch_feature_tensor_pay_QOE_discrete,batch_feature_tensor_pay_CHONGHE_discrete,batch_feature_tensor_pay_FUFEI_discrete,batch_feature_tensor_pay_QOE_continue,batch_feature_tensor_pay_CHONGHE_continue,batch_feature_tensor_pay_FUFEI_continue)        \n",
    "        user_history_not_pay_QOE_vec, user_history_not_pay_CHONGHE_vec, user_history_not_pay_FUFEI_vec = self.user_history_not_pay_embedding_layer(batch_feature_tensor_not_pay_QOE_discrete,batch_feature_tensor_not_pay_CHONGHE_discrete,batch_feature_tensor_not_pay_FUFEI_discrete,batch_feature_tensor_not_pay_QOE_continue,batch_feature_tensor_not_pay_CHONGHE_continue,batch_feature_tensor_not_pay_FUFEI_continue)        \n",
    "        target_QOE_vec, target_CHONGHE_vec, target_FUFEI_vec = self.target_embedding_layer(batch_feature_tensor_target_QOE_discrete,batch_feature_tensor_target_CHONGHE_discrete,batch_feature_tensor_target_FUFEI_discrete,batch_feature_tensor_target_QOE_continue,batch_feature_tensor_target_CHONGHE_continue,batch_feature_tensor_target_FUFEI_continue)\n",
    "        # print('user_history_pay_QOE_vec size=',user_history_pay_QOE_vec)\n",
    "        # print('user_history_not_pay_QOE_vec size=',user_history_not_pay_QOE_vec)\n",
    "        # User History & Target Attention层\n",
    "        # 合并mask输入  \n",
    "        # print(\"Shape of mask tensor:\", batch_feature_tensor_pay_QOE_discrete_mask.shape,batch_feature_tensor_pay_QOE_continue_mask.shape)\n",
    "        pay_QOE_mask = torch.cat((batch_feature_tensor_pay_QOE_discrete_mask, batch_feature_tensor_pay_QOE_continue_mask), dim=2)\n",
    "        pay_CHONGHE_mask = torch.cat((batch_feature_tensor_pay_CHONGHE_discrete_mask, batch_feature_tensor_pay_CHONGHE_continue_mask), dim=2)\n",
    "        pay_FUFEI_mask = torch.cat((batch_feature_tensor_pay_FUFEI_discrete_mask, batch_feature_tensor_pay_FUFEI_continue_mask), dim=2)\n",
    "        pay_HistoryDimScaling_Weight_Result, se_user_history_pay_QOE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_FUFEI_vec = self.history_pay_attention_layer(user_history_pay_QOE_vec,  user_history_pay_CHONGHE_vec, user_history_pay_FUFEI_vec, pay_QOE_mask=pay_QOE_mask,pay_CHONGHE_mask=pay_CHONGHE_mask,pay_FUFEI_mask=pay_FUFEI_mask)\n",
    "        not_pay_QOE_mask = torch.cat((batch_feature_tensor_not_pay_QOE_discrete_mask, batch_feature_tensor_not_pay_QOE_continue_mask), dim=2)\n",
    "        not_pay_CHONGHE_mask = torch.cat((batch_feature_tensor_not_pay_CHONGHE_discrete_mask, batch_feature_tensor_not_pay_CHONGHE_continue_mask), dim=2)\n",
    "        not_pay_FUFEI_mask = torch.cat((batch_feature_tensor_not_pay_FUFEI_discrete_mask, batch_feature_tensor_not_pay_FUFEI_continue_mask), dim=2)\n",
    "        not_pay_HistoryDimScaling_Weight_Result, se_user_history_not_pay_QOE_vec, se_user_history_not_pay_CHONGHE_vec, se_user_history_not_pay_FUFEI_vec = self.history_not_pay_attention_layer(user_history_not_pay_QOE_vec,  user_history_not_pay_CHONGHE_vec, user_history_not_pay_FUFEI_vec, pay_QOE_mask=not_pay_QOE_mask,pay_CHONGHE_mask=not_pay_CHONGHE_mask,pay_FUFEI_mask=not_pay_FUFEI_mask)\n",
    "\n",
    "        TargetDimScaling_Weight_Result, se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec = self.target_attention_layer(target_QOE_vec, target_CHONGHE_vec, target_FUFEI_vec)\n",
    "        print('se_user_history_pay_QOE_vec size=', se_user_history_pay_QOE_vec.shape)\n",
    "        print('se_target_QOE_vec size=', se_target_QOE_vec.shape)\n",
    "        # Target with History Attention层\n",
    "        target_history_pay_attention_vec,target_history_pay_attention_QOE_weight,\\\n",
    "        target_history_pay_attention_CHONGHE_weight,target_history_pay_attention_FUFEI_weight = self.target_pay_history_attention_layer(\n",
    "            se_user_history_pay_QOE_vec, se_user_history_pay_CHONGHE_vec, se_user_history_pay_FUFEI_vec,\n",
    "            se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec)\n",
    "        # 这里两个连着用se_target_QOE_vec 有没有变化？？？？\n",
    "        target_history_not_pay_attention_vec,target_history_not_pay_attention_QOE_weight,\\\n",
    "        target_history_not_pay_attention_CHONGHE_weight,target_history_not_pay_attention_FUFEI_weight = self.target_not_pay_history_attention_layer(\n",
    "            se_user_history_not_pay_QOE_vec, se_user_history_not_pay_CHONGHE_vec, se_user_history_not_pay_FUFEI_vec,\n",
    "            se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec)\n",
    "        print('target_history_pay_attention_vec size=', target_history_pay_attention_vec.shape)\n",
    "\n",
    "        # # 拼接user_info_vec与target_history_pay_attention_vec等\n",
    "        # user_info_vec = user_info_vec.squeeze(1)  # 使用 squeeze 函数移除大小为 1 的维度\n",
    "        # FUFEI:(batch,3,200)->(batch,3*200)经过网络->(batch,200) + uer_info:(batch,featuer_user*200)经过网络->(batch,200) 叠加后-> (batch,400)\n",
    "        # 维度转换 (batch,3,200)->(batch,feature*200)经过网络->(batch,200)\n",
    "        target_history_pay_attention_vec = target_history_pay_attention_vec.view(batch_size, -1)   # 将张量 x 重塑为 (batch, 3*200)  使用 -1 作为自动计算的维度       \n",
    "        target_history_pay_attention_vec = self.target_dim_change(target_history_pay_attention_vec)\n",
    "        target_history_not_pay_attention_vec = target_history_not_pay_attention_vec.view(batch_size, -1)   # 将张量 x 重塑为 (batch, 3*200)  使用 -1 作为自动计算的维度       \n",
    "        target_history_not_pay_attention_vec = self.target_dim_change(target_history_not_pay_attention_vec)\n",
    "        print('target_history_pay_attention_vec',target_history_pay_attention_vec)\n",
    "        print('target_history_not_pay_attention_vec',target_history_not_pay_attention_vec)\n",
    "\n",
    "        # MLP\n",
    "        # (batch,200) ->MLP ->(batch，1) ->sigmoid -> (batch,1)\n",
    "        out_pay_vec = self.pay_vec_MLP_layer(target_history_pay_attention_vec)\n",
    "        out_not_pay_vec = self.pay_vec_MLP_layer(target_history_not_pay_attention_vec)\n",
    "        # print('out_pay_vec size=',out_pay_vec.shape,'out_pay_vec:',out_pay_vec)\n",
    "        # print('out_out_not_pay_vecvec size=',out_not_pay_vec.shape,'out_not_pay_vec:',out_not_pay_vec)\n",
    "        # 相似度\n",
    "        target_vec = torch.cat((se_target_QOE_vec, se_target_CHONGHE_vec, se_target_FUFEI_vec),dim=2)\n",
    "        target_vec = target_vec.view(batch_size, -1)   # 将张量 x 重塑为 (batch, 3*200)  使用 -1 作为自动计算的维度       \n",
    "        target_vec = self.target_dim_change(target_vec)\n",
    "        pay_cos_sim = F.cosine_similarity(target_history_pay_attention_vec, target_vec)\n",
    "        not_pay_cos_sim = F.cosine_similarity(target_history_not_pay_attention_vec, target_vec)\n",
    "        sim_score = np.nanmax(np.stack([pay_cos_sim, not_pay_cos_sim], axis=0), axis=0) # 两个对应值最大的那个，但里面有nan，就给nan\n",
    "        # print('pay_cos_sim',pay_cos_sim)\n",
    "        # print('not_pay_cos_sim',not_pay_cos_sim)\n",
    "        print('sim_score',sim_score)\n",
    "\n",
    "\n",
    "        # 使用softmax函数将logits转换为概率分布\n",
    "        # softmax_score = F.softmax(out_vec, dim=1)  # 在类别维度（dim=1）上应用softmax\n",
    "        sigmoid_pay_score = torch.sigmoid(out_pay_vec)  \n",
    "        sigmoid_not_pay_score = torch.sigmoid(out_not_pay_vec)\n",
    "        softmax_pay_score = torch.softmax(out_pay_vec, dim=1)\n",
    "        softmax_not_pay_score = torch.softmax(out_not_pay_vec, dim=1)\n",
    "        # print('softmax_score size=',softmax_score.shape,'score:',softmax_score)\n",
    "        # print('sigmoid_score size=',sigmoid_score.shape,'score:',sigmoid_score)\n",
    "        TargetHistory_Weight_Result ={\n",
    "            'pay_QOE':target_history_pay_attention_QOE_weight,\n",
    "            'pay_CHONGHE':target_history_pay_attention_CHONGHE_weight,\n",
    "            'pay_FUFEI':target_history_pay_attention_FUFEI_weight,\n",
    "            'not_pay_QOE':target_history_not_pay_attention_QOE_weight,\n",
    "            'not_pay_CHONGHE':target_history_not_pay_attention_CHONGHE_weight,\n",
    "            'not_pay_FUFEI':target_history_not_pay_attention_FUFEI_weight,\n",
    "        }\n",
    "        print('sigmoid_pay_score:',sigmoid_pay_score)\n",
    "        print('sigmoid_not_pay_score:',sigmoid_not_pay_score)\n",
    "        return sigmoid_pay_score, softmax_pay_score, sigmoid_not_pay_score, softmax_not_pay_score, pay_HistoryDimScaling_Weight_Result, not_pay_HistoryDimScaling_Weight_Result, TargetDimScaling_Weight_Result, TargetHistory_Weight_Result\n",
    "\n",
    "# 损失函数\n",
    "class LossFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossFunction, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target_label):\n",
    "        # pred是未经处理过的原值，target_label是0、1标签\n",
    "        # 计算第一个任务的二元交叉熵损失\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, target_label, reduction='none')\n",
    "        return loss\n",
    "\n",
    "# 输出权重结果到文件夹 首先要压缩维度到特征上，然后根据特征名列表输出\n",
    "# tensor_dict_idx = ['pay_QOE_continue','pay_QOE_discrete','pay_CHONGHE_continue','pay_CHONGHE_discrete','pay_FUFEI_continue','pay_FUFEI_discrete','target_QOE_continue','target_QOE_discrete','target_CHONGHE_continue','target_CHONGHE_discrete','target_FUFEI_continue','target_FUFEI_discrete']\n",
    "# def outPut_weight_file(output_weight_result_path,tensor_dict_idx,\n",
    "#                        HistoryDimScaling_Weight_Result, TargetDimScaling_Weight_Result, target_history_pay_attention_weight,\n",
    "#                        user_history_pay_QOE_discrete_column,user_history_pay_QOE_continue_column,\n",
    "#                        user_history_pay_CHONGHE_discrete_column,user_history_pay_CHONGHE_continue_column,\n",
    "#                        user_history_pay_FUFEI_discrete_column,user_history_pay_FUFEI_continue_column):\n",
    "#     if\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5a90faa8-237f-4578-9890-a187f8f11efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建大模型的实例 'drama_upuser_subscriptions_num,drama_sound_max_traffic_position_in_sound_avg,label1'\n",
    "model = MatchingModel(feature_category_num_dict, feature_column_dict, continue_embedding_dim,\n",
    "                 discrete_embedding_dim, num_heads, feature_dim, max_history_len)\n",
    "# print('模型创建完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "bf028181-1968-4486-b6ef-3a1d338888f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.模型训练 Trainging\n",
    "\n",
    "def model_training(model,train_loader,val_loader, lossfunction,optimizer,EPOCH,device):\n",
    "    # 定义早停策略的参数\n",
    "    best_val_loss = float('inf')  # 初始化最佳验证损失为正无穷\n",
    "    patience = 3  # 容忍多少个epoch没有验证性能提升\n",
    "    early_stopping_counter = 0  # 初始化计数器\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        model.train()  # 设置模型为训练模式\n",
    "        total_classfier_loss = 0.0\n",
    "        total_loss = 0.0\n",
    "        train_time = 0\n",
    "        val_time = 0\n",
    "        for batch in train_loader:\n",
    "            batch = [data.to(device) for data in batch]\n",
    "            batch_feature_tensor_pay_QOE_discrete,batch_feature_tensor_pay_CHONGHE_discrete,batch_feature_tensor_pay_FUFEI_discrete,\\\n",
    "            batch_feature_tensor_pay_QOE_continue,batch_feature_tensor_pay_CHONGHE_continue,batch_feature_tensor_pay_FUFEI_continue,\\\n",
    "            batch_feature_tensor_not_pay_QOE_discrete,batch_feature_tensor_not_pay_CHONGHE_discrete,batch_feature_tensor_not_pay_FUFEI_discrete,\\\n",
    "            batch_feature_tensor_not_pay_QOE_continue,batch_feature_tensor_not_pay_CHONGHE_continue,batch_feature_tensor_not_pay_FUFEI_continue,\\\n",
    "            batch_feature_tensor_target_QOE_discrete,batch_feature_tensor_target_CHONGHE_discrete,batch_feature_tensor_target_FUFEI_discrete,\\\n",
    "            batch_feature_tensor_target_QOE_continue,batch_feature_tensor_target_CHONGHE_continue,batch_feature_tensor_target_FUFEI_continue,\\\n",
    "            batch_feature_tensor_pay_QOE_discrete_mask,batch_feature_tensor_pay_CHONGHE_discrete_mask,batch_feature_tensor_pay_FUFEI_discrete_mask,\\\n",
    "            batch_feature_tensor_pay_QOE_continue_mask,batch_feature_tensor_pay_CHONGHE_continue_mask,batch_feature_tensor_pay_FUFEI_continue_mask,\\\n",
    "            batch_feature_tensor_not_pay_QOE_discrete_mask,batch_feature_tensor_not_pay_CHONGHE_discrete_mask,batch_feature_tensor_not_pay_FUFEI_discrete_mask,\\\n",
    "            batch_feature_tensor_not_pay_QOE_continue_mask,batch_feature_tensor_not_pay_CHONGHE_continue_mask,batch_feature_tensor_not_pay_FUFEI_continue_mask,\\\n",
    "            train_label_tensor = batch  \n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer.zero_grad()\n",
    "            sigmoid_pay_score, softmax_pay_score, sigmoid_not_pay_score,\\\n",
    "            softmax_not_pay_score, pay_HistoryDimScaling_Weight_Result,\\\n",
    "            not_pay_HistoryDimScaling_Weight_Result, TargetDimScaling_Weight_Result, \\\n",
    "            TargetHistory_Weight_Result = model(batch_feature_tensor_pay_QOE_discrete,batch_feature_tensor_pay_CHONGHE_discrete,batch_feature_tensor_pay_FUFEI_discrete,\\\n",
    "                                                batch_feature_tensor_pay_QOE_continue,batch_feature_tensor_pay_CHONGHE_continue,batch_feature_tensor_pay_FUFEI_continue,\\\n",
    "                                                batch_feature_tensor_not_pay_QOE_discrete,batch_feature_tensor_not_pay_CHONGHE_discrete,batch_feature_tensor_not_pay_FUFEI_discrete,\\\n",
    "                                                batch_feature_tensor_not_pay_QOE_continue,batch_feature_tensor_not_pay_CHONGHE_continue,batch_feature_tensor_not_pay_FUFEI_continue,\\\n",
    "                                                batch_feature_tensor_target_QOE_discrete,batch_feature_tensor_target_CHONGHE_discrete,batch_feature_tensor_target_FUFEI_discrete,\\\n",
    "                                                batch_feature_tensor_target_QOE_continue,batch_feature_tensor_target_CHONGHE_continue,batch_feature_tensor_target_FUFEI_continue,\\\n",
    "                                                batch_feature_tensor_pay_QOE_discrete_mask,batch_feature_tensor_pay_CHONGHE_discrete_mask,batch_feature_tensor_pay_FUFEI_discrete_mask,\\\n",
    "                                                batch_feature_tensor_pay_QOE_continue_mask,batch_feature_tensor_pay_CHONGHE_continue_mask,batch_feature_tensor_pay_FUFEI_continue_mask,\\\n",
    "                                                batch_feature_tensor_not_pay_QOE_discrete_mask,batch_feature_tensor_not_pay_CHONGHE_discrete_mask,batch_feature_tensor_not_pay_FUFEI_discrete_mask,\\\n",
    "                                                batch_feature_tensor_not_pay_QOE_continue_mask,batch_feature_tensor_not_pay_CHONGHE_continue_mask,batch_feature_tensor_not_pay_FUFEI_continue_mask,\\\n",
    "                                                train_label_tensor)  \n",
    "\n",
    "            # print('HistoryDimScaling_Weight_Result, TargetDimScaling_Weight_Result, target_history_pay_attention_weight',\n",
    "            #      HistoryDimScaling_Weight_Result['mutli_QOE_weight'].shape, TargetDimScaling_Weight_Result['se_QOE_weight'].shape, target_history_pay_attention_weight.shape)\n",
    "            # sigmoid\n",
    "            sigmoid_score = sigmoid_score[:, 0]  # (样本数，1)\n",
    "            train_label_tensor = train_label_tensor[:, 0].to(device)  # (样本数，1)\n",
    "            train_label_tensor[train_label_tensor == 1] = 0\n",
    "            train_label_tensor[train_label_tensor == 2] = 1\n",
    "            # train_label_tensor = torch.where(train_label_tensor == 1, torch.tensor(0).to(device), torch.tensor(1).to(device))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "            loss = lossfunction(sigmoid_score, train_label_tensor.float())\n",
    "            # softmax\n",
    "            softmax_score = softmax_score[:, 0]  # (样本数，1)\n",
    "            # train_label_tensor = train_label_tensor[:, 0].to(device)  # (样本数，1)\n",
    "            # rain_label_tensor[train_label_tensor == 1] = 0\n",
    "            # train_label_tensor[train_label_tensor == 2] = 1\n",
    "            # # train_label_tensor = torch.where(train_label_tensor == 1, torch.tensor(0).to(device), torch.tensor(1).to(device))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "            # loss = lossfunction(softmax_score, train_label_tensor.float())\n",
    "            # loss.to(device)\n",
    "            \n",
    "             # loss回传检查\n",
    "            # for name, parms in model.named_parameters():\t\n",
    "            #     if parms.grad is not None:  # 检查梯度是否为None\n",
    "            #         grad_mean = torch.mean(parms.grad)  # 计算梯度的均值\n",
    "            #         print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '-->grad_mean: {:.4f}'.format(grad_mean))\n",
    "            #     else:\n",
    "            #         print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '-->grad_mean: None')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(\"=============更新之后===========\")\n",
    "            # for name, parms in model.named_parameters():\t\n",
    "            #     if parms.grad is not None:  # 检查梯度是否为None\n",
    "            #         grad_mean = torch.mean(parms.grad)  # 计算梯度的均值\n",
    "            #         print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '-->grad_mean: {:.4f}'.format(grad_mean))\n",
    "            #     else:\n",
    "            #         print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '-->grad_mean: None')\n",
    "            # print(optimizer)\n",
    "            # input(\"=====迭代结束=====\")\n",
    "\n",
    "            # 损失\n",
    "            total_loss += loss.item()\n",
    "            train_time += 1\n",
    "            print('||--训练：----------',train_time,'个batch运行时间：',datetime.datetime.now(),'-------------')\n",
    "        # 平均损失\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        \n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1},loss:{average_loss}\")\n",
    "\n",
    "            # 验证集评估\n",
    "            model.eval()  # 将模型切换为评估模式\n",
    "            with torch.no_grad():  # 在评估模式下不计算梯度\n",
    "                total_loss_val = 0.0\n",
    "                total_auc_val = 0.0\n",
    "                val_time = 0\n",
    "                for batch_val in val_loader:  # 假设你有一个名为 val_loader 的验证集数据加载器\n",
    "                    batch_val = [data.to(device) for data in batch_val]\n",
    "                    val_batch_feature_tensor_pay_QOE_discrete,val_batch_feature_tensor_pay_CHONGHE_discrete,val_batch_feature_tensor_pay_FUFEI_discrete,\\\n",
    "                    val_batch_feature_tensor_pay_QOE_continue,val_batch_feature_tensor_pay_CHONGHE_continue,val_batch_feature_tensor_pay_FUFEI_continue,\\\n",
    "                    val_batch_feature_tensor_not_pay_QOE_discrete,val_batch_feature_tensor_not_pay_CHONGHE_discrete,val_batch_feature_tensor_not_pay_FUFEI_discrete,\\\n",
    "                    val_batch_feature_tensor_not_pay_QOE_continue,val_batch_feature_tensor_not_pay_CHONGHE_continue,val_batch_feature_tensor_not_pay_FUFEI_continue,\\\n",
    "                    val_batch_feature_tensor_target_QOE_discrete,val_batch_feature_tensor_target_CHONGHE_discrete,val_batch_feature_tensor_target_FUFEI_discrete,\\\n",
    "                    val_batch_feature_tensor_target_QOE_continue,val_batch_feature_tensor_target_CHONGHE_continue,val_batch_feature_tensor_target_FUFEI_continue,\\\n",
    "                    val_batch_feature_tensor_pay_QOE_discrete_mask,val_batch_feature_tensor_pay_CHONGHE_discrete_mask,val_batch_feature_tensor_pay_FUFEI_discrete_mask,\\\n",
    "                    val_batch_feature_tensor_pay_QOE_continue_mask,val_batch_feature_tensor_pay_CHONGHE_continue_mask,val_batch_feature_tensor_pay_FUFEI_continue_mask,\\\n",
    "                    val_batch_feature_tensor_not_pay_QOE_discrete_mask,val_batch_feature_tensor_not_pay_CHONGHE_discrete_mask,val_batch_feature_tensor_not_pay_FUFEI_discrete_mask,\\\n",
    "                    val_batch_feature_tensor_not_pay_QOE_continue_mask,val_batch_feature_tensor_not_pay_CHONGHE_continue_mask,val_batch_feature_tensor_not_pay_FUFEI_continue_mask,\\\n",
    "                    val_label_tensor = batch_val \n",
    "                    sigmoid_pay_score_val, softmax_pay_score, sigmoid_not_pay_score_val, \\\n",
    "                    softmax_not_pay_score_val, pay_HistoryDimScaling_Weight_Result_val, \\\n",
    "                    not_pay_HistoryDimScaling_Weight_Result_val, TargetDimScaling_Weight_Result_val, \\\n",
    "                    TargetHistory_Weight_Result_val = model(val_batch_feature_tensor_pay_QOE_discrete,val_batch_feature_tensor_pay_CHONGHE_discrete,val_batch_feature_tensor_pay_FUFEI_discrete,\\\n",
    "                                                        val_batch_feature_tensor_pay_QOE_continue,val_batch_feature_tensor_pay_CHONGHE_continue,val_batch_feature_tensor_pay_FUFEI_continue,\\\n",
    "                                                        val_batch_feature_tensor_not_pay_QOE_discrete,val_batch_feature_tensor_not_pay_CHONGHE_discrete,val_batch_feature_tensor_not_pay_FUFEI_discrete,\\\n",
    "                                                        val_batch_feature_tensor_not_pay_QOE_continue,val_batch_feature_tensor_not_pay_CHONGHE_continue,val_batch_feature_tensor_not_pay_FUFEI_continue,\\\n",
    "                                                        val_batch_feature_tensor_target_QOE_discrete,val_batch_feature_tensor_target_CHONGHE_discrete,val_batch_feature_tensor_target_FUFEI_discrete,\\\n",
    "                                                        val_batch_feature_tensor_target_QOE_continue,val_batch_feature_tensor_target_CHONGHE_continue,val_batch_feature_tensor_target_FUFEI_continue,\\\n",
    "                                                        val_batch_feature_tensor_pay_QOE_discrete_mask,val_batch_feature_tensor_pay_CHONGHE_discrete_mask,val_batch_feature_tensor_pay_FUFEI_discrete_mask,\\\n",
    "                                                        val_batch_feature_tensor_pay_QOE_continue_mask,val_batch_feature_tensor_pay_CHONGHE_continue_mask,val_batch_feature_tensor_pay_FUFEI_continue_mask,\\\n",
    "                                                        val_batch_feature_tensor_not_pay_QOE_discrete_mask,val_batch_feature_tensor_not_pay_CHONGHE_discrete_mask,val_batch_feature_tensor_not_pay_FUFEI_discrete_mask,\\\n",
    "                                                        val_batch_feature_tensor_not_pay_QOE_continue_mask,val_batch_feature_tensor_not_pay_CHONGHE_continue_mask,val_batch_feature_tensor_not_pay_FUFEI_continue_mask,\\\n",
    "                                                        val_label_tensor) \n",
    "\n",
    "                    # sigmoid\n",
    "                    sigmoid_score_val = sigmoid_score_val[:, 0]  # (样本数，1)\n",
    "                    sigmoid_score_val = sigmoid_score_val.cpu()# .detach()  # 转为CPU\n",
    "                    val_label_tensor = val_label_tensor[:, 0]  # (样本数，1)\n",
    "                    val_label_tensor = val_label_tensor.cpu()\n",
    "                    val_label_tensor[val_label_tensor == 1] = 0\n",
    "                    val_label_tensor[val_label_tensor == 2] = 1\n",
    "                    # val_label_tensor = torch.where(val_label_tensor == 1, torch.tensor(0), torch.tensor(1))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "                    loss_val = lossfunction(sigmoid_score_val, val_label_tensor.float())\n",
    "                    # softmax\n",
    "                    # softmax_score_val = softmax_score_val[:, 0]  # (样本数，1)\n",
    "                    # softmax_score_val = softmax_score_val.cpu()# .detach()  # 转为CPU\n",
    "                    # val_label_tensor = val_label_tensor[:, 0]  # (样本数，1)\n",
    "                    # val_label_tensor = val_label_tensor.cpu()\n",
    "                    # val_label_tensor[val_label_tensor == 1] = 0\n",
    "                    # val_label_tensor[val_label_tensor == 2] = 1\n",
    "                    # # val_label_tensor = torch.where(val_label_tensor == 1, torch.tensor(0), torch.tensor(1))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "                    # loss_val = lossfunction(softmax_score_val, val_label_tensor.float())\n",
    "    \n",
    "                    # 损失\n",
    "                    total_loss_val += loss_val.item()\n",
    "                    # 计算验证集上的AUC   待修改\n",
    "                    correct_val = loss_val.sum().item()\n",
    "                    total_auc_val += roc_auc_score(val_label_tensor, sigmoid_score_val)\n",
    "                    # total_auc_val += roc_auc_score(val_label_tensor, softmax_score_val)\n",
    "                    val_time += 1\n",
    "                    print('||--验证：----------',val_time,'个batch运行时间：',datetime.datetime.now(),'-------------')\n",
    "                # 平均损失\n",
    "                average_loss_val = total_loss_val / len(val_loader)\n",
    "                average_auc_val = total_auc_val / len(val_loader)\n",
    "                print(f\"Validation Loss: {average_loss_val},AUC: {average_auc_val}\") \n",
    "\n",
    "                if average_loss_val < best_val_loss:\n",
    "                    best_val_loss = average_loss_val\n",
    "                    early_stopping_counter = 0\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "                if early_stopping_counter >= patience:\n",
    "                    print(f\"早停策略触发，停止训练在第 {epoch} 个epoch.\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "5cf0a32d-b61b-484f-a801-8c16e3d792be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型测试 Test\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 在评估模式下不计算梯度\n",
    "        total_loss_test = 0.0\n",
    "        total_auc_test = 0.0\n",
    "        test_time = 0\n",
    "        results = []  # 用于保存结果的列表\n",
    "        for batch_test in test_loader:  # 假设你有一个名为 val_loader 的验证集数据加载器\n",
    "            batch_test = [data.to(device) for data in batch_test]\n",
    "            test_batch_feature_tensor_pay_QOE_discrete,test_batch_feature_tensor_pay_CHONGHE_discrete,test_batch_feature_tensor_pay_FUFEI_discrete,\n",
    "            test_batch_feature_tensor_pay_QOE_continue,test_batch_feature_tensor_pay_CHONGHE_continue,test_batch_feature_tensor_pay_FUFEI_continue,\n",
    "            test_batch_feature_tensor_not_pay_QOE_discrete,test_batch_feature_tensor_not_pay_CHONGHE_discrete,test_batch_feature_tensor_not_pay_FUFEI_discrete,\n",
    "            test_batch_feature_tensor_not_pay_QOE_continue,test_batch_feature_tensor_not_pay_CHONGHE_continue,test_batch_feature_tensor_not_pay_FUFEI_continue,\n",
    "            test_batch_feature_tensor_target_QOE_discrete,test_batch_feature_tensor_target_CHONGHE_discrete,test_batch_feature_tensor_target_FUFEI_discrete,\n",
    "            test_batch_feature_tensor_target_QOE_continue,test_batch_feature_tensor_target_CHONGHE_continue,test_batch_feature_tensor_target_FUFEI_continue,\n",
    "            test_batch_feature_tensor_pay_QOE_discrete_mask,test_batch_feature_tensor_pay_CHONGHE_discrete_mask,test_batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "            test_batch_feature_tensor_pay_QOE_continue_mask,test_batch_feature_tensor_pay_CHONGHE_continue_mask,test_batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "            test_batch_feature_tensor_not_pay_QOE_discrete_mask,test_batch_feature_tensor_not_pay_CHONGHE_discrete_mask,test_batch_feature_tensor_not_pay_FUFEI_discrete_mask,\n",
    "            test_batch_feature_tensor_not_pay_QOE_continue_mask,test_batch_feature_tensor_not_pay_CHONGHE_continue_mask,test_batch_feature_tensor_not_pay_FUFEI_continue_mask,\n",
    "            test_label_tensor= batch_test \n",
    "            sigmoid_pay_score_test, softmax_pay_score_test, sigmoid_not_pay_score_test, \\\n",
    "            softmax_not_pay_score_test, pay_HistoryDimScaling_Weight_Result_test, \\\n",
    "            not_pay_HistoryDimScaling_Weight_Result_test, TargetDimScaling_Weight_Result_test, \\\n",
    "            TargetHistory_Weight_Result_test = model(test_batch_feature_tensor_pay_QOE_discrete,test_batch_feature_tensor_pay_CHONGHE_discrete,test_batch_feature_tensor_pay_FUFEI_discrete,\n",
    "                                                test_batch_feature_tensor_pay_QOE_continue,test_batch_feature_tensor_pay_CHONGHE_continue,test_batch_feature_tensor_pay_FUFEI_continue,\n",
    "                                                test_batch_feature_tensor_not_pay_QOE_discrete,test_batch_feature_tensor_not_pay_CHONGHE_discrete,test_batch_feature_tensor_not_pay_FUFEI_discrete,\n",
    "                                                test_batch_feature_tensor_not_pay_QOE_continue,test_batch_feature_tensor_not_pay_CHONGHE_continue,test_batch_feature_tensor_not_pay_FUFEI_continue,\n",
    "                                                test_batch_feature_tensor_target_QOE_discrete,test_batch_feature_tensor_target_CHONGHE_discrete,test_batch_feature_tensor_target_FUFEI_discrete,\n",
    "                                                test_batch_feature_tensor_target_QOE_continue,test_batch_feature_tensor_target_CHONGHE_continue,test_batch_feature_tensor_target_FUFEI_continue,\n",
    "                                                test_batch_feature_tensor_pay_QOE_discrete_mask,test_batch_feature_tensor_pay_CHONGHE_discrete_mask,test_batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "                                                test_batch_feature_tensor_pay_QOE_continue_mask,test_batch_feature_tensor_pay_CHONGHE_continue_mask,test_batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "                                                test_batch_feature_tensor_not_pay_QOE_discrete_mask,test_batch_feature_tensor_not_pay_CHONGHE_discrete_mask,test_batch_feature_tensor_not_pay_FUFEI_discrete_mask,\n",
    "                                                test_batch_feature_tensor_not_pay_QOE_continue_mask,test_batch_feature_tensor_not_pay_CHONGHE_continue_mask,test_batch_feature_tensor_not_pay_FUFEI_continue_mask,\n",
    "                                                test_label_tensor)  \n",
    "\n",
    "            # sigmoid\n",
    "            sigmoid_score_test = sigmoid_score_test[:, 0]  # (样本数，1)\n",
    "            sigmoid_score_test = sigmoid_score_test.cpu()#.detach()  # 转为CPU\n",
    "            test_label_tensor = test_label_tensor[:, 0]  # (样本数，1)\n",
    "            test_label_tensor = test_label_tensor.cpu()\n",
    "            test_label_tensor[test_label_tensor == 1] = 0\n",
    "            test_label_tensor[test_label_tensor == 2] = 1\n",
    "            # test_label_tensor = torch.where(test_label_tensor == 1, torch.tensor(0), torch.tensor(1))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "            loss_test = lossfunction(sigmoid_score_test, test_label_tensor.float())\n",
    "            # softmax\n",
    "            # softmax_score_test = softmax_score_test[:, 0]  # (样本数，1)\n",
    "            # softmax_score_test = softmax_score_test.cpu()#.detach()  # 转为CPU\n",
    "            # test_label_tensor = test_label_tensor[:, 0]  # (样本数，1)\n",
    "            # test_label_tensor = test_label_tensor.cpu()\n",
    "            # test_label_tensor[test_label_tensor == 1] = 0\n",
    "            # test_label_tensor[test_label_tensor == 2] = 1\n",
    "            # # test_label_tensor = torch.where(test_label_tensor == 1, torch.tensor(0), torch.tensor(1))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "            # loss_test = lossfunction(softmax_score_test, test_label_tensor.float())\n",
    "            # 损失\n",
    "            total_loss_test += loss_test.item()\n",
    "            # 计算验证集上的AUC   待修改\n",
    "            correct_test = loss_test.sum().item()\n",
    "            total_auc_test += roc_auc_score(test_label_tensor, sigmoid_score_test)\n",
    "            # total_auc_test += roc_auc_score(test_label_tensor, softmax_score_test)\n",
    "            test_time += 1\n",
    "            print('||--测试：----------',test_time,'个batch运行时间：',datetime.datetime.now(),'-------------')\n",
    "        # 平均损失\n",
    "        average_loss_test = total_loss_test / len(test_loader)\n",
    "        average_auc_test = total_auc_test / len(test_loader)\n",
    "        print(\n",
    "            f\"Test Loss: {average_loss_test},AUC: {average_auc_test}\")\n",
    "        return average_loss_test, average_auc_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "9ccf0921-8a05-4ee5-beda-d085cdd1e5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=:1\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "1.Embedding:user_history_QOE_vec torch.Size([128, 6, 25, 200]) torch.Size([128, 6, 25])\n",
      "2.0.二、三维度互换 ）user_history_QOE_vec torch.Size([128, 25, 6, 200]) tensor([[[[ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.7040,  0.5790,  0.3030,  ...,  0.7558,  0.4814,  0.5564],\n",
      "          [ 0.6307,  0.6405, -0.5339,  ..., -0.4887,  0.3610,  1.4006],\n",
      "          [ 0.7040,  0.5790,  0.3030,  ...,  0.7558,  0.4814,  0.5564]],\n",
      "\n",
      "         [[ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [-1.8924, -0.1033,  0.3453,  ...,  0.1420,  0.7252,  1.3673],\n",
      "          [-0.8011,  0.8690, -1.9446,  ..., -0.5160, -0.3954,  0.4136],\n",
      "          [-0.8011,  0.8690, -1.9446,  ..., -0.5160, -0.3954,  0.4136]],\n",
      "\n",
      "         [[ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 0.9538, -0.6349,  0.7260,  ..., -0.6902, -0.5772, -0.9151],\n",
      "          [ 0.9538, -0.6349,  0.7260,  ..., -0.6902, -0.5772, -0.9151],\n",
      "          [ 0.9538, -0.6349,  0.7260,  ..., -0.6902, -0.5772, -0.9151]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5159, -0.5032,  0.2767,  ..., -0.8407, -0.2286, -0.4477],\n",
      "          [ 0.5784, -0.7851,  0.3804,  ..., -1.0464, -0.3672, -0.2487],\n",
      "          [ 0.7241, -1.4424,  0.6220,  ..., -1.5259, -0.6903,  0.2153]],\n",
      "\n",
      "         [[ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.7091, -0.9274,  0.7641,  ..., -1.0874, -0.8887, -0.3327],\n",
      "          [ 0.9488, -1.5733,  0.3679,  ..., -1.7026, -0.8892, -0.1272],\n",
      "          [ 0.3569,  0.0221,  1.3466,  ..., -0.1832, -0.8879, -0.6348]],\n",
      "\n",
      "         [[-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.0118, -0.9414, -0.0113,  ...,  0.8822,  0.0602, -1.6379],\n",
      "          [ 0.1602, -1.1283,  0.4148,  ...,  0.8741, -0.1275, -2.0307],\n",
      "          [-0.8376, -0.0442, -2.0570,  ...,  0.9211,  0.9614,  0.2479]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [-0.3384,  0.0247,  0.9063,  ..., -1.6238, -1.1033,  0.9232],\n",
      "          [ 0.7040,  0.5790,  0.3030,  ...,  0.7558,  0.4814,  0.5564],\n",
      "          [ 0.7040,  0.5790,  0.3030,  ...,  0.7558,  0.4814,  0.5564]],\n",
      "\n",
      "         [[ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 1.6023,  1.2949,  0.8938,  ..., -0.4309,  0.4651,  0.3429],\n",
      "          [-0.5968, -0.2585,  0.3178,  ..., -0.4937,  1.0082, -0.9336],\n",
      "          [-0.6718,  1.4165,  1.3216,  ..., -1.6964, -0.5930,  0.8128]],\n",
      "\n",
      "         [[ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.0337, -0.6014,  0.8096,  ..., -0.7870, -0.6306, -1.0484],\n",
      "          [ 1.0337, -0.6014,  0.8096,  ..., -0.7870, -0.6306, -1.0484],\n",
      "          [ 1.0337, -0.6014,  0.8096,  ..., -0.7870, -0.6306, -1.0484]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.3705,  0.1523,  0.0357,  ..., -0.3624,  0.0938, -0.9105],\n",
      "          [ 0.1821,  1.0022, -0.2767,  ...,  0.2576,  0.5116, -1.5104],\n",
      "          [ 0.4949, -0.4089,  0.2420,  ..., -0.7719, -0.1822, -0.5143]],\n",
      "\n",
      "         [[ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 1.0082, -1.7334,  0.2697,  ..., -1.8551, -0.8893, -0.0762],\n",
      "          [ 1.3434, -2.6372, -0.2848,  ..., -2.7158, -0.8900,  0.2113],\n",
      "          [ 0.6188, -0.6838,  0.9136,  ..., -0.8555, -0.8885, -0.4102]],\n",
      "\n",
      "         [[-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [ 0.1808, -1.1507,  0.4660,  ...,  0.8731, -0.1500, -2.0779],\n",
      "          [ 0.0993, -1.0621,  0.2640,  ...,  0.8769, -0.0610, -1.8917],\n",
      "          [-0.3225, -0.6038, -0.7810,  ...,  0.8968,  0.3993, -0.9284]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.7040,  0.5790,  0.3030,  ...,  0.7558,  0.4814,  0.5564],\n",
      "          [ 0.7040,  0.5790,  0.3030,  ...,  0.7558,  0.4814,  0.5564],\n",
      "          [-0.3384,  0.0247,  0.9063,  ..., -1.6238, -1.1033,  0.9232],\n",
      "          [ 0.7065, -0.2474, -1.5250,  ...,  0.2247, -0.7820, -0.8357],\n",
      "          [-0.3384,  0.0247,  0.9063,  ..., -1.6238, -1.1033,  0.9232]],\n",
      "\n",
      "         [[ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.9375, -0.8170,  0.2259,  ...,  0.3815,  0.3634, -0.9614],\n",
      "          [-0.2695,  0.1274,  0.4586,  ...,  1.0385,  0.8528,  0.1370],\n",
      "          [ 0.3885, -2.1283,  0.2980,  ...,  0.4963,  0.9866,  1.2333],\n",
      "          [-1.8613, -0.4912,  1.8404,  ...,  1.3098,  0.4377,  0.3918],\n",
      "          [ 0.3885, -2.1283,  0.2980,  ...,  0.4963,  0.9866,  1.2333]],\n",
      "\n",
      "         [[ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 0.3136, -0.9032,  0.0559,  ...,  0.0862, -0.1492,  0.1532],\n",
      "          [ 0.3136, -0.9032,  0.0559,  ...,  0.0862, -0.1492,  0.1532],\n",
      "          [ 0.3136, -0.9032,  0.0559,  ...,  0.0862, -0.1492,  0.1532],\n",
      "          [ 0.3136, -0.9032,  0.0559,  ...,  0.0862, -0.1492,  0.1532],\n",
      "          [ 0.3136, -0.9032,  0.0559,  ...,  0.0862, -0.1492,  0.1532]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.1783,  1.0191, -0.2830,  ...,  0.2700,  0.5199, -1.5224],\n",
      "          [ 0.2849,  0.5385, -0.1063,  ..., -0.0807,  0.2836, -1.1831],\n",
      "          [ 0.4297, -0.1144,  0.1338,  ..., -0.5570, -0.0374, -0.7222],\n",
      "          [ 0.4329, -0.1291,  0.1392,  ..., -0.5678, -0.0446, -0.7118],\n",
      "          [ 0.5739, -0.7649,  0.3729,  ..., -1.0316, -0.3572, -0.2630]],\n",
      "\n",
      "         [[ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.6320, -0.7195,  0.8917,  ..., -0.8894, -0.8885, -0.3988],\n",
      "          [ 0.7941, -1.1563,  0.6237,  ..., -1.3055, -0.8889, -0.2598],\n",
      "          [ 1.0004, -1.7125,  0.2825,  ..., -1.8351, -0.8893, -0.0829],\n",
      "          [ 0.7645, -1.0767,  0.6725,  ..., -1.2297, -0.8888, -0.2852],\n",
      "          [ 0.6249, -0.7002,  0.9035,  ..., -0.8711, -0.8885, -0.4049]],\n",
      "\n",
      "         [[-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.4425, -0.4735, -1.0782,  ...,  0.9025,  0.5302, -0.6544],\n",
      "          [-0.1941, -0.7433, -0.4629,  ...,  0.8908,  0.2592, -1.2216],\n",
      "          [-0.1458, -0.7958, -0.3432,  ...,  0.8885,  0.2065, -1.3319],\n",
      "          [-0.2710, -0.6598, -0.6534,  ...,  0.8944,  0.3431, -1.0460],\n",
      "          [-0.3997, -0.5199, -0.9723,  ...,  0.9005,  0.4836, -0.7520]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290]],\n",
      "\n",
      "         [[ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994]],\n",
      "\n",
      "         [[ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800]],\n",
      "\n",
      "         [[ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795]],\n",
      "\n",
      "         [[-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290]],\n",
      "\n",
      "         [[ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994]],\n",
      "\n",
      "         [[ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800]],\n",
      "\n",
      "         [[ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795]],\n",
      "\n",
      "         [[-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "          [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290]],\n",
      "\n",
      "         [[ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "          [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994]],\n",
      "\n",
      "         [[ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "          [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "          [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800]],\n",
      "\n",
      "         [[ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "          [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795]],\n",
      "\n",
      "         [[-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "          [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "2.样本数*特征数,历史数，200）user_history_QOE_vec torch.Size([3200, 6, 200]) tensor([[[ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "         [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "         [ 0.6798, -2.4044,  0.1349,  ...,  0.4091, -0.8988, -1.5290],\n",
      "         [ 0.7040,  0.5790,  0.3030,  ...,  0.7558,  0.4814,  0.5564],\n",
      "         [ 0.6307,  0.6405, -0.5339,  ..., -0.4887,  0.3610,  1.4006],\n",
      "         [ 0.7040,  0.5790,  0.3030,  ...,  0.7558,  0.4814,  0.5564]],\n",
      "\n",
      "        [[ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "         [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "         [ 0.6119, -0.6954,  0.2369,  ..., -1.1982, -0.9775,  1.4994],\n",
      "         [-1.8924, -0.1033,  0.3453,  ...,  0.1420,  0.7252,  1.3673],\n",
      "         [-0.8011,  0.8690, -1.9446,  ..., -0.5160, -0.3954,  0.4136],\n",
      "         [-0.8011,  0.8690, -1.9446,  ..., -0.5160, -0.3954,  0.4136]],\n",
      "\n",
      "        [[ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "         [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "         [ 1.2459, -0.5124,  1.0317,  ..., -1.0444, -0.7725, -1.4025],\n",
      "         [ 0.9538, -0.6349,  0.7260,  ..., -0.6902, -0.5772, -0.9151],\n",
      "         [ 0.9538, -0.6349,  0.7260,  ..., -0.6902, -0.5772, -0.9151],\n",
      "         [ 0.9538, -0.6349,  0.7260,  ..., -0.6902, -0.5772, -0.9151]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "         [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "         [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "         [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "         [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800],\n",
      "         [ 0.5999, -0.8824,  0.4161,  ..., -1.1174, -0.4150, -0.1800]],\n",
      "\n",
      "        [[ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "         [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "         [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "         [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "         [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795],\n",
      "         [ 0.3048,  0.1626,  1.4328,  ..., -0.0494, -0.8878, -0.6795]],\n",
      "\n",
      "        [[-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "         [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "         [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "         [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "         [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713],\n",
      "         [-0.7603, -0.1281, -1.8655,  ...,  0.9175,  0.8771,  0.0713]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "pay_QOE_mask tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]])\n",
      "3.(样本数*特征数，200）multi_user_history_QOE_vec torch.Size([3200, 1, 200]) tensor([[[ 0.0480,  0.0221, -0.1309,  ...,  0.4395,  0.0480, -0.1617]],\n",
      "\n",
      "        [[ 0.3784,  0.2219,  0.4207,  ...,  0.4286, -0.2826,  0.4751]],\n",
      "\n",
      "        [[-0.0072,  0.2809, -0.6635,  ...,  0.5795,  0.1012,  0.7698]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "4.(样本数,特征数，200）multi_user_history_QOE_vec torch.Size([128, 25, 200]) tensor([[[ 0.0480,  0.0221, -0.1309,  ...,  0.4395,  0.0480, -0.1617],\n",
      "         [ 0.3784,  0.2219,  0.4207,  ...,  0.4286, -0.2826,  0.4751],\n",
      "         [-0.0072,  0.2809, -0.6635,  ...,  0.5795,  0.1012,  0.7698],\n",
      "         ...,\n",
      "         [ 0.6192,  0.0582, -0.5219,  ..., -0.1080, -0.7825,  0.2720],\n",
      "         [ 0.1028, -0.1878,  0.3253,  ..., -0.2211,  0.0868,  0.2511],\n",
      "         [-0.2178, -0.4137, -0.1553,  ..., -0.4908, -0.4036,  0.1466]],\n",
      "\n",
      "        [[ 0.0716, -0.3139,  0.1051,  ...,  0.2139, -0.3225,  0.0113],\n",
      "         [-0.0293, -0.0198,  0.1618,  ..., -0.0990,  0.2824, -0.0019],\n",
      "         [ 0.0076,  0.3236, -0.6602,  ...,  0.5787,  0.0729,  0.7975],\n",
      "         ...,\n",
      "         [ 0.2963,  0.2589, -0.3456,  ..., -0.4288, -0.0060, -0.4732],\n",
      "         [ 0.0713, -0.0844,  0.7453,  ...,  0.1585,  0.4906,  0.4860],\n",
      "         [-0.2159, -0.3465, -0.0948,  ..., -0.5326, -0.4175,  0.4969]],\n",
      "\n",
      "        [[-0.0721, -0.1610,  0.0555,  ...,  0.1079, -0.2634,  0.0548],\n",
      "         [-0.2042,  0.2126, -0.5563,  ...,  0.0668,  0.3454, -0.0113],\n",
      "         [-0.1258, -0.0610, -0.6902,  ...,  0.5859,  0.3277,  0.5479],\n",
      "         ...,\n",
      "         [ 0.3317,  0.2369, -0.3649,  ..., -0.3910, -0.0976, -0.3853],\n",
      "         [ 0.0932, -0.1561,  0.4541,  ..., -0.0962,  0.2197,  0.3284],\n",
      "         [-0.2195, -0.4691, -0.2051,  ..., -0.4852, -0.4018,  0.0993]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         ...,\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         ...,\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         ...,\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "multi_user_history_CHONGHE_vec torch.Size([128, 27, 200]) tensor([[[ 1.0907e+00,  9.8104e-01, -7.0592e-01,  ...,  1.1120e+00,\n",
      "           7.7557e-01, -1.2583e-01],\n",
      "         [ 8.5948e-01, -1.6409e-01,  1.8469e-01,  ...,  4.2874e-01,\n",
      "           1.6136e-01, -6.6398e-02],\n",
      "         [ 6.2412e-01,  1.0804e-01,  2.5646e-02,  ...,  2.7032e-01,\n",
      "           4.2760e-01, -1.8464e-01],\n",
      "         ...,\n",
      "         [ 2.9228e-01, -8.6993e-02,  3.2981e-01,  ..., -3.8036e-01,\n",
      "          -2.1614e-01, -6.4813e-04],\n",
      "         [-5.1916e-02,  7.2850e-01, -2.1538e-01,  ..., -2.4008e-01,\n",
      "           8.7577e-02,  1.1034e-01],\n",
      "         [ 8.6576e-01,  7.6468e-02,  3.4302e-01,  ...,  1.8028e-01,\n",
      "          -2.2403e-01, -8.7739e-02]],\n",
      "\n",
      "        [[ 1.0124e+00,  1.2403e-02,  8.2106e-02,  ..., -4.9027e-01,\n",
      "          -1.9652e-01,  2.0524e-01],\n",
      "         [ 8.5948e-01, -1.6409e-01,  1.8469e-01,  ...,  4.2874e-01,\n",
      "           1.6136e-01, -6.6398e-02],\n",
      "         [-1.2810e+00, -5.8910e-02, -4.4322e-01,  ..., -5.4027e-01,\n",
      "           2.4055e-01, -2.4766e-01],\n",
      "         ...,\n",
      "         [ 2.9843e-01, -8.5072e-02,  3.4288e-01,  ..., -3.7128e-01,\n",
      "          -2.1510e-01,  1.1313e-02],\n",
      "         [ 3.1215e-01,  1.0853e-01,  5.5005e-02,  ..., -5.9296e-01,\n",
      "           3.6157e-02, -3.7667e-01],\n",
      "         [ 9.0228e-01,  6.4095e-02,  3.1453e-01,  ...,  2.0419e-01,\n",
      "          -2.6360e-01, -9.4643e-02]],\n",
      "\n",
      "        [[ 1.0124e+00,  1.2403e-02,  8.2106e-02,  ..., -4.9027e-01,\n",
      "          -1.9652e-01,  2.0524e-01],\n",
      "         [-5.0901e-02,  5.6263e-01, -6.8647e-01,  ..., -1.1301e-01,\n",
      "           3.8528e-01,  1.2567e-01],\n",
      "         [ 3.2796e-01, -2.8964e-01,  3.1717e-01,  ..., -2.0432e-03,\n",
      "          -2.8958e-01, -1.0821e+00],\n",
      "         ...,\n",
      "         [ 2.5623e-01, -9.8254e-02,  2.5312e-01,  ..., -4.3189e-01,\n",
      "          -2.2203e-01, -6.8499e-02],\n",
      "         [ 2.7854e-02,  5.9266e-01, -1.5613e-01,  ..., -2.9490e-01,\n",
      "           7.9589e-02,  3.4686e-02],\n",
      "         [ 1.0143e+00,  2.6148e-02,  2.2715e-01,  ...,  2.8144e-01,\n",
      "          -3.9148e-01, -1.1695e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         ...,\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan]],\n",
      "\n",
      "        [[        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         ...,\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan]],\n",
      "\n",
      "        [[        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         ...,\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan]]], grad_fn=<ViewBackward0>)\n",
      "multi_user_history_FUFEI_vec torch.Size([128, 31, 200]) tensor([[[ 1.3634, -0.8165,  0.1858,  ...,  0.9506, -0.4748, -0.0100],\n",
      "         [ 0.2079, -0.2789, -1.1081,  ..., -1.4094, -0.6028, -0.0370],\n",
      "         [ 0.2486, -0.2328, -0.2838,  ..., -0.8247, -0.2216,  0.2976],\n",
      "         ...,\n",
      "         [ 0.5171, -1.1403,  0.0574,  ..., -0.6696, -0.1192,  0.6095],\n",
      "         [-0.3903, -0.0738, -0.0505,  ..., -0.8919,  0.2097,  0.3949],\n",
      "         [-0.2119, -0.0366,  0.3430,  ..., -0.1532, -0.1091, -0.0395]],\n",
      "\n",
      "        [[ 1.3634, -0.8165,  0.1858,  ...,  0.9506, -0.4748, -0.0100],\n",
      "         [ 0.2079, -0.2789, -1.1081,  ..., -1.4094, -0.6028, -0.0370],\n",
      "         [ 0.0674, -0.5993, -0.1182,  ..., -0.4871, -0.2390,  0.1768],\n",
      "         ...,\n",
      "         [ 0.1789,  0.1530, -0.2683,  ..., -0.3048,  0.2834,  0.5592],\n",
      "         [-0.3111, -0.2956,  0.3214,  ..., -0.5482,  0.3581,  0.1022],\n",
      "         [-0.1361,  0.0212,  0.3162,  ..., -0.0285, -0.2212, -0.0217]],\n",
      "\n",
      "        [[ 0.0441, -0.9075, -0.0890,  ..., -0.0695,  1.0023,  0.5164],\n",
      "         [ 0.3631,  0.4924, -0.2452,  ..., -0.8767,  0.1713,  0.5742],\n",
      "         [-0.0506,  0.5084, -0.4810,  ...,  0.1154, -0.2216, -0.1903],\n",
      "         ...,\n",
      "         [ 0.1638,  0.2109, -0.2829,  ..., -0.3104,  0.2772,  0.5600],\n",
      "         [-0.3486, -0.1904,  0.1451,  ..., -0.7098,  0.2884,  0.2398],\n",
      "         [-0.1039,  0.0458,  0.3049,  ...,  0.0259, -0.2700, -0.0140]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         ...,\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         ...,\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         ...,\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "se_user_history_QOE_vec torch.Size([128, 1, 200]) tensor([[[ 0.0217,  0.0201, -0.0524,  ...,  0.0574, -0.0610,  0.0545]],\n",
      "\n",
      "        [[-0.0556, -0.0170, -0.0313,  ...,  0.0086, -0.0783, -0.0203]],\n",
      "\n",
      "        [[-0.0445, -0.0240, -0.0663,  ...,  0.0484, -0.0540,  0.0108]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "1.Embedding:user_history_QOE_vec torch.Size([128, 6, 25, 200]) torch.Size([128, 6, 25])\n",
      "2.0.二、三维度互换 ）user_history_QOE_vec torch.Size([128, 25, 6, 200]) tensor([[[[ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 1.4612, -1.4967, -0.3702,  ...,  1.3610, -1.5603,  0.9828],\n",
      "          [ 1.4612, -1.4967, -0.3702,  ...,  1.3610, -1.5603,  0.9828],\n",
      "          [ 0.5032, -0.7672, -1.0597,  ...,  0.9691,  0.0162, -0.7119],\n",
      "          [ 0.5032, -0.7672, -1.0597,  ...,  0.9691,  0.0162, -0.7119]],\n",
      "\n",
      "         [[ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [-0.3367,  0.3052,  0.8247,  ...,  0.2973, -1.3058,  0.2116],\n",
      "          [-0.3367,  0.3052,  0.8247,  ...,  0.2973, -1.3058,  0.2116],\n",
      "          [-0.3367,  0.3052,  0.8247,  ...,  0.2973, -1.3058,  0.2116],\n",
      "          [-0.3367,  0.3052,  0.8247,  ...,  0.2973, -1.3058,  0.2116]],\n",
      "\n",
      "         [[-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-0.7922, -0.1229, -1.3140,  ...,  1.0712, -0.5125, -0.9749],\n",
      "          [-0.7922, -0.1229, -1.3140,  ...,  1.0712, -0.5125, -0.9749],\n",
      "          [-0.7922, -0.1229, -1.3140,  ...,  1.0712, -0.5125, -0.9749],\n",
      "          [-0.7922, -0.1229, -1.3140,  ...,  1.0712, -0.5125, -0.9749]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [-0.3654,  0.7750,  0.3210,  ...,  0.3357, -0.5663, -0.7493],\n",
      "          [-0.4479,  0.8113,  0.3553,  ...,  0.3832, -0.5361, -0.7809],\n",
      "          [ 0.8821,  0.2253, -0.1974,  ..., -0.3822, -1.0224, -0.2725],\n",
      "          [ 1.6196, -0.0998, -0.5040,  ..., -0.8066, -1.2920,  0.0094]],\n",
      "\n",
      "         [[-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [ 0.5556, -1.5558, -1.7116,  ..., -1.4596,  0.2310,  1.4813],\n",
      "          [ 0.3800, -1.3542, -1.5241,  ..., -1.2789,  0.1566,  1.3065],\n",
      "          [-2.5932,  2.0584,  1.6516,  ...,  1.7810, -1.1025, -1.6525],\n",
      "          [-1.0530,  0.2905,  0.0065,  ...,  0.1959, -0.4502, -0.1197]],\n",
      "\n",
      "         [[ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [-0.0063,  0.1844,  0.5276,  ..., -0.8135,  0.1437, -1.1383],\n",
      "          [-0.1573,  0.2262,  0.6491,  ..., -0.7926,  0.0175, -1.2880],\n",
      "          [ 2.5911, -0.5352, -1.5626,  ..., -1.1728,  2.3149,  1.4369],\n",
      "          [ 1.7711, -0.3080, -0.9027,  ..., -1.0594,  1.6295,  0.6240]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 1.4612, -1.4967, -0.3702,  ...,  1.3610, -1.5603,  0.9828],\n",
      "          [ 1.2635,  0.8284,  0.5645,  ...,  1.1880,  1.8596, -0.3941],\n",
      "          [ 1.2635,  0.8284,  0.5645,  ...,  1.1880,  1.8596, -0.3941]],\n",
      "\n",
      "         [[ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 0.7913,  0.0699,  1.0323,  ..., -1.5971, -0.0581,  0.0144],\n",
      "          [ 0.7913,  0.0699,  1.0323,  ..., -1.5971, -0.0581,  0.0144],\n",
      "          [ 0.7913,  0.0699,  1.0323,  ..., -1.5971, -0.0581,  0.0144]],\n",
      "\n",
      "         [[-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-0.9213, -0.2625, -1.4418,  ...,  1.1988, -0.3839, -1.0127],\n",
      "          [-0.9213, -0.2625, -1.4418,  ...,  1.1988, -0.3839, -1.0127],\n",
      "          [-0.9213, -0.2625, -1.4418,  ...,  1.1988, -0.3839, -1.0127]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.6505,  0.3273, -0.1012,  ..., -0.2489, -0.9377, -0.3610],\n",
      "          [-0.1039,  0.6598,  0.2124,  ...,  0.1853, -0.6618, -0.6494],\n",
      "          [ 0.1762,  0.5363,  0.0959,  ...,  0.0240, -0.7643, -0.5423]],\n",
      "\n",
      "         [[-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [ 0.6018, -1.6087, -1.7609,  ..., -1.5071,  0.2505,  1.5272],\n",
      "          [-0.2548, -0.6256, -0.8460,  ..., -0.6255, -0.1122,  0.6747],\n",
      "          [ 0.0944, -1.0264, -1.2190,  ..., -0.9850,  0.0357,  1.0222]],\n",
      "\n",
      "         [[ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [-0.4997,  0.3211,  0.9247,  ..., -0.7452, -0.2687, -1.6275],\n",
      "          [ 0.4461,  0.0590,  0.1635,  ..., -0.8761,  0.5219, -0.6898],\n",
      "          [ 0.4847,  0.0484,  0.1325,  ..., -0.8814,  0.5541, -0.6515]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2522,  1.1128,  1.2404,  ...,  1.4837,  1.6734, -0.8870],\n",
      "          [ 0.2522,  1.1128,  1.2404,  ...,  1.4837,  1.6734, -0.8870],\n",
      "          [ 1.0782,  1.4829, -1.2439,  ..., -0.3659, -0.7644, -0.5786],\n",
      "          [ 0.2522,  1.1128,  1.2404,  ...,  1.4837,  1.6734, -0.8870],\n",
      "          [ 0.5032, -0.7672, -1.0597,  ...,  0.9691,  0.0162, -0.7119],\n",
      "          [ 1.0782,  1.4829, -1.2439,  ..., -0.3659, -0.7644, -0.5786]],\n",
      "\n",
      "         [[-0.7878, -1.6971, -0.3976,  ...,  0.5454,  0.1161, -1.3212],\n",
      "          [-0.7878, -1.6971, -0.3976,  ...,  0.5454,  0.1161, -1.3212],\n",
      "          [-1.2109, -1.5493, -1.8495,  ..., -0.9096, -2.9943, -0.6836],\n",
      "          [-0.2840, -2.1006,  0.3642,  ..., -1.7143, -2.0170,  1.0669],\n",
      "          [ 0.0247,  0.0889,  0.7052,  ..., -1.3288, -1.1981,  0.7956],\n",
      "          [ 0.0247,  0.0889,  0.7052,  ..., -1.3288, -1.1981,  0.7956]],\n",
      "\n",
      "         [[ 0.2438,  0.9961, -0.2895,  ...,  0.0479, -1.5435, -0.6713],\n",
      "          [ 0.2438,  0.9961, -0.2895,  ...,  0.0479, -1.5435, -0.6713],\n",
      "          [ 0.2438,  0.9961, -0.2895,  ...,  0.0479, -1.5435, -0.6713],\n",
      "          [ 0.2438,  0.9961, -0.2895,  ...,  0.0479, -1.5435, -0.6713],\n",
      "          [ 0.2438,  0.9961, -0.2895,  ...,  0.0479, -1.5435, -0.6713],\n",
      "          [ 0.2438,  0.9961, -0.2895,  ...,  0.0479, -1.5435, -0.6713]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0667,  0.6434,  0.1969,  ...,  0.1638, -0.6754, -0.6352],\n",
      "          [ 0.0074,  0.6107,  0.1661,  ...,  0.1212, -0.7025, -0.6069],\n",
      "          [ 1.0428,  0.1544, -0.2642,  ..., -0.4747, -1.0811, -0.2111],\n",
      "          [ 0.0562,  0.5892,  0.1458,  ...,  0.0931, -0.7204, -0.5882],\n",
      "          [-0.0908,  0.6540,  0.2069,  ...,  0.1777, -0.6666, -0.6444],\n",
      "          [ 0.0240,  0.6034,  0.1592,  ...,  0.1116, -0.7086, -0.6005]],\n",
      "\n",
      "         [[ 0.1987, -1.1461, -1.3304,  ..., -1.0923,  0.0798,  1.1260],\n",
      "          [-0.0123, -0.9040, -1.1051,  ..., -0.8752, -0.0095,  0.9161],\n",
      "          [-1.5146,  0.8203,  0.4995,  ...,  0.6709, -0.6457, -0.5790],\n",
      "          [ 0.4511, -1.4358, -1.6000,  ..., -1.3521,  0.1867,  1.3773],\n",
      "          [-0.6534, -0.1681, -0.4203,  ..., -0.2154, -0.2810,  0.2780],\n",
      "          [-0.8985,  0.1132, -0.1585,  ...,  0.0369, -0.3848,  0.0341]],\n",
      "\n",
      "         [[ 0.4200,  0.0663,  0.1846,  ..., -0.8725,  0.5000, -0.7157],\n",
      "          [ 0.0541,  0.1676,  0.4790,  ..., -0.8219,  0.1942, -1.0784],\n",
      "          [ 2.1920, -0.4246, -1.2414,  ..., -1.1176,  1.9813,  1.0412],\n",
      "          [-0.0891,  0.2073,  0.5943,  ..., -0.8020,  0.0744, -1.2205],\n",
      "          [ 0.7056, -0.0129, -0.0453,  ..., -0.9120,  0.7388, -0.4324],\n",
      "          [ 1.0381, -0.1049, -0.3128,  ..., -0.9580,  1.0167, -0.1029]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.2522,  1.1128,  1.2404,  ...,  1.4837,  1.6734, -0.8870],\n",
      "          [ 1.0782,  1.4829, -1.2439,  ..., -0.3659, -0.7644, -0.5786]],\n",
      "\n",
      "         [[ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 0.3668,  0.1126,  0.8529,  ...,  0.1669,  0.2669,  0.5689],\n",
      "          [ 0.3668,  0.1126,  0.8529,  ...,  0.1669,  0.2669,  0.5689]],\n",
      "\n",
      "         [[-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-0.1907,  0.5268, -0.7192,  ...,  0.4771, -1.1112, -0.7986],\n",
      "          [-0.1907,  0.5268, -0.7192,  ...,  0.4771, -1.1112, -0.7986]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [-0.3761,  0.7797,  0.3255,  ...,  0.3419, -0.5623, -0.7534],\n",
      "          [ 0.4409,  0.4197, -0.0141,  ..., -0.1283, -0.8611, -0.4411]],\n",
      "\n",
      "         [[-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-0.2204, -0.6651, -0.8827,  ..., -0.6610, -0.0977,  0.7089],\n",
      "          [-0.0433, -0.8684, -1.0719,  ..., -0.8432, -0.0227,  0.8852]],\n",
      "\n",
      "         [[ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 0.7204, -0.0170, -0.0572,  ..., -0.9140,  0.7512, -0.4178],\n",
      "          [ 0.3142,  0.0956,  0.2697,  ..., -0.8578,  0.4116, -0.8205]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 1.2635,  0.8284,  0.5645,  ...,  1.1880,  1.8596, -0.3941]],\n",
      "\n",
      "         [[ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [-0.1563,  1.2849, -0.9864,  ...,  0.3614, -1.1204,  0.0588]],\n",
      "\n",
      "         [[-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-0.6100,  0.0739, -1.1339,  ...,  0.8913, -0.6938, -0.9215]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.0824,  0.5776,  0.1349,  ...,  0.0780, -0.7300, -0.5782]],\n",
      "\n",
      "         [[-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [ 0.4224, -1.4029, -1.5694,  ..., -1.3226,  0.1746,  1.3487]],\n",
      "\n",
      "         [[ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [-0.4342,  0.3029,  0.8720,  ..., -0.7543, -0.2140, -1.5626]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "          [ 0.2522,  1.1128,  1.2404,  ...,  1.4837,  1.6734, -0.8870]],\n",
      "\n",
      "         [[ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "          [-0.0696, -0.1041, -0.9313,  ..., -0.3811, -0.3165, -1.0478]],\n",
      "\n",
      "         [[-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "          [-0.4338,  0.2642, -0.9596,  ...,  0.7172, -0.8691, -0.8699]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "          [-0.7770,  0.9564,  0.4921,  ...,  0.5726, -0.4157, -0.9067]],\n",
      "\n",
      "         [[-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "          [ 0.1374, -1.0758, -1.2649,  ..., -1.0292,  0.0539,  1.0650]],\n",
      "\n",
      "         [[ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "          [ 0.0941,  0.1566,  0.4468,  ..., -0.8274,  0.2276, -1.0387]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "2.样本数*特征数,历史数，200）user_history_QOE_vec torch.Size([3200, 6, 200]) tensor([[[ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "         [ 0.9679,  0.7316, -1.3280,  ...,  1.4222, -1.4076,  0.1148],\n",
      "         [ 1.4612, -1.4967, -0.3702,  ...,  1.3610, -1.5603,  0.9828],\n",
      "         [ 1.4612, -1.4967, -0.3702,  ...,  1.3610, -1.5603,  0.9828],\n",
      "         [ 0.5032, -0.7672, -1.0597,  ...,  0.9691,  0.0162, -0.7119],\n",
      "         [ 0.5032, -0.7672, -1.0597,  ...,  0.9691,  0.0162, -0.7119]],\n",
      "\n",
      "        [[ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "         [ 1.2949,  0.6702,  2.2727,  ...,  1.0782,  1.6882,  0.8222],\n",
      "         [-0.3367,  0.3052,  0.8247,  ...,  0.2973, -1.3058,  0.2116],\n",
      "         [-0.3367,  0.3052,  0.8247,  ...,  0.2973, -1.3058,  0.2116],\n",
      "         [-0.3367,  0.3052,  0.8247,  ...,  0.2973, -1.3058,  0.2116],\n",
      "         [-0.3367,  0.3052,  0.8247,  ...,  0.2973, -1.3058,  0.2116]],\n",
      "\n",
      "        [[-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "         [-1.2647, -0.6334, -1.7814,  ...,  1.5380, -0.0422, -1.1133],\n",
      "         [-0.7922, -0.1229, -1.3140,  ...,  1.0712, -0.5125, -0.9749],\n",
      "         [-0.7922, -0.1229, -1.3140,  ...,  1.0712, -0.5125, -0.9749],\n",
      "         [-0.7922, -0.1229, -1.3140,  ...,  1.0712, -0.5125, -0.9749],\n",
      "         [-0.7922, -0.1229, -1.3140,  ...,  1.0712, -0.5125, -0.9749]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "         [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "         [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "         [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "         [ 0.7759,  0.2721, -0.1533,  ..., -0.3211, -0.9835, -0.3131],\n",
      "         [-0.7770,  0.9564,  0.4921,  ...,  0.5726, -0.4157, -0.9067]],\n",
      "\n",
      "        [[-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "         [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "         [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "         [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "         [-1.0547,  0.2925,  0.0083,  ...,  0.1976, -0.4510, -0.1213],\n",
      "         [ 0.1374, -1.0758, -1.2649,  ..., -1.0292,  0.0539,  1.0650]],\n",
      "\n",
      "        [[ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "         [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "         [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "         [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "         [ 1.6200, -0.2662, -0.7811,  ..., -1.0385,  1.5031,  0.4741],\n",
      "         [ 0.0941,  0.1566,  0.4468,  ..., -0.8274,  0.2276, -1.0387]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "pay_QOE_mask tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "3.(样本数*特征数，200）multi_user_history_QOE_vec torch.Size([3200, 1, 200]) tensor([[[-0.0837,  0.1241, -0.4356,  ..., -0.0560,  0.4475,  0.3410]],\n",
      "\n",
      "        [[ 0.7630,  0.2334,  0.1720,  ..., -0.1114,  0.3411,  0.0042]],\n",
      "\n",
      "        [[ 0.2040, -0.0373,  0.0683,  ..., -0.6871,  0.0791, -0.2907]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5135,  0.0451, -0.0301,  ..., -0.3431, -0.6856,  0.0413]],\n",
      "\n",
      "        [[ 0.8765,  0.0693, -0.4638,  ..., -0.3267, -0.2294,  0.3564]],\n",
      "\n",
      "        [[ 0.3014,  0.0794,  0.0438,  ...,  0.0272,  0.3864, -0.9217]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "4.(样本数,特征数，200）multi_user_history_QOE_vec torch.Size([128, 25, 200]) tensor([[[-8.3676e-02,  1.2412e-01, -4.3563e-01,  ..., -5.5973e-02,\n",
      "           4.4753e-01,  3.4105e-01],\n",
      "         [ 7.6303e-01,  2.3337e-01,  1.7201e-01,  ..., -1.1137e-01,\n",
      "           3.4110e-01,  4.1600e-03],\n",
      "         [ 2.0404e-01, -3.7346e-02,  6.8254e-02,  ..., -6.8712e-01,\n",
      "           7.9084e-02, -2.9068e-01],\n",
      "         ...,\n",
      "         [ 4.7272e-01, -2.7274e-01,  1.2157e-01,  ...,  3.6759e-01,\n",
      "          -2.1708e-01,  2.7863e-01],\n",
      "         [ 5.0987e-01, -8.4007e-02, -2.0264e-01,  ..., -1.7391e-01,\n",
      "          -5.3025e-01,  2.4011e-01],\n",
      "         [ 6.5519e-02, -2.3559e-01,  1.1665e-01,  ...,  1.4448e-01,\n",
      "           5.4803e-01, -5.1125e-01]],\n",
      "\n",
      "        [[ 6.9710e-01,  6.2010e-01, -7.6237e-02,  ...,  6.9927e-02,\n",
      "           7.4058e-02,  3.8323e-01],\n",
      "         [ 5.1356e-01,  3.1777e-01, -2.7388e-01,  ..., -3.7781e-01,\n",
      "           1.4385e-01, -3.6324e-01],\n",
      "         [ 2.4320e-01, -8.2851e-02,  4.9825e-02,  ..., -7.4435e-01,\n",
      "           6.4096e-02, -2.5231e-01],\n",
      "         ...,\n",
      "         [ 2.9785e-01, -2.1639e-01,  9.4686e-02,  ...,  2.4533e-01,\n",
      "          -2.9768e-01,  2.3780e-01],\n",
      "         [ 8.9473e-01,  7.6928e-02, -4.7684e-01,  ..., -3.2824e-01,\n",
      "          -2.2644e-01,  3.5756e-01],\n",
      "         [ 3.0135e-01,  7.9298e-02,  4.3817e-02,  ...,  3.3675e-02,\n",
      "           3.9534e-01, -8.9886e-01]],\n",
      "\n",
      "        [[-1.2871e-01,  5.3037e-01,  2.3120e-01,  ...,  8.0349e-02,\n",
      "          -1.1978e-01, -5.2809e-01],\n",
      "         [-1.4615e-01,  2.5394e-01, -9.5390e-02,  ..., -6.8695e-02,\n",
      "          -1.4344e-02, -4.5712e-01],\n",
      "         [-1.1004e-01,  3.2756e-01,  2.1603e-01,  ..., -2.2817e-01,\n",
      "           1.9928e-01, -5.9834e-01],\n",
      "         ...,\n",
      "         [ 2.4234e-01, -1.9850e-01,  8.6152e-02,  ...,  2.0181e-01,\n",
      "          -3.2637e-01,  2.2326e-01],\n",
      "         [ 5.9332e-01, -4.9111e-02, -2.6209e-01,  ..., -2.1423e-01,\n",
      "          -4.5088e-01,  2.7080e-01],\n",
      "         [ 1.0851e-01, -1.7819e-01,  1.0337e-01,  ...,  1.1210e-01,\n",
      "           5.0340e-01, -6.2453e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1527e-01,  4.3372e-01,  4.5205e-01,  ...,  1.6307e-01,\n",
      "          -2.1370e-01, -5.9437e-01],\n",
      "         [-4.1387e-01, -9.1252e-01,  5.2750e-01,  ...,  5.4561e-01,\n",
      "          -7.4140e-01, -2.7901e-01],\n",
      "         [ 2.1676e-02,  1.7453e-01,  1.5406e-01,  ..., -4.2064e-01,\n",
      "           1.4887e-01, -4.6931e-01],\n",
      "         ...,\n",
      "         [ 1.3587e-01, -1.6419e-01,  6.9782e-02,  ...,  1.2724e-01,\n",
      "          -3.7553e-01,  1.9836e-01],\n",
      "         [ 7.1365e-01,  1.2082e-03, -3.4783e-01,  ..., -2.7235e-01,\n",
      "          -3.3646e-01,  3.1503e-01],\n",
      "         [ 1.4557e-01, -1.2871e-01,  9.1929e-02,  ...,  8.2723e-02,\n",
      "           4.6293e-01, -7.2729e-01]],\n",
      "\n",
      "        [[ 1.2227e+00,  6.3888e-01,  1.7774e-01,  ...,  6.3647e-02,\n",
      "           1.3051e-01,  4.1755e-01],\n",
      "         [-5.8066e-01,  7.6280e-01, -5.5638e-01,  ..., -1.4149e-01,\n",
      "          -3.6302e-01,  1.3185e-01],\n",
      "         [ 1.4880e-01,  2.6828e-02,  9.4243e-02,  ..., -6.0641e-01,\n",
      "           1.0022e-01, -3.4478e-01],\n",
      "         ...,\n",
      "         [ 1.6747e-01, -1.7437e-01,  7.4641e-02,  ...,  1.5148e-01,\n",
      "          -3.5955e-01,  2.0645e-01],\n",
      "         [ 1.0495e+00,  1.4167e-01, -5.8714e-01,  ..., -3.8434e-01,\n",
      "          -1.1600e-01,  4.0026e-01],\n",
      "         [ 5.0105e-01,  3.4594e-01, -1.7859e-02,  ..., -4.2591e-02,\n",
      "           2.9025e-01, -1.1656e+00]],\n",
      "\n",
      "        [[-3.7343e-02,  1.1700e+00,  2.2559e-01,  ..., -1.6794e-01,\n",
      "          -8.0745e-01, -1.3633e+00],\n",
      "         [ 9.3969e-01, -8.6017e-01,  2.0575e-01,  ..., -1.3831e-01,\n",
      "           2.9095e-01, -6.2354e-02],\n",
      "         [ 9.5395e-02,  8.8881e-02,  1.1937e-01,  ..., -5.2836e-01,\n",
      "           1.2066e-01, -3.9710e-01],\n",
      "         ...,\n",
      "         [-5.1354e-01,  4.5093e-02, -3.0061e-02,  ..., -3.4313e-01,\n",
      "          -6.8564e-01,  4.1265e-02],\n",
      "         [ 8.7646e-01,  6.9291e-02, -4.6382e-01,  ..., -3.2671e-01,\n",
      "          -2.2944e-01,  3.5640e-01],\n",
      "         [ 3.0144e-01,  7.9416e-02,  4.3789e-02,  ...,  2.7153e-02,\n",
      "           3.8635e-01, -9.2168e-01]]], grad_fn=<ViewBackward0>)\n",
      "multi_user_history_CHONGHE_vec torch.Size([128, 27, 200]) tensor([[[ 0.7240, -0.3321, -0.0651,  ..., -0.2011,  0.1652,  0.3163],\n",
      "         [ 0.0458, -0.2435, -0.4625,  ..., -0.7283, -0.5847,  0.8859],\n",
      "         [ 1.3498,  0.3556,  0.7826,  ...,  0.2178, -0.3964, -0.3938],\n",
      "         ...,\n",
      "         [-0.0537, -0.1982, -0.1268,  ..., -0.0944,  0.6073,  0.2822],\n",
      "         [-0.2231, -0.3021, -0.2305,  ...,  0.2949,  0.3387,  0.0666],\n",
      "         [-0.3966,  0.1636, -0.0047,  ..., -0.5941, -0.5502, -0.2011]],\n",
      "\n",
      "        [[-0.4081, -0.0671, -0.7094,  ..., -0.9917, -0.5247, -0.8766],\n",
      "         [ 0.0458, -0.2435, -0.4625,  ..., -0.7283, -0.5847,  0.8859],\n",
      "         [-0.3787, -0.1697, -0.2664,  ..., -1.0739, -0.4645, -0.8978],\n",
      "         ...,\n",
      "         [-0.2708, -0.1307, -0.0665,  ..., -0.1063,  0.5004,  0.2723],\n",
      "         [-0.1566, -0.3448, -0.2623,  ...,  0.2988,  0.3517,  0.0509],\n",
      "         [-0.4672,  0.5111,  0.1370,  ..., -0.1001, -0.2168, -0.0953]],\n",
      "\n",
      "        [[-0.4081, -0.0671, -0.7094,  ..., -0.9917, -0.5247, -0.8766],\n",
      "         [ 0.4077, -0.7128, -0.2152,  ...,  0.1492, -0.1951, -0.1752],\n",
      "         [-0.3416, -0.8364,  0.0390,  ...,  0.0645, -1.4451,  0.6299],\n",
      "         ...,\n",
      "         [ 0.2939, -0.3062, -0.2234,  ..., -0.0754,  0.7784,  0.2981],\n",
      "         [-0.1516, -0.3480, -0.2647,  ...,  0.3008,  0.3581,  0.0432],\n",
      "         [-0.3692,  0.0289, -0.0596,  ..., -0.5719, -0.5352, -0.1964]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7548, -0.0094, -0.7532,  ..., -0.0671,  0.2722,  0.1418],\n",
      "         [ 0.4077, -0.7128, -0.2152,  ...,  0.1492, -0.1951, -0.1752],\n",
      "         [-0.3416, -0.8364,  0.0390,  ...,  0.0645, -1.4451,  0.6299],\n",
      "         ...,\n",
      "         [-0.2246, -0.1451, -0.0793,  ..., -0.1038,  0.5230,  0.2744],\n",
      "         [-0.5013, -0.1237, -0.0977,  ...,  0.2660,  0.2436,  0.1808],\n",
      "         [-0.2884, -0.3686, -0.2217,  ..., -0.9049, -0.7599, -0.2677]],\n",
      "\n",
      "        [[ 1.0811, -0.2221,  0.2704,  ...,  0.3471,  0.9373,  0.2696],\n",
      "         [ 0.4077, -0.7128, -0.2152,  ...,  0.1492, -0.1951, -0.1752],\n",
      "         [-0.3416, -0.8364,  0.0390,  ...,  0.0645, -1.4451,  0.6299],\n",
      "         ...,\n",
      "         [ 0.2626, -0.2964, -0.2148,  ..., -0.0771,  0.7631,  0.2967],\n",
      "         [ 0.1135, -0.5180, -0.3913,  ...,  0.3177,  0.4139, -0.0238],\n",
      "         [-0.2585, -0.5155, -0.2816,  ..., -1.0410, -0.8518, -0.2969]],\n",
      "\n",
      "        [[ 0.1455,  0.2302,  0.2186,  ..., -0.7883, -0.2379,  0.5241],\n",
      "         [ 0.0458, -0.2435, -0.4625,  ..., -0.7283, -0.5847,  0.8859],\n",
      "         [-0.3416, -0.8364,  0.0390,  ...,  0.0645, -1.4451,  0.6299],\n",
      "         ...,\n",
      "         [ 0.0504, -0.2305, -0.1558,  ..., -0.0887,  0.6586,  0.2870],\n",
      "         [-0.1689, -0.3369, -0.2564,  ...,  0.2939,  0.3356,  0.0702],\n",
      "         [-0.3478, -0.0766, -0.1026,  ..., -0.6236, -0.5701, -0.2074]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "multi_user_history_FUFEI_vec torch.Size([128, 31, 200]) tensor([[[-0.9288,  1.1725, -0.1280,  ..., -0.2358,  0.0197,  0.6168],\n",
      "         [ 0.8077,  0.7066, -0.6292,  ..., -0.3436,  0.1773,  1.1221],\n",
      "         [ 0.2185,  0.0233, -0.1209,  ...,  0.5323, -0.0515, -0.2750],\n",
      "         ...,\n",
      "         [ 0.2929, -0.2357,  0.0427,  ..., -0.8463, -0.4368,  0.0827],\n",
      "         [-0.0434,  0.1773,  0.0808,  ...,  0.1202, -0.2303,  0.0574],\n",
      "         [-0.0535,  0.1249, -0.4457,  ..., -0.5891, -0.2449, -0.4673]],\n",
      "\n",
      "        [[-0.9288,  1.1725, -0.1280,  ..., -0.2358,  0.0197,  0.6168],\n",
      "         [ 0.8077,  0.7066, -0.6292,  ..., -0.3436,  0.1773,  1.1221],\n",
      "         [-0.4069,  0.3437,  0.3147,  ..., -0.4997,  0.7517,  0.0461],\n",
      "         ...,\n",
      "         [ 0.3933, -0.3105,  0.0165,  ..., -0.8654, -0.5053,  0.1000],\n",
      "         [-0.0356,  0.1014,  0.3706,  ...,  0.1719, -0.2393, -0.0213],\n",
      "         [-0.0401,  0.1683, -0.4397,  ..., -0.5080, -0.2467, -0.5079]],\n",
      "\n",
      "        [[ 0.4691, -1.5189, -0.6086,  ..., -0.3895, -0.1292, -0.6556],\n",
      "         [ 0.5710, -0.3061, -1.2244,  ..., -0.7978, -0.1415, -0.1226],\n",
      "         [ 0.0300, -0.3950, -0.2860,  ...,  0.2016,  0.0993, -0.0223],\n",
      "         ...,\n",
      "         [ 0.2436, -0.1990,  0.0556,  ..., -0.8241, -0.3575,  0.0627],\n",
      "         [-0.0339,  0.0844,  0.4353,  ...,  0.1808, -0.2409, -0.0349],\n",
      "         [-0.0245,  0.2192, -0.4327,  ..., -0.4346, -0.2484, -0.5447]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4691, -1.5189, -0.6086,  ..., -0.3895, -0.1292, -0.6556],\n",
      "         [-1.3765,  0.3905, -0.2136,  ..., -0.7845,  0.3190, -0.1952],\n",
      "         [ 1.1290,  0.3954, -0.1281,  ..., -0.0495,  0.4184, -0.1350],\n",
      "         ...,\n",
      "         [ 0.2460, -0.2008,  0.0550,  ..., -0.8272, -0.3684,  0.0655],\n",
      "         [-0.0270,  0.0172,  0.6920,  ...,  0.2264, -0.2489, -0.1044],\n",
      "         [-0.0561,  0.1163, -0.4469,  ..., -0.6034, -0.2445, -0.4601]],\n",
      "\n",
      "        [[ 0.4691, -1.5189, -0.6086,  ..., -0.3895, -0.1292, -0.6556],\n",
      "         [-0.1505, -0.1415,  0.8606,  ..., -0.1922, -1.0169,  0.8229],\n",
      "         [ 0.3298, -0.3173, -0.6952,  ..., -0.3737,  0.1573, -0.5860],\n",
      "         ...,\n",
      "         [ 0.2915, -0.2347,  0.0431,  ..., -0.8370, -0.4035,  0.0743],\n",
      "         [-0.0514,  0.2560, -0.2195,  ...,  0.0664, -0.2209,  0.1394],\n",
      "         [ 0.0219,  0.3703, -0.4119,  ..., -0.1259, -0.2554, -0.6994]],\n",
      "\n",
      "        [[-0.9288,  1.1725, -0.1280,  ..., -0.2358,  0.0197,  0.6168],\n",
      "         [ 0.1525,  0.1960,  0.3905,  ..., -0.5760,  0.1266, -0.1936],\n",
      "         [-0.0846, -0.2715, -0.0328,  ...,  0.3475, -0.6832,  0.1093],\n",
      "         ...,\n",
      "         [ 0.1391, -0.1213,  0.0829,  ..., -0.8025, -0.2802,  0.0433],\n",
      "         [-0.0366,  0.1112,  0.3331,  ...,  0.1634, -0.2379, -0.0085],\n",
      "         [-0.0644,  0.0893, -0.4506,  ..., -0.6541, -0.2434, -0.4347]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "se_user_history_QOE_vec torch.Size([128, 1, 200]) tensor([[[ 0.0760, -0.0279,  0.0297,  ..., -0.0078,  0.0562, -0.0026]],\n",
      "\n",
      "        [[ 0.0912, -0.0016, -0.0117,  ..., -0.0216,  0.0529,  0.0068]],\n",
      "\n",
      "        [[ 0.0672,  0.0173,  0.0079,  ..., -0.0044,  0.0218, -0.0243]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0878, -0.0192,  0.0219,  ...,  0.0101,  0.0444, -0.0051]],\n",
      "\n",
      "        [[ 0.0907,  0.0142, -0.0277,  ..., -0.0002,  0.0275,  0.0396]],\n",
      "\n",
      "        [[ 0.0830,  0.0231, -0.0324,  ..., -0.0631,  0.0016, -0.0667]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "se_target_QOE_vec torch.Size([128, 1, 200]) tensor([[[ 0.0932, -0.0080, -0.0797,  ...,  0.0157,  0.0454, -0.0154]],\n",
      "\n",
      "        [[ 0.0440,  0.0761, -0.0647,  ..., -0.1045,  0.0733,  0.1008]],\n",
      "\n",
      "        [[ 0.0918,  0.1245, -0.0699,  ..., -0.0411,  0.0606,  0.0742]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0243,  0.1129, -0.1051,  ..., -0.0680,  0.0264,  0.0804]],\n",
      "\n",
      "        [[-0.0382,  0.1005, -0.0900,  ..., -0.0538, -0.0307,  0.0712]],\n",
      "\n",
      "        [[-0.0434,  0.0171, -0.0276,  ..., -0.1157,  0.0631,  0.1644]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "se_user_history_pay_QOE_vec size= torch.Size([128, 1, 200])\n",
      "se_target_QOE_vec size= torch.Size([128, 1, 200])\n",
      "target_history_pay_attention_vec size= torch.Size([128, 3, 200])\n",
      "target_history_pay_attention_vec tensor([[0.0000, 0.0322, 0.0000,  ..., 0.0063, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0309, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0180, 0.0000,  ..., 0.0126, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
      "        [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
      "        [   nan,    nan,    nan,  ...,    nan,    nan,    nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "target_history_not_pay_attention_vec tensor([[0.0000, 0.0116, 0.0000,  ..., 0.0146, 0.0113, 0.0569],\n",
      "        [0.0000, 0.0152, 0.0046,  ..., 0.0066, 0.0000, 0.0651],\n",
      "        [0.0000, 0.0030, 0.0071,  ..., 0.0134, 0.0000, 0.0580],\n",
      "        ...,\n",
      "        [0.0000, 0.0176, 0.0159,  ..., 0.0000, 0.0000, 0.0633],\n",
      "        [0.0000, 0.0055, 0.0197,  ..., 0.0129, 0.0000, 0.0544],\n",
      "        [0.0000, 0.0050, 0.0253,  ..., 0.0013, 0.0000, 0.0475]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[286], line 243\u001b[0m\n\u001b[1;32m    240\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m p: p\u001b[38;5;241m.\u001b[39mrequires_grad, model\u001b[38;5;241m.\u001b[39mparameters()), lr\u001b[38;5;241m=\u001b[39mlr, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# 训练\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m \u001b[43mmodel_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlossfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m模型训练完成\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m||--------训练结束时间：\u001b[39m\u001b[38;5;124m'\u001b[39m,datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow(),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[284], line 34\u001b[0m, in \u001b[0;36mmodel_training\u001b[0;34m(model, train_loader, val_loader, lossfunction, optimizer, EPOCH, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     31\u001b[0m sigmoid_pay_score, softmax_pay_score, sigmoid_not_pay_score,\\\n\u001b[1;32m     32\u001b[0m softmax_not_pay_score, pay_HistoryDimScaling_Weight_Result,\\\n\u001b[1;32m     33\u001b[0m not_pay_HistoryDimScaling_Weight_Result, TargetDimScaling_Weight_Result, \\\n\u001b[0;32m---> 34\u001b[0m TargetHistory_Weight_Result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_feature_tensor_pay_QOE_discrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_pay_CHONGHE_discrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_pay_FUFEI_discrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbatch_feature_tensor_pay_QOE_continue\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_pay_CHONGHE_continue\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_pay_FUFEI_continue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbatch_feature_tensor_not_pay_QOE_discrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_not_pay_CHONGHE_discrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_not_pay_FUFEI_discrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbatch_feature_tensor_not_pay_QOE_continue\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_not_pay_CHONGHE_continue\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_not_pay_FUFEI_continue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbatch_feature_tensor_target_QOE_discrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_target_CHONGHE_discrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_target_FUFEI_discrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbatch_feature_tensor_target_QOE_continue\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_target_CHONGHE_continue\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_target_FUFEI_continue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbatch_feature_tensor_pay_QOE_discrete_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_pay_CHONGHE_discrete_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_pay_FUFEI_discrete_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbatch_feature_tensor_pay_QOE_continue_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_pay_CHONGHE_continue_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_pay_FUFEI_continue_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbatch_feature_tensor_not_pay_QOE_discrete_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_not_pay_CHONGHE_discrete_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_not_pay_FUFEI_discrete_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbatch_feature_tensor_not_pay_QOE_continue_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_not_pay_CHONGHE_continue_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_feature_tensor_not_pay_FUFEI_continue_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mtrain_label_tensor\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# print('HistoryDimScaling_Weight_Result, TargetDimScaling_Weight_Result, target_history_pay_attention_weight',\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#      HistoryDimScaling_Weight_Result['mutli_QOE_weight'].shape, TargetDimScaling_Weight_Result['se_QOE_weight'].shape, target_history_pay_attention_weight.shape)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# sigmoid\u001b[39;00m\n\u001b[1;32m     49\u001b[0m sigmoid_score \u001b[38;5;241m=\u001b[39m sigmoid_score[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (样本数，1)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/maoer_DL/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/maoer_DL/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[282], line 105\u001b[0m, in \u001b[0;36mMatchingModel.forward\u001b[0;34m(self, batch_feature_tensor_pay_QOE_discrete, batch_feature_tensor_pay_CHONGHE_discrete, batch_feature_tensor_pay_FUFEI_discrete, batch_feature_tensor_pay_QOE_continue, batch_feature_tensor_pay_CHONGHE_continue, batch_feature_tensor_pay_FUFEI_continue, batch_feature_tensor_not_pay_QOE_discrete, batch_feature_tensor_not_pay_CHONGHE_discrete, batch_feature_tensor_not_pay_FUFEI_discrete, batch_feature_tensor_not_pay_QOE_continue, batch_feature_tensor_not_pay_CHONGHE_continue, batch_feature_tensor_not_pay_FUFEI_continue, batch_feature_tensor_target_QOE_discrete, batch_feature_tensor_target_CHONGHE_discrete, batch_feature_tensor_target_FUFEI_discrete, batch_feature_tensor_target_QOE_continue, batch_feature_tensor_target_CHONGHE_continue, batch_feature_tensor_target_FUFEI_continue, batch_feature_tensor_pay_QOE_discrete_mask, batch_feature_tensor_pay_CHONGHE_discrete_mask, batch_feature_tensor_pay_FUFEI_discrete_mask, batch_feature_tensor_pay_QOE_continue_mask, batch_feature_tensor_pay_CHONGHE_continue_mask, batch_feature_tensor_pay_FUFEI_continue_mask, batch_feature_tensor_not_pay_QOE_discrete_mask, batch_feature_tensor_not_pay_CHONGHE_discrete_mask, batch_feature_tensor_not_pay_FUFEI_discrete_mask, batch_feature_tensor_not_pay_QOE_continue_mask, batch_feature_tensor_not_pay_CHONGHE_continue_mask, batch_feature_tensor_not_pay_FUFEI_continue_mask, label_tensor)\u001b[0m\n\u001b[1;32m    103\u001b[0m pay_cos_sim \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcosine_similarity(target_history_pay_attention_vec, target_vec)\n\u001b[1;32m    104\u001b[0m not_pay_cos_sim \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcosine_similarity(target_history_not_pay_attention_vec, target_vec)\n\u001b[0;32m--> 105\u001b[0m sim_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpay_cos_sim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnot_pay_cos_sim\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# 两个对应值最大的那个，但里面有nan，就给nan\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# print('pay_cos_sim',pay_cos_sim)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# print('not_pay_cos_sim',not_pay_cos_sim)\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msim_score\u001b[39m\u001b[38;5;124m'\u001b[39m,sim_score)\n",
      "File \u001b[0;32m~/anaconda3/envs/maoer_DL/lib/python3.9/site-packages/numpy/core/shape_base.py:443\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_stack_dispatcher)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    374\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    Join a sequence of arrays along a new axis.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [asanyarray(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/maoer_DL/lib/python3.9/site-packages/numpy/core/shape_base.py:443\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_stack_dispatcher)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    374\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    Join a sequence of arrays along a new axis.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/maoer_DL/lib/python3.9/site-packages/torch/_tensor.py:1062\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1062\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# 模型运行\n",
    "\n",
    "# 创建一个空的DataFrame来存储结果\n",
    "test_auc_df = pd.DataFrame(columns=['时间窗','训练验证测试比例','最大历史长度','特征embedding维度','学习率','batchSize','实验数', '测试集总损失', 'AUC'])\n",
    "for i in range(5):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    print(f\"i=:{i+1}\")\n",
    "    n = i\n",
    "    # 数据集 train、val、test划分及总数据hash表(以user_id为key的存储对应对应行的hash表)及不同类特征数存储的字典\n",
    "    train_list, val_list, test_list, data_hash, feature_category_num_dict = data_input(data_time_windows, path, dataset_spilt_path, train_ratio, val_ratio, test_ratio, total_continue_feature)\n",
    "    # 获取训练、验证、测试集对应的数据形成的向量hash存储及label\n",
    "    train_data_tensor_hash, train_label, train_data_tensor_hash_history_mask = get_feature_to_matrix(train_list, data_hash, feature_column_dict)\n",
    "    val_data_tensor_hash, val_label, val_data_tensor_hash_history_mask = get_feature_to_matrix(val_list, data_hash, feature_column_dict)\n",
    "    test_data_tensor_hash, test_label, test_data_tensor_hash_history_mask = get_feature_to_matrix(test_list, data_hash, feature_column_dict)\n",
    "    # 输出查看结果\n",
    "    # for key1 in train_data_tensor_hash.keys():\n",
    "    #     dimensions1 = train_data_tensor_hash[key1]['pay_QOE_continue'].size()\n",
    "    #     dimensions2 = train_data_tensor_hash[key1]['pay_QOE_discrete'].size()\n",
    "    #     dimensions3 = train_data_tensor_hash[key1]['pay_CHONGHE_continue'].size()\n",
    "    #     dimensions4 = train_data_tensor_hash[key1]['target_QOE_continue'].size()\n",
    "    #     dimensions5 = train_data_tensor_hash[key1]['target_QOE_discrete'].size()\n",
    "    #     dimensions6 = train_data_tensor_hash[key1]['target_CHONGHE_continue'].size()\n",
    "    #     print(\"val_data_tensor_hash size=\", dimensions1,dimensions2,dimensions3,dimensions4,dimensions5,dimensions6)\n",
    "\n",
    "    # 生成batch再添加维度对齐张量（三个维度）这里张量输出的全是三维 (batch_size, 1 or max_history_len, feature_num)\n",
    "    train_batch_feature_tensor_dict = generate_user_feature_alignment_tensor(train_list,train_data_tensor_hash)\n",
    "    val_batch_feature_tensor_dict = generate_user_feature_alignment_tensor(val_list,val_data_tensor_hash)\n",
    "    test_batch_feature_tensor_dict = generate_user_feature_alignment_tensor(test_list,test_data_tensor_hash)\n",
    "    train_label_tensor = torch.tensor(train_label)\n",
    "    val_label_tensor = torch.tensor(val_label)\n",
    "    test_label_tensor = torch.tensor(test_label)\n",
    "    train_label_tensor = train_label_tensor.unsqueeze(-1)\n",
    "    val_label_tensor = val_label_tensor.unsqueeze(-1)\n",
    "    test_label_tensor = test_label_tensor.unsqueeze(-1)  # 在最后新增一个维度，因为TensorDataset要第一维大小相同 label变为(batch,1)\n",
    "    # mask矩阵的字典\n",
    "    train_batch_feature_tensor_history_mask_dict = generate_user_feature_alignment_tensor(train_list,train_data_tensor_hash_history_mask, is_mask=True)\n",
    "    val_batch_feature_tensor_history_mask_dict = generate_user_feature_alignment_tensor(val_list,val_data_tensor_hash_history_mask, is_mask=True)\n",
    "    test_batch_feature_tensor_history_mask_dict = generate_user_feature_alignment_tensor(test_list,test_data_tensor_hash_history_mask, is_mask=True)\n",
    "    print('张量生成完成')\n",
    "    \n",
    "    # # TensorDataset输入得是张量，因此由字典转为张量\n",
    "    train_batch_feature_tensor_pay_QOE_discrete = train_batch_feature_tensor_dict['pay_QOE_discrete']\n",
    "    train_batch_feature_tensor_pay_CHONGHE_discrete = train_batch_feature_tensor_dict['pay_CHONGHE_discrete']\n",
    "    train_batch_feature_tensor_pay_FUFEI_discrete = train_batch_feature_tensor_dict['pay_FUFEI_discrete']\n",
    "    train_batch_feature_tensor_pay_QOE_continue = train_batch_feature_tensor_dict['pay_QOE_continue']\n",
    "    train_batch_feature_tensor_pay_CHONGHE_continue = train_batch_feature_tensor_dict['pay_CHONGHE_continue']\n",
    "    train_batch_feature_tensor_pay_FUFEI_continue = train_batch_feature_tensor_dict['pay_FUFEI_continue']\n",
    "    train_batch_feature_tensor_not_pay_QOE_discrete = train_batch_feature_tensor_dict['not_pay_QOE_discrete']\n",
    "    train_batch_feature_tensor_not_pay_CHONGHE_discrete = train_batch_feature_tensor_dict['not_pay_CHONGHE_discrete']\n",
    "    train_batch_feature_tensor_not_pay_FUFEI_discrete = train_batch_feature_tensor_dict['not_pay_FUFEI_discrete']\n",
    "    train_batch_feature_tensor_not_pay_QOE_continue = train_batch_feature_tensor_dict['not_pay_QOE_continue']\n",
    "    train_batch_feature_tensor_not_pay_CHONGHE_continue = train_batch_feature_tensor_dict['not_pay_CHONGHE_continue']\n",
    "    train_batch_feature_tensor_not_pay_FUFEI_continue = train_batch_feature_tensor_dict['not_pay_FUFEI_continue']\n",
    "    train_batch_feature_tensor_target_QOE_discrete = train_batch_feature_tensor_dict['target_QOE_discrete']\n",
    "    train_batch_feature_tensor_target_CHONGHE_discrete = train_batch_feature_tensor_dict['target_CHONGHE_discrete']\n",
    "    train_batch_feature_tensor_target_FUFEI_discrete = train_batch_feature_tensor_dict['target_FUFEI_discrete']\n",
    "    train_batch_feature_tensor_target_QOE_continue = train_batch_feature_tensor_dict['target_QOE_continue']\n",
    "    train_batch_feature_tensor_target_CHONGHE_continue = train_batch_feature_tensor_dict['target_CHONGHE_continue']\n",
    "    train_batch_feature_tensor_target_FUFEI_continue = train_batch_feature_tensor_dict['target_FUFEI_continue']\n",
    "    train_batch_feature_tensor_pay_QOE_discrete_mask = train_batch_feature_tensor_history_mask_dict['pay_QOE_discrete']\n",
    "    train_batch_feature_tensor_pay_CHONGHE_discrete_mask = train_batch_feature_tensor_history_mask_dict['pay_CHONGHE_discrete']\n",
    "    train_batch_feature_tensor_pay_FUFEI_discrete_mask = train_batch_feature_tensor_history_mask_dict['pay_FUFEI_discrete']\n",
    "    train_batch_feature_tensor_pay_QOE_continue_mask = train_batch_feature_tensor_history_mask_dict['pay_QOE_continue']\n",
    "    train_batch_feature_tensor_pay_CHONGHE_continue_mask = train_batch_feature_tensor_history_mask_dict['pay_CHONGHE_continue']\n",
    "    train_batch_feature_tensor_pay_FUFEI_continue_mask = train_batch_feature_tensor_history_mask_dict['pay_FUFEI_continue']\n",
    "    train_batch_feature_tensor_not_pay_QOE_discrete_mask = train_batch_feature_tensor_history_mask_dict['not_pay_QOE_discrete']\n",
    "    train_batch_feature_tensor_not_pay_CHONGHE_discrete_mask = train_batch_feature_tensor_history_mask_dict['not_pay_CHONGHE_discrete']\n",
    "    train_batch_feature_tensor_not_pay_FUFEI_discrete_mask = train_batch_feature_tensor_history_mask_dict['not_pay_FUFEI_discrete']\n",
    "    train_batch_feature_tensor_not_pay_QOE_continue_mask = train_batch_feature_tensor_history_mask_dict['not_pay_QOE_continue']\n",
    "    train_batch_feature_tensor_not_pay_CHONGHE_continue_mask = train_batch_feature_tensor_history_mask_dict['not_pay_CHONGHE_continue']\n",
    "    train_batch_feature_tensor_not_pay_FUFEI_continue_mask = train_batch_feature_tensor_history_mask_dict['not_pay_FUFEI_continue']\n",
    "\n",
    "    val_batch_feature_tensor_pay_QOE_discrete = val_batch_feature_tensor_dict['pay_QOE_discrete']\n",
    "    val_batch_feature_tensor_pay_CHONGHE_discrete = val_batch_feature_tensor_dict['pay_CHONGHE_discrete']\n",
    "    val_batch_feature_tensor_pay_FUFEI_discrete = val_batch_feature_tensor_dict['pay_FUFEI_discrete']\n",
    "    val_batch_feature_tensor_pay_QOE_continue = val_batch_feature_tensor_dict['pay_QOE_continue']\n",
    "    val_batch_feature_tensor_pay_CHONGHE_continue = val_batch_feature_tensor_dict['pay_CHONGHE_continue']\n",
    "    val_batch_feature_tensor_pay_FUFEI_continue = val_batch_feature_tensor_dict['pay_FUFEI_continue']\n",
    "    val_batch_feature_tensor_not_pay_QOE_discrete = val_batch_feature_tensor_dict['not_pay_QOE_discrete']\n",
    "    val_batch_feature_tensor_not_pay_CHONGHE_discrete = val_batch_feature_tensor_dict['not_pay_CHONGHE_discrete']\n",
    "    val_batch_feature_tensor_not_pay_FUFEI_discrete = val_batch_feature_tensor_dict['not_pay_FUFEI_discrete']\n",
    "    val_batch_feature_tensor_not_pay_QOE_continue = val_batch_feature_tensor_dict['not_pay_QOE_continue']\n",
    "    val_batch_feature_tensor_not_pay_CHONGHE_continue = val_batch_feature_tensor_dict['not_pay_CHONGHE_continue']\n",
    "    val_batch_feature_tensor_not_pay_FUFEI_continue = val_batch_feature_tensor_dict['not_pay_FUFEI_continue']\n",
    "    val_batch_feature_tensor_target_QOE_discrete = val_batch_feature_tensor_dict['target_QOE_discrete']\n",
    "    val_batch_feature_tensor_target_CHONGHE_discrete = val_batch_feature_tensor_dict['target_CHONGHE_discrete']\n",
    "    val_batch_feature_tensor_target_FUFEI_discrete = val_batch_feature_tensor_dict['target_FUFEI_discrete']\n",
    "    val_batch_feature_tensor_target_QOE_continue = val_batch_feature_tensor_dict['target_QOE_continue']\n",
    "    val_batch_feature_tensor_target_CHONGHE_continue = val_batch_feature_tensor_dict['target_CHONGHE_continue']\n",
    "    val_batch_feature_tensor_target_FUFEI_continue = val_batch_feature_tensor_dict['target_FUFEI_continue']\n",
    "    val_batch_feature_tensor_pay_QOE_discrete_mask = val_batch_feature_tensor_history_mask_dict['pay_QOE_discrete']\n",
    "    val_batch_feature_tensor_pay_CHONGHE_discrete_mask = val_batch_feature_tensor_history_mask_dict['pay_CHONGHE_discrete']\n",
    "    val_batch_feature_tensor_pay_FUFEI_discrete_mask = val_batch_feature_tensor_history_mask_dict['pay_FUFEI_discrete']\n",
    "    val_batch_feature_tensor_pay_QOE_continue_mask = val_batch_feature_tensor_history_mask_dict['pay_QOE_continue']\n",
    "    val_batch_feature_tensor_pay_CHONGHE_continue_mask = val_batch_feature_tensor_history_mask_dict['pay_CHONGHE_continue']\n",
    "    val_batch_feature_tensor_pay_FUFEI_continue_mask = val_batch_feature_tensor_history_mask_dict['pay_FUFEI_continue']\n",
    "    val_batch_feature_tensor_not_pay_QOE_discrete_mask = val_batch_feature_tensor_history_mask_dict['not_pay_QOE_discrete']\n",
    "    val_batch_feature_tensor_not_pay_CHONGHE_discrete_mask = val_batch_feature_tensor_history_mask_dict['not_pay_CHONGHE_discrete']\n",
    "    val_batch_feature_tensor_not_pay_FUFEI_discrete_mask = val_batch_feature_tensor_history_mask_dict['not_pay_FUFEI_discrete']\n",
    "    val_batch_feature_tensor_not_pay_QOE_continue_mask = val_batch_feature_tensor_history_mask_dict['not_pay_QOE_continue']\n",
    "    val_batch_feature_tensor_not_pay_CHONGHE_continue_mask = val_batch_feature_tensor_history_mask_dict['not_pay_CHONGHE_continue']\n",
    "    val_batch_feature_tensor_not_pay_FUFEI_continue_mask = val_batch_feature_tensor_history_mask_dict['not_pay_FUFEI_continue']\n",
    "    \n",
    "    test_batch_feature_tensor_pay_QOE_discrete = test_batch_feature_tensor_dict['pay_QOE_discrete']\n",
    "    test_batch_feature_tensor_pay_CHONGHE_discrete = test_batch_feature_tensor_dict['pay_CHONGHE_discrete']\n",
    "    test_batch_feature_tensor_pay_FUFEI_discrete = test_batch_feature_tensor_dict['pay_FUFEI_discrete']\n",
    "    test_batch_feature_tensor_pay_QOE_continue = test_batch_feature_tensor_dict['pay_QOE_continue']\n",
    "    test_batch_feature_tensor_pay_CHONGHE_continue = test_batch_feature_tensor_dict['pay_CHONGHE_continue']\n",
    "    test_batch_feature_tensor_pay_FUFEI_continue = test_batch_feature_tensor_dict['pay_FUFEI_continue']\n",
    "    test_batch_feature_tensor_not_pay_QOE_discrete = test_batch_feature_tensor_dict['not_pay_QOE_discrete']\n",
    "    test_batch_feature_tensor_not_pay_CHONGHE_discrete = test_batch_feature_tensor_dict['not_pay_CHONGHE_discrete']\n",
    "    test_batch_feature_tensor_not_pay_FUFEI_discrete = test_batch_feature_tensor_dict['not_pay_FUFEI_discrete']\n",
    "    test_batch_feature_tensor_not_pay_QOE_continue = test_batch_feature_tensor_dict['not_pay_QOE_continue']\n",
    "    test_batch_feature_tensor_not_pay_CHONGHE_continue = test_batch_feature_tensor_dict['not_pay_CHONGHE_continue']\n",
    "    test_batch_feature_tensor_not_pay_FUFEI_continue = test_batch_feature_tensor_dict['not_pay_FUFEI_continue']\n",
    "    test_batch_feature_tensor_target_QOE_discrete = test_batch_feature_tensor_dict['target_QOE_discrete']\n",
    "    test_batch_feature_tensor_target_CHONGHE_discrete = test_batch_feature_tensor_dict['target_CHONGHE_discrete']\n",
    "    test_batch_feature_tensor_target_FUFEI_discrete = test_batch_feature_tensor_dict['target_FUFEI_discrete']\n",
    "    test_batch_feature_tensor_target_QOE_continue = test_batch_feature_tensor_dict['target_QOE_continue']\n",
    "    test_batch_feature_tensor_target_CHONGHE_continue = test_batch_feature_tensor_dict['target_CHONGHE_continue']\n",
    "    test_batch_feature_tensor_target_FUFEI_continue = test_batch_feature_tensor_dict['target_FUFEI_continue']\n",
    "    test_batch_feature_tensor_pay_QOE_discrete_mask = test_batch_feature_tensor_history_mask_dict['pay_QOE_discrete']\n",
    "    test_batch_feature_tensor_pay_CHONGHE_discrete_mask = test_batch_feature_tensor_history_mask_dict['pay_CHONGHE_discrete']\n",
    "    test_batch_feature_tensor_pay_FUFEI_discrete_mask = test_batch_feature_tensor_history_mask_dict['pay_FUFEI_discrete']\n",
    "    test_batch_feature_tensor_pay_QOE_continue_mask = test_batch_feature_tensor_history_mask_dict['pay_QOE_continue']\n",
    "    test_batch_feature_tensor_pay_CHONGHE_continue_mask = test_batch_feature_tensor_history_mask_dict['pay_CHONGHE_continue']\n",
    "    test_batch_feature_tensor_pay_FUFEI_continue_mask = test_batch_feature_tensor_history_mask_dict['pay_FUFEI_continue']\n",
    "    test_batch_feature_tensor_not_pay_QOE_discrete_mask = test_batch_feature_tensor_history_mask_dict['not_pay_QOE_discrete']\n",
    "    test_batch_feature_tensor_not_pay_CHONGHE_discrete_mask = test_batch_feature_tensor_history_mask_dict['not_pay_CHONGHE_discrete']\n",
    "    test_batch_feature_tensor_not_pay_FUFEI_discrete_mask = test_batch_feature_tensor_history_mask_dict['not_pay_FUFEI_discrete']\n",
    "    test_batch_feature_tensor_not_pay_QOE_continue_mask = test_batch_feature_tensor_history_mask_dict['not_pay_QOE_continue']\n",
    "    test_batch_feature_tensor_not_pay_CHONGHE_continue_mask = test_batch_feature_tensor_history_mask_dict['not_pay_CHONGHE_continue']\n",
    "    test_batch_feature_tensor_not_pay_FUFEI_continue_mask = test_batch_feature_tensor_history_mask_dict['not_pay_FUFEI_continue']\n",
    "    # 训练集\n",
    "    train_dataset = TensorDataset(train_batch_feature_tensor_pay_QOE_discrete,train_batch_feature_tensor_pay_CHONGHE_discrete,train_batch_feature_tensor_pay_FUFEI_discrete,\n",
    "                                train_batch_feature_tensor_pay_QOE_continue,train_batch_feature_tensor_pay_CHONGHE_continue,train_batch_feature_tensor_pay_FUFEI_continue,\n",
    "                                train_batch_feature_tensor_not_pay_QOE_discrete,train_batch_feature_tensor_not_pay_CHONGHE_discrete,train_batch_feature_tensor_not_pay_FUFEI_discrete,\n",
    "                                train_batch_feature_tensor_not_pay_QOE_continue,train_batch_feature_tensor_not_pay_CHONGHE_continue,train_batch_feature_tensor_not_pay_FUFEI_continue,\n",
    "                                train_batch_feature_tensor_target_QOE_discrete,train_batch_feature_tensor_target_CHONGHE_discrete,train_batch_feature_tensor_target_FUFEI_discrete,\n",
    "                                train_batch_feature_tensor_target_QOE_continue,train_batch_feature_tensor_target_CHONGHE_continue,train_batch_feature_tensor_target_FUFEI_continue,\n",
    "                                train_batch_feature_tensor_pay_QOE_discrete_mask,train_batch_feature_tensor_pay_CHONGHE_discrete_mask,train_batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "                                train_batch_feature_tensor_pay_QOE_continue_mask,train_batch_feature_tensor_pay_CHONGHE_continue_mask,train_batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "                                train_batch_feature_tensor_not_pay_QOE_discrete_mask,train_batch_feature_tensor_not_pay_CHONGHE_discrete_mask,train_batch_feature_tensor_not_pay_FUFEI_discrete_mask,\n",
    "                                train_batch_feature_tensor_not_pay_QOE_continue_mask,train_batch_feature_tensor_not_pay_CHONGHE_continue_mask,train_batch_feature_tensor_not_pay_FUFEI_continue_mask,\n",
    "                                train_label_tensor)\n",
    "    val_dataset = TensorDataset(val_batch_feature_tensor_pay_QOE_discrete,val_batch_feature_tensor_pay_CHONGHE_discrete,val_batch_feature_tensor_pay_FUFEI_discrete,\n",
    "                                val_batch_feature_tensor_pay_QOE_continue,val_batch_feature_tensor_pay_CHONGHE_continue,val_batch_feature_tensor_pay_FUFEI_continue,\n",
    "                                val_batch_feature_tensor_not_pay_QOE_discrete,val_batch_feature_tensor_not_pay_CHONGHE_discrete,val_batch_feature_tensor_not_pay_FUFEI_discrete,\n",
    "                                val_batch_feature_tensor_not_pay_QOE_continue,val_batch_feature_tensor_not_pay_CHONGHE_continue,val_batch_feature_tensor_not_pay_FUFEI_continue,\n",
    "                                val_batch_feature_tensor_target_QOE_discrete,val_batch_feature_tensor_target_CHONGHE_discrete,val_batch_feature_tensor_target_FUFEI_discrete,\n",
    "                                val_batch_feature_tensor_target_QOE_continue,val_batch_feature_tensor_target_CHONGHE_continue,val_batch_feature_tensor_target_FUFEI_continue,\n",
    "                                val_batch_feature_tensor_pay_QOE_discrete_mask,val_batch_feature_tensor_pay_CHONGHE_discrete_mask,val_batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "                                val_batch_feature_tensor_pay_QOE_continue_mask,val_batch_feature_tensor_pay_CHONGHE_continue_mask,val_batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "                                val_batch_feature_tensor_not_pay_QOE_discrete_mask,val_batch_feature_tensor_not_pay_CHONGHE_discrete_mask,val_batch_feature_tensor_not_pay_FUFEI_discrete_mask,\n",
    "                                val_batch_feature_tensor_not_pay_QOE_continue_mask,val_batch_feature_tensor_not_pay_CHONGHE_continue_mask,val_batch_feature_tensor_not_pay_FUFEI_continue_mask,\n",
    "                                val_label_tensor)\n",
    "\n",
    "    # 旧\n",
    "    # train_batch_feature_tensor = list(train_batch_feature_tensor_dict.values())\n",
    "    # train_batch_feature_tensor_history_mask = list(train_batch_feature_tensor_history_mask_dict.values())\n",
    "    # val_batch_feature_tensor = list(val_batch_feature_tensor_dict.values())\n",
    "    # val_batch_feature_tensor_history_mask = list(val_batch_feature_tensor_history_mask_dict.values())\n",
    "    # test_batch_feature_tensor = list(test_batch_feature_tensor_dict.values())\n",
    "    # test_batch_feature_tensor_history_mask = list(test_batch_feature_tensor_history_mask_dict.values())  \n",
    "    # # 训练集\n",
    "    # train_dataset = TensorDataset(*train_batch_feature_tensor, *train_batch_feature_tensor_history_mask, train_label_tensor)\n",
    "    # val_dataset = TensorDataset(*val_batch_feature_tensor, *val_batch_feature_tensor_history_mask, val_label_tensor)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)  # 记得改回随机\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    # 确保您的计算机上有CUDA支持的GPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # 创建大模型的实例\n",
    "    model = MatchingModel(feature_category_num_dict, feature_column_dict, continue_embedding_dim,\n",
    "                 discrete_embedding_dim, num_heads, feature_dim, max_history_len)\n",
    "    print('模型搭建完成')\n",
    "    model.to(device)\n",
    "    # 进一步处理 列表转移到GPU\n",
    "    for i in range(len(model.user_history_pay_embedding_layer.user_pay_history_QOE_discrete_embeddings)):\n",
    "        model.user_history_pay_embedding_layer.user_pay_history_QOE_discrete_embeddings[i] = \\\n",
    "        model.user_history_pay_embedding_layer.user_pay_history_QOE_discrete_embeddings[i].to(device)\n",
    "    for i in range(len(model.user_history_pay_embedding_layer.user_pay_history_CHONGHE_discrete_embeddings)):\n",
    "        model.user_history_pay_embedding_layer.user_pay_history_CHONGHE_discrete_embeddings[i] = \\\n",
    "        model.user_history_pay_embedding_layer.user_pay_history_CHONGHE_discrete_embeddings[i].to(device)\n",
    "    for i in range(len(model.user_history_pay_embedding_layer.user_pay_history_FUFEI_discrete_embeddings)):\n",
    "        model.user_history_pay_embedding_layer.user_pay_history_FUFEI_discrete_embeddings[i] = \\\n",
    "        model.user_history_pay_embedding_layer.user_pay_history_FUFEI_discrete_embeddings[i].to(device)\n",
    "    for i in range(len(model.user_history_pay_embedding_layer.user_pay_history_QOE_continue_embedding)):\n",
    "        model.user_history_pay_embedding_layer.user_pay_history_QOE_continue_embedding[i] = \\\n",
    "        model.user_history_pay_embedding_layer.user_pay_history_QOE_continue_embedding[i].to(device)\n",
    "    for i in range(len(model.user_history_pay_embedding_layer.user_pay_history_CHONGHE_continue_embedding)):\n",
    "        model.user_history_pay_embedding_layer.user_pay_history_CHONGHE_continue_embedding[i] = \\\n",
    "        model.user_history_pay_embedding_layer.user_pay_history_CHONGHE_continue_embedding[i].to(device)\n",
    "    for i in range(len(model.user_history_pay_embedding_layer.user_pay_history_FUFEI_continue_embedding)):\n",
    "        model.user_history_pay_embedding_layer.user_pay_history_FUFEI_continue_embedding[i] = \\\n",
    "        model.user_history_pay_embedding_layer.user_pay_history_FUFEI_continue_embedding[i].to(device)\n",
    "\n",
    "    for i in range(len(model.user_history_not_pay_embedding_layer.user_pay_history_QOE_discrete_embeddings)):\n",
    "        model.user_history_not_pay_embedding_layer.user_pay_history_QOE_discrete_embeddings[i] = \\\n",
    "        model.user_history_not_pay_embedding_layer.user_pay_history_QOE_discrete_embeddings[i].to(device)\n",
    "    for i in range(len(model.user_history_not_pay_embedding_layer.user_pay_history_CHONGHE_discrete_embeddings)):\n",
    "        model.user_history_not_pay_embedding_layer.user_pay_history_CHONGHE_discrete_embeddings[i] = \\\n",
    "        model.user_history_not_pay_embedding_layer.user_pay_history_CHONGHE_discrete_embeddings[i].to(device)\n",
    "    for i in range(len(model.user_history_not_pay_embedding_layer.user_pay_history_FUFEI_discrete_embeddings)):\n",
    "        model.user_history_not_pay_embedding_layer.user_pay_history_FUFEI_discrete_embeddings[i] = \\\n",
    "        model.user_history_not_pay_embedding_layer.user_pay_history_FUFEI_discrete_embeddings[i].to(device)\n",
    "    for i in range(len(model.user_history_not_pay_embedding_layer.user_pay_history_QOE_continue_embedding)):\n",
    "        model.user_history_not_pay_embedding_layer.user_pay_history_QOE_continue_embedding[i] = \\\n",
    "        model.user_history_not_pay_embedding_layer.user_pay_history_QOE_continue_embedding[i].to(device)\n",
    "    for i in range(len(model.user_history_not_pay_embedding_layer.user_pay_history_CHONGHE_continue_embedding)):\n",
    "        model.user_history_not_pay_embedding_layer.user_pay_history_CHONGHE_continue_embedding[i] = \\\n",
    "        model.user_history_not_pay_embedding_layer.user_pay_history_CHONGHE_continue_embedding[i].to(device)\n",
    "    for i in range(len(model.user_history_not_pay_embedding_layer.user_pay_history_FUFEI_continue_embedding)):\n",
    "        model.user_history_not_pay_embedding_layer.user_pay_history_FUFEI_continue_embedding[i] = \\\n",
    "        model.user_history_not_pay_embedding_layer.user_pay_history_FUFEI_continue_embedding[i].to(device)\n",
    "    \n",
    "    for i in range(len(model.target_embedding_layer.target_QOE_discrete_embeddings)):\n",
    "        model.target_embedding_layer.target_QOE_discrete_embeddings[i] = \\\n",
    "        model.target_embedding_layer.target_QOE_discrete_embeddings[i].to(device)\n",
    "    for i in range(len(model.target_embedding_layer.target_CHONGHE_discrete_embeddings)):\n",
    "        model.target_embedding_layer.target_CHONGHE_discrete_embeddings[i] = \\\n",
    "        model.target_embedding_layer.target_CHONGHE_discrete_embeddings[i].to(device)\n",
    "    for i in range(len(model.target_embedding_layer.target_FUFEI_discrete_embeddings)):\n",
    "        model.target_embedding_layer.target_FUFEI_discrete_embeddings[i] = \\\n",
    "        model.target_embedding_layer.target_FUFEI_discrete_embeddings[i].to(device)\n",
    "    for i in range(len(model.target_embedding_layer.target_QOE_continue_embedding)):\n",
    "        model.target_embedding_layer.target_QOE_continue_embedding[i] = \\\n",
    "        model.target_embedding_layer.target_QOE_continue_embedding[i].to(device)\n",
    "    for i in range(len(model.target_embedding_layer.target_CHONGHE_continue_embedding)):\n",
    "        model.target_embedding_layer.target_CHONGHE_continue_embedding[i] = \\\n",
    "        model.target_embedding_layer.target_CHONGHE_continue_embedding[i].to(device)\n",
    "    for i in range(len(model.target_embedding_layer.target_FUFEI_continue_embedding)):\n",
    "        model.target_embedding_layer.target_FUFEI_continue_embedding[i] = \\\n",
    "        model.target_embedding_layer.target_FUFEI_continue_embedding[i].to(device)\n",
    "    print('模型转移到GPU完成')\n",
    "    lossfunction = nn.BCELoss()\n",
    "#     optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9)\n",
    "\n",
    "    # 训练\n",
    "    model_training(model, train_loader, val_loader, lossfunction, optimizer, 500, device)\n",
    "    print('模型训练完成')\n",
    "    print('||--------训练结束时间：',datetime.datetime.now(),'-------------')\n",
    "    # 测试\n",
    "    test_dataset = TensorDataset(test_batch_feature_tensor_pay_QOE_discrete,test_batch_feature_tensor_pay_CHONGHE_discrete,test_batch_feature_tensor_pay_FUFEI_discrete,\n",
    "                                test_batch_feature_tensor_pay_QOE_continue,test_batch_feature_tensor_pay_CHONGHE_continue,test_batch_feature_tensor_pay_FUFEI_continue,\n",
    "                                test_batch_feature_tensor_not_pay_QOE_discrete,test_batch_feature_tensor_not_pay_CHONGHE_discrete,test_batch_feature_tensor_not_pay_FUFEI_discrete,\n",
    "                                test_batch_feature_tensor_not_pay_QOE_continue,test_batch_feature_tensor_not_pay_CHONGHE_continue,test_batch_feature_tensor_not_pay_FUFEI_continue,\n",
    "                                test_batch_feature_tensor_target_QOE_discrete,test_batch_feature_tensor_target_CHONGHE_discrete,test_batch_feature_tensor_target_FUFEI_discrete,\n",
    "                                test_batch_feature_tensor_target_QOE_continue,test_batch_feature_tensor_target_CHONGHE_continue,test_batch_feature_tensor_target_FUFEI_continue,\n",
    "                                test_batch_feature_tensor_pay_QOE_discrete_mask,test_batch_feature_tensor_pay_CHONGHE_discrete_mask,test_batch_feature_tensor_pay_FUFEI_discrete_mask,\n",
    "                                test_batch_feature_tensor_pay_QOE_continue_mask,test_batch_feature_tensor_pay_CHONGHE_continue_mask,test_batch_feature_tensor_pay_FUFEI_continue_mask,\n",
    "                                test_batch_feature_tensor_not_pay_QOE_discrete_mask,test_batch_feature_tensor_not_pay_CHONGHE_discrete_mask,test_batch_feature_tensor_not_pay_FUFEI_discrete_mask,\n",
    "                                test_batch_feature_tensor_not_pay_QOE_continue_mask,test_batch_feature_tensor_not_pay_CHONGHE_continue_mask,test_batch_feature_tensor_not_pay_FUFEI_continue_mask,\n",
    "                                test_label_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    average_loss_test, average_auc_test = test_model(model, test_loader)\n",
    "    # 测试的每个样本结果保存到csv\n",
    "    # 将本次训练的结果添加到DataFrame中\n",
    "    test_auc_df = test_auc_df.append(\n",
    "        {'时间窗':data_time_windows,'训练验证测试比例':train_ratio,'最大历史长度':max_history_len,'特征embedding维度':feature_dim,'学习率':lr,'batchSize':batch_size,'实验数': i + 1, '测试集总损失': average_loss_test, 'AUC': average_auc_test}, ignore_index=True)\n",
    "# 将结果保存到CSV文件中\n",
    "test_auc_df.to_csv('./Dataset/maoerDL_result_',datetime.datetime.now(),'.csv', index=False)\n",
    "print('结果已输出')\n",
    "print('||--------结束时间：',datetime.datetime.now(),'-------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f4de78-e6d2-4b0c-ab58-5a7cc163e30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec32e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
